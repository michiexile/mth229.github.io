[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MTH229 with Julia",
    "section": "",
    "text": "These projects use version v1.7 of Julia.\n\n (Binder can be used to access Julia remotely.)\n\n\nMTH229 at the College of Staten Island is a course to introduce a programming language to reinforce concepts of a first-semester calculus course from numerical and graphical points of view.\nSome sections use the Julia programming language. For Julia, the computer-lab “projects” are on WeBWorK and there should be sufficient background material therein to work through the details. IN the notes here can be found additional detail for those seeking it. For a more thorough introduction, visit Calculus with Julia.\nInstallation details for Julia are at the end of this page\n\nThese notes are broken into different sections, where most all sections have some self-grading questions at the end that allow you to test your knowledge of that material. The code should be copy-and-pasteable into a Julia session. The code output is similar to what would be shown if evaluated in an IJulia cell, our recommended interface while learning Julia, though some may like the Pluto interface as well.\nThe notes mostly follow topics of a standard first-semester calculus course after some background material is presented for learning Julia within a mathematical framework.\nEach topic has a lab project. At CSI, sufficient time is allotted to complete these projects during the lab class. These projects are available as IJulia notebooks or Pluto notebooks. (There are also Pluto notebooks with 5-10 minutes of commentary.) Find links for these near the top of each page of notes.\nFor example, blank notebooks for test taking, etc. are found by following these links:\nipynb (Pluto html)\n\n\nQuestion and answers are now presented and completed through WeBWorK. The .ipynb notebooks only contain modest background details.\nThere are a few idiosyncracies in the WeBWorK pages to be aware of:\n\nThe code examples are typset in WeBWorK as though they appear in a terminal. A terminal displays the output of each command immediately after execution. In a notebook, when a cell is executed, all the commands are computed and only the last value is shown. (The use of @show or print(...) can be used to display intermediate values in a cell.)\nCopy and paste from a WeBWorK page into a notebook will usually be unsuccessful, as numbers in the font used to display computer markup do not copy as ASCII numbers into a cell. The numbers can be hand edited though.\nWhile Julia is very happy to express its output using scientific notation, WeBWorK is not happy to receive the exact output for an answer. Either replace e with E (as in 1.23e4 would be 1.23E4) or use decimals.\nFor most questions with a numeric answer it is best to copy all 16 digits of output. Several digits are expected to match a correct answer. For numeric questions where an estimate is made, say from a graph, this is significantly relaxed.\nIf the answer is to be a function, the automatic grader is expecting just the rule of the function (an expression), as in for f(x) = sin(x) just enter sin(x).\n\n\n\n\n\nJulia makes an excellent choice as a computer supplement for this material as its syntax is very similar to standard mathematical syntax. The ability to define mathematical functions using the familiar f(x) = ... notation makes getting started really easy. Further, the fact that functions are first-class objects means that it is possible to create higher-order Julia functions that mirror the standard operations of calculus. The following pattern is used throughout:\naction(function_object, args...)\nFor example, the notes use:\n\nplot(f, a, b) to plot f over [a,b]; plot!(g) to add a curve (using Plots)\nfzero(f, a, b) or find_zero(f, (a,b)) to find a zero inside the bracketing interval [a,b] (from Roots)\nfzeros(f, a, b) (or find_zeros(f, (a,b))) to find all the real zeros of a function f in [a,b] (from Roots)\nfzero(f, a) (or find_zero(f, a)) to find a zero using initial starting oint a (from Roots)\nlimit(f(x), x=>c) to find the limit of f at c (from SymPy)\nf' to return a function that computes the derivative of f (Added in the MTH229 package based on the derivative function from the ForwardDiff package)\ndiff(f(x),x) to find a symbolic derivative of f (from SymPy)\nquadgk(f, a, b) to find the numeric integral of f over (a,b) (from the QuadGK package)\nintegrate(f(x), x) to find the symbolic integral of f (from the SymPy package)\nintegrate(f(x), (x, a, b)) to find the definite integral over [a,b] symbolically (from the SymPy package).\n\nWith just this basic set of actions, akin to buttons on the calculator, a rich variety of problems can be addressed.\n\n\n\nUsing Julia to complete the projects of MTH 229 can be done in several ways.\n\n\nCSI students have access to a server that gives access to the jupyter notebooks.\n\n\n\nThis is not terribly difficult, but does involve a few additional steps:\n\nDownload and install Julia from julialang.org/. This will install like any other software for you system. You should use the latest released version, currently v1.8.\nStart the application\n\nThis opens a terminal, appearing as follows:\n#| echo: false\nBase.banner()\nCommands are typed after the prompt (> julia) and executed when the return key is pressed.\nTry a few commands and see. Adding 2 and 2 should look like:\njulia> 2 + 2\n4\n\njulia>\nFor this class, some external packages must be loaded. First issue the command\nusing MTH229, Plots\nThis installs and loads two external packages – one containing functions for this class, the other providing a plotting environments.\nOnce these are installed and loaded, the projects for the class can be installed following this command:\nmth229()\nOkay, that should set everything up.\nWhen you want to actually use Julia for this class, you only need to use these two commands from the command line:\nusing IJulia\nnotebook()\nIf not already installed, IJulia will be installed and configured, and then the notebook command will open a browser window allowing the selection of one of the projects. Your work will be within a browser window, not the terminal.\nThe latter two commands are the only ones needed for subsequent usage, as the packages MTH229 and Plots will be loaded within an IJulia notebook.\n\n\nPluto notebooks are easier to install. At the terminal (assuming version 1.7 or higher) run:\nusing Pluto\nPluto.run()\nThis will open a Pluto landing page in a browser tab. The html notebooks linked herein offer a means to “Edit or run this notebook.” Download the notebook (it will make a .jl file) and then open this within Pluto.\n\n\n\n\n\n\n\nBinder\n\n\nThe link above allows the projects for MTH229 to be run through the web.\n\nbinder is a service that runs interactive notebooks through the web. Each notebook is limited in memory and has a 10 minute inactivity timeout. Binder notebooks are not persistent, though they do have a button to save to local storage.\n\nBinder takes between 30 seconds and one minute to get up and running. Once a notebook is selected, it takes another 30ish seconds to get the typical packages started.\n\nThis table covers pros and cons for the approaches mentioned above:\n                         Using server    Binder       Local Installation\nSetup ease                  ✓              ✓                 ×\n\nSpeed                       ✓              ×                 ✓\n\nPersistence of work         ×              ×                 ✓\n\nFree                        ✓              ✓                 ✓\n\nUse at home                 ✓              ✓                 ✓"
  },
  {
    "objectID": "calculator.html",
    "href": "calculator.html",
    "title": "1  Julia as a calculator",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "calculator.html#introduction",
    "href": "calculator.html#introduction",
    "title": "1  Julia as a calculator",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nThe programming language Julia (www.julialang.org) is a new language that builds on a long history of so-called dynamic scripting languages (DSLs). DSLs are widely used for exploratory work and are part of the toolbox of most all data scientists, a rapidly growing area of employment. The basic Julia language is reminiscent of is MATLAB, though it offers many improvements over that language. For these notes, the focus will be on its more transparent syntax, but in general a major selling point of Julia is that it is much faster that MATLAB at many tasks. (Well it should be, MATLAB was started back in the 70s.) Even better, Julia is an open-source project which means it is free to download and install, unlike the commercial package MATLAB.\nThese notes will use Julia to explore calculus concepts. Unlike some other programs used with calculus (e.g., Mathematica, Maple, and Sage) Julia is not a symbolic math language. Rather, we will use a numeric approach. This gives a different viewpoint on the calculus material supplementing that of the text book. Though there are a few idiosyncrasies we will see along the way, for the most part the Julia language will be both powerful and easy to learn.\nIn this project we start with baby steps – how to use Julia to perform operations we can do on the calculator. The use of a calculator requires knowledge about several things we take for granted here:\n\nthe use of the basic math operators\nan understanding of the order of operations, or knowing when parentheses are needed\nhow to use the buttons that compute functions such as the sine function\nand how to use the memory feature to store intermediate computations.\n\nParallells of each of these will be discussed in the following."
  },
  {
    "objectID": "calculator.html#expressions",
    "href": "calculator.html#expressions",
    "title": "1  Julia as a calculator",
    "section": "1.2 Expressions",
    "text": "1.2 Expressions\nJulia can replicate the basics of a calculator with the standard notations. The familiar binary operators are +, -, *, /, and ^. With a calculator you “punch” in numbers and operators and to get an answer push the = key. Using Julia is not much different: you type in an expression then send to Julia to compute. The “equals key” on a calculator is replaced by the enter key on the keyboard (or shift-enter if using IJulia). Beyond that there isn’t much difference.\nFor example, to add two and two we simply execute:\n2 + 2\nOr to convert \\(70\\) degrees to Celsius with the standard formula \\(C=5/9(F-32)\\):\n(5/9)*(70 - 32)\nOf to find a value of \\(32 - 16x^2\\) when \\(x=1.5\\):\n32 - 16*(1.5)^2\nTo find the value of \\(\\sqrt{15}\\) we can use power notation:\n15^(1/2)\n\n1.2.1 Practice\n\nQuestion\nCompute \\(22/7\\) in Julia.\n#| echo: false\nval = 22/7\nnumericq(val, 1e-5)\n\n\nQuestion\nCompute \\(\\sqrt{220}\\) in Julia.\n#| echo: false\nval = sqrt(220)\nnumericq(val, 1e-5)\n\n\nQuestion\nCompute \\(2^8\\) in Julia.\n#| echo: false\nval = 2^8\nnumericq(val, 1e-5)"
  },
  {
    "objectID": "calculator.html#precedence",
    "href": "calculator.html#precedence",
    "title": "1  Julia as a calculator",
    "section": "1.3 Precedence",
    "text": "1.3 Precedence\nOne drawback about using a calculator is the expression gets evaluated as it gets entered. For simple computations this is a convenience, but for more complicated ones it requires some thinking about the order of how an expression will be computed. In Julia you still need to be mindful of the order that operations are carried out, but as the entire expression is typed – and can be edited – before evaluation, you can more closely control what you want.\nOrder of operations refers to conventions used to decide which operation will happen first, when there is a choice of more than one. A simple example, is what is the value of \\(3 \\cdot 2 + 1\\)?\nThere are two binary operations in this expressions: a multiplication and an addition. Which is done first and which second?\nIn some instances the order used doesn’t matter. A case of this would be \\(3 + 2 + 1\\). This is because addition is associative. (Well, not really on the computer, but that is another lesson.) In the case of \\(3 \\cdot 2 + 1\\) the order certainly matters.\nFor \\(3 \\cdot 2 + 1\\) if we did the addition first, the expression would be \\(9 = 3\\cdot 3\\). If we did the multiplication first, the value would be \\(7=6+1\\). In this case, we all know that the correct answer is \\(7\\), as we perform multiplication before addition, or in more precise terms the precedence of multiplication is higher than that of addition.\n\n1.3.1 Basics of PEMDAS\nThe standard order of the basic mathematical operations is remembered by many students through the mnemonic PEMDAS, which can be misleading, so we spell it out here:\n\n(P) First parentheses\n(E) then exponents (or powers)\n(MD) then multiplication or division\n(AS) then addition or subtraction.\n\nThis has the precedence of multiplication (part of MD) higher than that of subtraction (part of AS), as just mentioned.\nApplying this, if we have the mathematical expression\n\\[\n\\frac{12 - 10}{2}\n\\]\nWe know that the subtraction needs to be done before the division, as this is how we interpret this form of division. How to make this happen? The precedence of parentheses is used to force the subtraction before the division, as in (12-10)/2. Without parentheses you get a different answer:\n#| echo: false\n(12 - 10)/2,  12 - 10/2\n\n\n\n\n\n\nAlert\n\n\n\nUsing a comma to separate expressions will cause both to print out – not just the last one evaluated. This trick is also a useful trick within an IJulia notebook.\n\n\n\nParentheses are used to force lower precedence operations to happen before higher precedence ones.\n\n\n\n1.3.2 Same precedence – what to do\nThere is a little more to the story, as we need to understand what happens when we have more then one operation with the same level. For instance, what is \\(2 - 3- 4\\)? Is it \\((2 - 3) - 4\\) or \\(2 - (3 - 4)\\).\nUnlike addition, subtraction is not associative so this really matters. The subtraction operator is left associative meaning the evaluation of \\(2 - 3 - 4\\) is done by \\((2-3) - 4\\). The operations are performed in a left-to-right manner. Most – but not all operations – are left associative, some are right associative and performed in a right-to-left manner.\n\n\n\n\n\n\nAlert\n\n\n\nright to left It is the order of which operation is done first, not reading from right to left, as one might read Arabic.\n\n\nTo see that Julia has left associative subtraction, we can just check.\n2 - 3 - 4, (2 - 3) - 4, 2 - (3 - 4)\nNot all operations are processed left-to-right. The power operation, ^, is right associative, as this matches the mathematical usage. For example:\n4^3^2, (4^3)^2, 4^(3^2)\nWhat about the case where we have different operations with the same precedence? What happens then? A simple example would be \\(2 / 3 * 4\\)? Is this done in a left to right manner as in:\n(2 / 3) * 4\nOr a right-to-left manner, as in:\n2 / (3 * 4)\nAnd the answer is left-to-right:\n2 / 3 * 4\n\n\n1.3.3 Practice\n\nQuestion\nWich of the following is a valid Julia expression for\n\\[\n\\frac{3 - 2}{4 - 1}\n\\]\nthat uses the least number of parentheses?\n#| echo: false\nchoices = [\"`(3 - 2)/ 4 - 1`\", \"`3 - 2 / (4 - 1)`\", \"`(3 - 2) / (4 - 1)`\"]\nanswer = 3\nradioq(choices, answer)\n\n\nQuestion\nWich of the following is a valid Julia expression for\n\\[\n\\frac{3\\cdot2}{4}\n\\]\nthat uses the least number of parentheses?\n#| echo: false\nchoices = [\"`3 * 2 / 4`\", \"`(3 * 2) / 4`\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion\nWich of the following is a valid Julia expression for\n\\[\n2^{4 - 2}\n\\]\nthat uses the least number of parentheses?\n#| echo: false\nchoices = [\"`2 ^ 4 - 2`\", \"`(2 ^ 4) - 2`\", \"`2 ^ (4 - 2)`\"]\nanswer = 3\nradioq(choices, answer)\n\n\nQuestion\nOne of these three expressions will produce a different answer, select that one:\n#| echo: false\nchoices = [\n\"`2 - 3 - 4`\",\n\"`(2 - 3) - 4`\",\n\"`2 - (3 - 4)`\"\n];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion\nOne of these three expressions will produce a different answer, select that one:\n#| echo: false\nchoices = [\n\"`2 - 3 * 4`\",\n\"`(2 - 3) * 4`\",\n\"`2 - (3 * 4)`\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion Unary operator: the minus sign\nOne of these three expressions will produce a different answer, select that one:\n#| echo: false\nchoices = [\n\"`-1^2`\",\n\"`(-1)^2`\",\n\"`-(1^2)`\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nCompute the value of\n\\[\n\\frac{9 - 5 \\cdot (3-4)}{6 - 2}.\n\\]\n#| echo: false\nval = (9-5*(3-4)) / (6-2)\nnumericq(val, .001)\n\n\nQuestion\nCompute the following using Julia:\n\\[\n\\frac{(.25 - .2)^2}{(1/4)^2 + (1/3)^2}\n\\]\n#| echo: false\nanswer = (.25 - .2)^2/((1/4)^2 + (1/3)^2);\nnumericq(answer)\n\n\nQuestion\nCompute the decimal representation of the following using Julia:\n\\[\n1 + \\frac{1}{2} + \\frac{1}{2^2} + \\frac{1}{2^3} + \\frac{1}{2^4}\n\\]\n#| echo: false\nanswer = sum((1/2).^(0:4));\nnumericq(answer)\n\n\nQuestion\nCompute the following using Julia:\n\\[\n\\frac{3 - 2^2}{4 - 2\\cdot3}\n\\]\n#| echo: false\nanswer = (3 - 2^2)/(4 - 2*3);\nnumericq(answer)\n\n\nQuestion\nCompute the following using Julia:\n\\[\n(1/2) \\cdot 32 \\cdot 3^2 + 100 \\cdot 3 - 20\n\\]\n#| echo: false\nanswer = (1/2)*32*3^2 + 100*3 - 20;\nnumericq(answer)"
  },
  {
    "objectID": "calculator.html#using-functions",
    "href": "calculator.html#using-functions",
    "title": "1  Julia as a calculator",
    "section": "1.4 Using functions",
    "text": "1.4 Using functions\nMost all calculators used are not limited to these basic arithmetic operations. So-called scientific calculators provide buttons for many of the common mathematical functions, such as exponential, logs, and trigonometric functions. Julia provides these too, of course.\nThere are special functions to perform common powers. For example, the square-root function is used as:\nsqrt(15)\nThis shows how to evaluate a function – using its name and parentheses, as in function_name(arguments). Parentheses are also used to group expressions, as would be done to do this using the power notation:\n15^(1/2)\nAdditionally, parentheses are also used to make “tuples”, a concept we don’t pursue here but that is important for programming with Julia. The point here is the context of how parentheses are used is important, though for the most part the usage is the same as their dual use in your calculus text.\nLike sqrt, there is also a cube-root function:\ncbrt(27)\nThe cbrt and sqrt functions are not exactly the same as using ^, as they differ when the inputs are not in their domain: For cube roots, we can see that there is a difference with negative bases:\ncbrt(-8)            ## correct\n(-8)^(1/3)              ## need first parentheses, why?\n(The latter is an error as the power function has an output type that depends on the power being real, not a specific value of a real. For 1/2 the above would clearly be an error, so then for 1/3 Julia makes this an error.)\n\n1.4.1 trigonometric functions\nThe basic trigonometric functions in Julia work with radians:\nsin(pi/4)\ncos(pi/3)\nBut students think in degrees. What to do? Well, you can always convert via the ratio \\(\\pi/180\\):\nsin(45 * pi/180)\ncos(60 * pi/180)\nHowever, Julia provides the student-friendly functions sind, cosd, and tand to work directly with degrees:\nsind(45)\ncosd(45)\nBe careful, an expression like \\(\\cos^2(\\pi/4)\\) is a shorthand for squaring the output of the cosine of \\(\\pi/4\\), hence is expressed with\ncos(pi/4)^2         # not cos^2(pi/4) !!!\n\n\n1.4.2 Inverse trigonometric function\nThe math notation \\(\\sin^{-1}(x)\\) is also a source of confusion. This is not a power, rather it indicates an inverse function, in this case the arcsine. The arcsine function is written asin in Julia.\nFor certain values, the arcsine and sine function are inverses:\nasin(sin(0.1))\nHowever, this isn’t true for all values of \\(x\\), as \\(\\sin(x)\\) is not monotonic everywhere. In particular, the above won’t work for \\(x\\) values outside \\((-\\pi/2, \\pi/2)\\):\nasin(sin(100))\nOther inverse trigonometric functions are acos, atan and for completeness asec, acsc, and acot are available for use.\n\n\n1.4.3 Exponential and logs\nThe values \\(e^x\\) can be computed through the function exp(x):\nexp(2)\nThe constant value of e is only available on demand:\nusing Base.MathConstants\ne\nThe logarithm function, log (and not ln) does log base \\(e\\):\nlog(exp(2))\nTo do base 10, there is a log10 function:\nlog10(exp(2))\nThere is also a log2 function for base 2. However, there are many more possible choices for a base. Rather than create functions for each possible one of interest the log function has an alternative form taking two argument. The first is interpreted as the base, the second the \\(x\\) value. So the above, is also done through:\nlog(10, exp(2))\n\n\n1.4.4 Some useful functions\nThere are some other useful functions For example, abs for the absolute value, round for rounding, floor for rounding down and ceil for rounding up. Here are some examples\nround(3.14)\nfloor(3.14)\nceil(3.14)\nThe observant eye will notice the answers above are not integers. (We discuss how to tell later.) What to do if you want an integer? These functions take a “type” argument, as in rount(Int, 3.14).\n\n\n1.4.5 Practice\n\nQuestion\nWhat is the value of \\(\\sin(\\pi/10)\\)?\n#| echo: false\nnumericq(sin(pi/10))\n\n\nQuestion\nWhat is the value of \\(\\sin(52^\\circ)\\)?\n#| echo: false\nnumericq(sind(52))\n\n\nQuestion\nIs \\(\\sin^{-1}(\\sin(3\\pi/2))\\) equal to \\(3\\pi/2\\)?\n#| echo: false\nbooleanq(false, labels=[\"yes\", \"no\"])\n\n\nQuestion\nWhat is the value of round(3.5000)\n#| echo: false\nnumericq(round(3.5))\n\n\nQuestion\nWhat is the value of sqrt(32 - 12)\n#| echo: false\nnumericq(sqrt(32-12))\n\n\nQuestion\nWhich is greater \\(e^\\pi\\) or \\(\\pi^e\\)?\n#| echo: false\nchoices = [\n\"`e^pi`\",\n\"`pi^e`\"\n];\nanswer = e^pi - pi^e > 0 ? 1 : 2;\nradioq(choices, answer)\n\n\nQuestion\nWhat is the value of \\(\\pi - (x - \\sin(x)/\\cos(x))\\) when \\(x=3\\)?\n#| echo: false\nx = 3;\nanswer = x - sin(x)/cos(x);\nnumericq(pi - answer)"
  },
  {
    "objectID": "calculator.html#variables",
    "href": "calculator.html#variables",
    "title": "1  Julia as a calculator",
    "section": "1.5 Variables",
    "text": "1.5 Variables\nWith a calculator, one can store values into a memory for later usage. This useful feature with calculators is greatly enhanced with computer languages, where one can bind, or assign, a variable to a value. For example the command x=2 will bind x to the value \\(2\\):\nx = 2\nSo, when we evaluate\nx^2\nThe value assigned to x is looked up and used to return \\(4\\).\nThe word “dynamic” to describe the Julia language refers to the fact that variables can be reassigned and retyped. For example:\nx = sqrt(2) ## a Float64 now\nIn Julia one can have single letter names, or much longer ones, such as\nsome_ridiculously_long_name = 3\nsome_ridiculously_long_name^2\nThe basic tradeoff being: longer names are usually more expressive and easier to remember, whereas short names are simpler to type. To get a list of the currently bound names, the whos function may be called. Not all names are syntactically valid, for example names can’t begin with a number or include spaces.\n\n\n\n\n\n\nAlert\n\n\n\nIn fact, only most objects bound to a name can be arbitrarily redefined. When we discuss functions, we will see that redefining functions can be an issue and new names will need to be used. As such, it often works to stick to come convention for naming: numbers use values like i, j, x, y; functions like f, g, h, etc.\n\n\nTo work with computer languages, it is important to appreciate that the equals sign in the variable assignment is unlike that of mathematics, where often it is used to indicate an equation which may be solved for a value. With the following computer command the right hand expression is evaluated and that value is assigned to the variable. So,\nx = 2 + 3\ndoes not assign the expression 2 + 3 to x, but rather the evaluation of that expression, which yields 5. (This also shows that the precedence of the assignment operator is lower than addition, as addition is performed first in the absence of parentheses.)\n\n1.5.1 Multiple assignments\nAt the prompt, a simple expression is entered and, when the return key is pressed, evaluated. At times we may want to work with multiple subexpressions. A particular case might be setting different parameters:\na=0\nb=1\nMultiple expressions can be more tersely written by separating each expression using a semicolon:\na=0; b=1;\nNote that Julia makes this task even easier, as one can do multiple assignments via “tuple destructuring:”\na, b  = 0, 1        ## printed output is a \"tuple\"\na + b\n\n\n1.5.2 Practice\n\nQuestion\nLet \\(a=10\\), \\(b=2.3\\), and \\(c=8\\). Find the value of \\((a-b)/(a-c)\\).\n#| echo: false\na,b,c = 10, 2.3, 8;\nnumericq((a-b)/(a-c))\n\n\nQuestion\nWhat is the answer to this computation?\na = 3.2; b=2.3\na^b - b^a\n#| echo: false\na = 3.2; b=2.3;\nval = a^b - b^a;\nnumericq(val)\n\n\nQuestion\nFor longer computations, it can be convenient to do them in parts, as this makes it easier to check for mistakes. (You likely do this with your calculator.)\nFor example, to compute\n\\[\n\\frac{p - q}{\\sqrt{p(1-p)}}\n\\]\nfor \\(p=0.25\\) and \\(q=0.2\\) we might do:\np, q = 0.25, 0.2\ntop = p - q\nbottom = sqrt(p*(1-p))\nanswer = top/bottom\nWhat is the result of the above?\n#| echo: false\np, q = 0.25, 0.2;\ntop = p - q;\nbottom = sqrt(p*(1-p));\nanswer = top/bottom;\nnumericq(answer)"
  },
  {
    "objectID": "calculator.html#numbers",
    "href": "calculator.html#numbers",
    "title": "1  Julia as a calculator",
    "section": "1.6 Numbers",
    "text": "1.6 Numbers\nIn mathematics, there a many different types of numbers. Familiar ones are integers, rational numbers, and the real numbers. In addition, complex numbers are needed to fully discuss polynomial functions. This is not the case with calculators.\nMost calculators treat all numbers as floating point numbers – an approximation to the real numbers. Not so with Julia. Julia has types for many different numbers: Integer, Real, Rational, Complex, and specializations depending on the number of bits that are used, e.g., Int64 and Float64. For the most part there is no need to think about the details, as values are promoted to a common type when used together. However, there are times where one needs to be aware of the distinctions.\n\n1.6.1 Integers and floating point numbers\nIn the real number system of mathematics, there are the familiar real numbers and integers. The integers are viewed as a subset of the real numbers.\nJulia provides types Integer and Real to represent these values. (Actually, the Integer type represents more than one actual storage type, either Int32 or Int64.) These are separate types. The type of an object is returned by typeof().\nFor example, the integer \\(1\\) is simply created by the value 1:\n1\nThe floating point value \\(1\\) is specified by using a decimal point:\n1.0\nThe two values are printed differently – integers never have a decimal point, floating point values always have a decimal point. This emphasizes the fact that the two values 1 and 1.0 are not the same – they are stored differently, they print differently, and can give different answers. In most cases – but not all – uses they can be used interchangeably.\nFor example, we can add the two:\n1 + 1.0\nThis gives back the floating point value 2.0. First the integer and floating point value are promoted to a common type (floating point in this case) and then added.\nSometimes there can be an issue. The value 2^(-3) we know should be \\(1/2^3 = 1/8\\) or 0.125 and Julia agrees:\n2^(-3)\nHowever, this is special cased. If -3 is replaced with a variable name, there will be a failure:\nx = -3\n2^x\nThis gotcha has an explanation: in julia, most functions are “type-stable” meaning, the type of the input (integer/integer in this case) should determine the type of the output (in this case floating point). But for this operation to be fast, julia insists (in general) it be an integer, as what happens when the base is non-negative. It is not a “gotcha” when either the exponent or the base is a floating point number:\nx = -3\n2.0^x\nWhen a computer is used to represent numeric values there are limitations: a computer only assigns a finite number of bits for a value. This works great in most cases, but since there are infinitely many numbers, not all possible numbers can be represented on the computer.\n\nThe first limitation is numbers can not be arbitrarily large.\n\nTake for instance a 64-bit integer. A bit is just a place in computer memory to hold a \\(0\\) or a \\(1\\). Basically one bit is used to record the sign of the number and the remaining 63 to represent the numbers. This leaves the following range for such integers \\(-2^{63}\\) to \\(2^{63} - 1\\).\nJulia is said to not provide training wheels. This means it doesn’t put in checks for integer overflow, as these can slow things down. To see what happens, let just peek:\n2^62                ## about 4.6 * 10^18\n2^63                ## negative!!!\nSo if working with really large values, one must be mindful of the difference – or your bike might crash!\n\nGotchas\nLook at the output of\n2^3^4\nWhy is it 0? The value of \\(3^4=81\\) is bigger than 63, so \\(2^{81}\\) will overflow.\nThe following works though:\n2.0 ^ 3 ^ 4\nThis is because the value 2.0 will use floating point arithmetic which has a much wider range of values. (The Julia documentation sends you to this interesting blog post johndcook, which indicates the largest floating point value is \\(2^{1023}(2 - 2^{-52})\\) which is roughly 1.8e308.\n\nScientific notation is used to represent many numbers\n\nA number in Julia may be represented in scientific notation. The basic canonical form is \\(a\\cdot 10^b\\), with \\(1 \\leq |a| < 10\\) and \\(b\\) is an integer. This is written in Julia as aeb where e is used to separate the value from the exponent. The value 1.8e308 means \\(1.8 \\cdot 10^{308}\\). Scientific notation makes it very easy to focus on the gross size of a number, as the exponent is set off.\n\nThe second limitation is numbers are often only an approximation.\n\nThis means expressions which are mathematically true, need not be true once approximated on the computer. For example, \\(\\sqrt{2}\\) is an irrational number, that is, its decimal representation does not repeat the way a rational number does. Hence it is impossible to store on the computer an exact representation, at some level there is a truncation or round off. This will show up when you try something like:\n2 - sqrt(2) * sqrt(2)\nThat difference of basically \\(10^{-16}\\) is roughly the machine tolerance when representing a number. (One way to imagine this is mathematically, we have two ways to write the number \\(1\\):\n\\[\n0.\\bar{9} = 0.9999... = 1\n\\]\nbut on the computer, you can’t have the “…” in a decimal expansion – it must truncate – so instead values round to something like \\(0.9999999999999999\\) or \\(1\\), with nothing in between.\n\n\nComparing values\nA typical expression in computer languages is to use == to compare the values on the left- and right-hand sides. This is not assignment, rather a question. For example:\n2 == 2\n2 == 3\nsqrt(2) * sqrt(2) == 2      ## surprising?\nThe last one would be surprising were you not paying attention to the last paragraph. Comparisons with == work well for integers and strings, but not with floating point numbers. (For these the isapprox function can be used.)\nComparisons do a promotion prior to comparing, so even though these numbers are of different types, the == operation treats them as equal:\n1 == 1.0\nThe === operator has an even more precise notion of equality:\n1 === 1.0\n\n\n\n1.6.2 Scientific notation\nAs mentioned, one can write 3e8 for \\(3 \\cdot 10^8\\), but in fact to Julia the two values 3e8 and 3*10^8 are not quite the same, as one is stored in floating point, and one as an integer. One can use 3.0 * 10.0^8 to get a floating point equivalent to 3e8.\n\nFloating point includes the special values: NaN, Inf. (Not so with integers.)\n\nFloating point contains two special values: NaN and Inf to represent “not a number” and “infinity.” These arise in some natural cases:\n1/0             ## infinity. Also -1/0.\n0/0             ## indeterminate\nThese values can come up in unexpected circumstances. For example division by \\(0\\) can occur due to round off errors:\nx = 1e-17\nx^2/(1-cos(x))          ## should be about 2\n\n\n1.6.3 Rational numbers\nIn addition to special classes for integer and floating point values, Julia has a special class for rational numbers, or ratios of integers. To distinguish between regular division and rational numbers, Julia has the // symbol to define rational numbers:\n1//2\ntypeof(1//2)\nAs you know, a rational number \\(m/n\\) can be reduced to lowest terms by factoring out common factors. Julia does this to store its rational numbers:\n2//4\nRational numbers are used typically to avoid round off error when using floating point values. This is easy to do, as Julia will convert them when needed:\n1//2 - 5//2                         ## still a rational\n1//2 - sqrt(5)/2                    ## now a floating point\nHowever, we can’t do the following, as the numerator would be non-integer when trying to make the rational number:\n(1 - sqrt(5)) // 2\n\n\n1.6.4 Complex numbers\nComplex numbers are an extension of the real numbers when the values \\(i = \\sqrt{-1}\\) is added. Complex numbers have two terms: a real and imaginary part. They are typically written as \\(a + bi\\), though the polar form \\(r\\cdot e^{i\\theta}\\) is also used. The complex numbers have the usual arithmetic operations defined for them.\nIn Julia a complex number may be constructed by the Complex function:\nz = Complex(1,2)\nWe see that Julia uses im (and not i) for the \\(i\\). It can be more direct to just use this value in constructing complex numbers:\nz = 1 + 2im\nHere we see that the usual operations can be done:\nz^2, 1/z, conj(z)\nThe value of \\(i\\) comes from taking the square root of \\(-1\\). This is almost true in Julia, but not quite. As the sqrt function will return a real value for any real input, directly trying sqrt(-1.0) will give a DomainError, as in \\(-1.0\\) is not in the domain of the function. However, the sqrt function will return complex numbers for complex inputs. So we have:\nsqrt(-1.0 + 0im)\nComplex numbers have a big role to play in higher level mathematics. In calculus, they primarily occur as roots of polynomial equation.\n\n\n1.6.5 Practice\n\nQuestion\nCompute the value of \\(2^{1023}(2 -2^{-52})\\) using 2.0 – not the integer 2:\n#| echo: false\nanswer = 2.0^1022 * 2 *(2.0 - 2.0^(-52));\nchoices = [\n\"`-Inf`\",\n\"Domain Error\",\n\"`1.7976931348623157e308`\"\n];\nanswer = 3;\nradioq(choices, answer, hint=\"You must use 2.0 -- not 2 to do this.\")\n\n\nQuestion\nThe result of sqrt(16) is\n#| echo: false\nchoices = [\n    \"An integer\",\n    \"A floating point number\",\n    \"A rational number (fraction)\"\n    ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nThe result of 16^2` is\n#| echo: false\nchoices = [\n    \"An integer\",\n    \"A floating point number\",\n    \"A rational number (fraction)\"\n    ];\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nThe result of 1/2 is\n#| echo: false\nchoices = [\n    \"An integer\",\n    \"A floating point number\",\n    \"A rational number (fraction)\"\n    ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nThe result of 2/1 is\n#| echo: false\nchoices = [\n    \"An integer\",\n    \"A floating point number\",\n    \"A rational number (fraction)\"\n    ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nWhich number is 1.23e4?\n#| echo: false\nchoices = [\n    \"1234\",\n    \"12340\",\n    \"12300\"\n    ];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion\nWhich number is -43e-2?\n#| echo: false\nchoices = [\n    \"-0.43\",\n    \"-4.30\",\n    \"-43.0\"\n    ];\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nWhat is the answer to the following:\nval = round(3.4999999999999999);\n#| echo: false\nval = round(3.4999999999999999);\nnumericq(val; hint=\"This value is indistinguishable from 3.5\")\n\n\nQuestion\nIf you need more bits, Julia provides the BigInt and BigFloat classes which give \\(256\\) bits of precision. Using this allows one to compute \\(2^3^4\\) precisely as an integer:\nx = BigInt(2)\nanswer = x^3^4\nWhat is the answer?\n#| echo: false\nchoices = [\n\"`2417851639229258349412352`\",\n\"`2.4178516392292583e24`\",\n\"`0`\"\n];\nanswer = 1;\nradioq(choices, answer)"
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "2  Functions in Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "functions.html#introduction",
    "href": "functions.html#introduction",
    "title": "2  Functions in Julia",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nWe see in this section how to easily create functions in Julia. In the following sections we begin to do things with function, such as learning how to graph functions with Julia.\nFor basic things creating a new function and plotting it is as familiar as this:\nWe begin by loading some packages:\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nThen we define a function and plot it:\nf(x) = sin(3x^2 - 2x^3)\nplot(f, 0, pi)\nReally, you’d be hard pressed to make this any shorter or more familiar. Of course, not everything is this easy so there are still things to learn, but keep in mind that 90% of what we want to do in these projects is really this straightforward.\nMathematically, a function can be viewed in many different ways. An abstract means is to think of a function as a mapping, assigning to each \\(x\\) value in the function’s domain, a corresponding \\(y\\) value in the function’s range. With computer languages, such as Julia, the same holds, though there may be more than one argument to the function and with Julia the number of arguments and type of each argument are consulted to see exactly which function is to be called.\nHere we don’t work abstractly though. For a mathematical function (real-valued function of a single variable, \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\)), we typically just have some rule for what the function will do to \\(x\\) to produce \\(y\\), such as\n\\[\nf(x) = \\sin(x) - \\cos(x).\n\\]\nIn Julia there are a few different ways to define a function, we start with the most natural one which makes it very simple to work with such functions."
  },
  {
    "objectID": "functions.html#mathematical-functions",
    "href": "functions.html#mathematical-functions",
    "title": "2  Functions in Julia",
    "section": "2.2 Mathematical functions",
    "text": "2.2 Mathematical functions\nReal-valued functions (\\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\)) are often described in terms of elementary types of functions such as polynomial, trigonometric, or exponential. We give examples of each in the following."
  },
  {
    "objectID": "functions.html#polynomials-and-related-functions",
    "href": "functions.html#polynomials-and-related-functions",
    "title": "2  Functions in Julia",
    "section": "2.3 Polynomials and related functions",
    "text": "2.3 Polynomials and related functions\nOne of the most basic families of functions are the polynomial functions, which include as special cases the very familiar constant functions, linear functions and quadratic functions.\nLet’s look at the familiar linear function to convert Fahrenheit into Celsius:\n\\[\nf(x) = 5/9 \\cdot (x - 32).\n\\]\nThat is we subtract \\(32\\) then multiply by \\(5/9\\)\nWe can easily turn this into a function, simply by replacing the mathematical notation \\(\\cdot\\) with *:\nf(x) = (5/9) * (x - 32)\nThis defines a function object f. To evaluate f for a given value of \\(x\\) we simply use the familiar mathematical notation. Here we see what Celsius is for “normal” body temperature:\nf(98.6)\nAnd the Celsius equivalent to the standard boiling point:\nf(212)\n\n\n\n\n\n\nAlert\n\n\n\nCalling a function Evaluating a function for a given value is also known in programming languages as “calling” f. When we work with functions in Julia, the distinction between the function object and calling the function is important to keep straight – though not too hard to do. In mathematical notation, it is sort of like the difference between writing \\(f\\) – as opposed to \\(f(x)\\) – to describe the function, the latter implying there is some \\(x\\) to be evaluated, so we think of \\(f(x)\\) as a \\(y\\)-value and \\(f\\) as a function.\n\n\n\n2.3.1 Numeric literals\nJulia provides the familiar notation above for simple functions. In fact, for polynomials with numeric coefficients, one can even skip using * for multiplication:\ng(x) = 2x^2 - 3x + 2\ng(2)\nThe convention is that when variables are immediately preceded by a numeric literal (and by immediately it is meant no spaces are in between) Julia will assume multiplication is intended. (This can bypass the usual order of operations, e.g. 5/9(x-32) is not 5/9*(x-32).)\nThis can also be used when simple parentheses are involved:\nk(x) = 2(x - 1)^2 + 3(x+1)\nBut won’t work with expressions such as (x+1)(x-1), as Julia will then think the first parenthetical pair is a function and try to call it with a value of x-1.\n\nExample: Equations versus functions\nMathematically we tend to blur the distinction between the equation\n\\[\ny = 5/9 \\cdot (x - 32)\n\\]\nand the function\n\\[\nf(x) = 5/9 \\cdot (x - 32)\n\\]\nAs the graph of the function \\(f(x)\\) is the same as the graph of the equation \\(y=f(x)\\). There is a distinction in Julia as these commands\nx = -40\ny = 5/9 * (x - 32)\nwill evaluate the righthand side with the value of x bound at the time of assignment to y, whereas\nf(x) = 5/9 * (x - 32)\nf(72)               ## room temperature\nwill create a function which is called with a value of x at a later time. So the value of x defined when the function is created is not important here (as x is passed in as an argument).\n\n\n\n2.3.2 Rational functions\nRational functions are simply ratios of polynomial functions. Defining them is straightforward. For example.\n\\[\nf(x) = \\frac{x^2 - 2}{x - 2}\n\\]\nbecomes\nf(x) = (x^2 - 2)/(x-2)\nHere, as with your calculator, it is important to remember to use parentheses around the top and bottom expressions, as otherwise the division operator will have higher precedence than the subtraction operators.\n\n\n2.3.3 Other powers\nWhile polynomials use non-negative integer coefficients for the powers, functions with other powers are, of course, possible. The ^ operator is used in general for powers, and the sqrt and cbrt offer an alternative.\nSo, this\n\\[\nf(x) = \\sqrt{x} + x^{1/3} + x^{1/4}\n\\]\ncan become:\nf(x) = sqrt(x) + cbrt(x) + x^(1/4)\nFor the fractional power, this shows the required parentheses around (1/4) to ensure that division occurs before the higher-precedence power operation (compare 2^1/4 to 2^(1/4))."
  },
  {
    "objectID": "functions.html#common-functions",
    "href": "functions.html#common-functions",
    "title": "2  Functions in Julia",
    "section": "2.4 Common functions",
    "text": "2.4 Common functions\nOf course Julia has readily available all the usual built-in functions found on a scientific calculator, and many more. See the section on mathematical operations and functions of the official Julia documentation. In the following, we show how to translate some basic math functions into Julia functions:\n\n2.4.1 Trigonometric functions\n\\[\nf(x) = \\cos(x) - \\sin^2(x)\n\\]\nbecomes\nf(x) = cos(x) - sin(x)^2\n\n\n\n\n\n\nAbout exponents and functions…\n\n\n\nThe conversion from the commonly written form (\\(\\sin^2(x)\\)) to the far less ambiguous \\(\\sin(x)^2\\) is very important. This is necessary with Julia – as it is with calculators – as there is no function sin^2. In Julia, squaring is done on values – not functions, like sin. (And most likely squaring of a function is more likely to be composition, which is not the usage here.) So, to have success, learn to drop the notations \\(\\sin^2(x)\\) or for the arc sine function \\(\\sin^{-1}(x)\\). These shortcuts are best left in the age when mathematics was done just on paper.\n\n\n\nIf you want to work in degrees you can do so with the degree-based trigonometric functions, which follow the same naming pattern save a trailing “d”:\nfd(x) = cosd(x) - sind(x)^2\n\n\n2.4.2 Inverse trigonometric functions\nA mathematical definition like\n\\[\nf(x) = 2\\tan^{-1}(\\frac{\\sqrt{1 - x^2}}{1 + x})\n\\]\nbecomes\nf(x) = 2atan( sqrt(1-x^2) / (1 + x) )\nThis particular function is just an alternative expression for the arc cosine (mathematically \\(\\cos^{-1}\\) but in Julia acos) using the arctan function, as seen here:\nf(.5) - acos(.5) ## nearly 0\nThe exponent in the inverse trigonometric functions is just mathematical notation for the longer expression “arctan” or “arccos”. (It definitely is not a reciprocal.) The Julia functions – like most all computer languages – abbreviate these names to atan, acos or asin.\n\n\n2.4.3 Exponential function\nThe math function\n\\[\nf(x) = e^{-\\frac{1}{2}x^2}\n\\]\nCan be expressed as\nf(x) = e^(-(1/2)*x^2)\nThe value of \\(e\\) is built-in to Julia, but not immediately available. It is s exposed by the MTH229 package. But \\(e\\) can be inadvertently redefined. As such, it is a safer practice to use the exp function, as in:\nf(x) = exp(-(1/2)*x^2)\nThere isn’t much difference in use, but don’t try to do both at once, as in exp^(-(1/2)*x^2)!\n\n\n2.4.4 Logarithms\nThe mathematical notations for logarithms often include \\(\\ln\\) and \\(\\log\\) for natural log and log base 10. With computers, there is typically just log for natural log, or with an extra argument the logarithm to other bases.\n\\[\nf(x) = \\ln(1 - x)\n\\]\nbecomes just\nf(x) = log(1 - x)\nWhereas, the base 10 log:\n\\[\nf(x) = \\log_{10}(1 + x)\n\\]\ncan be done through:\nf(x) = log(10, 1 + x)\nwhere the first argument expresses the base. For convenience, Julia also gives the functions log10 and log2 for base 10 and 2 respectively."
  },
  {
    "objectID": "functions.html#algebra-of-functions",
    "href": "functions.html#algebra-of-functions",
    "title": "2  Functions in Julia",
    "section": "2.5 Algebra of functions",
    "text": "2.5 Algebra of functions\nIn mathematics a typical observation is to recognize some object as a combination of simpler objects. For functions, we think of combining simpler functions into more complicated ones. For example, we can think of the sum of functions, \\(h(x) = f(x) + g(x)\\). The rule for each \\(x\\) is simply to add the results of the two rules for \\(f\\) and \\(g\\) applied to \\(x\\). Notationally, we might write this as either:\n\\[\nh = f + g\n\\]\nor\n\\[\nh(x) = f(x) + g(x).\n\\]\nThe former treats \\(f\\) and \\(g\\) as function objects, the latter ties more closely to the concept of a function as a rule that operates on \\(x\\).\nWith Julia the latter representation is more useful for defining combinations of functions. For example, if \\(f(x) = \\sin(x)\\) and \\(g(x) = x^2\\), then we can combine these in several ways. The following illustrates several ways to combine the two functions \\(f\\) and \\(g\\):\nf(x) = sin(x)\ng(x) = x^2\nh(x) = f(x) + g(x)      # f + g\nh(x) = f(x) - g(x)      # f - g\nh(x) = f(x) * g(x)      # f * g\nh(x) = f(x) / g(x)      # f / g\nh(x) = f(x)^g(x)        # f^g\nAll these are based on underlying mathematical operators. In addition, for functions there is the operation of composition, where the output of one function is the input to another. For example:\nh(x) = f(g(x))          # f ∘ g or sin(x^2)\nh(x) = g(f(x))          # g ∘ f or (sin(x))^2\nThis operation is fundamentally non-commutative, as the above example illustrates.\n\n2.5.1 Practice\n\nQuestion\nWhich of these functions will compute \\(\\sin^3(x^2)\\)?\n#| echo: false\nradioq([\n\"`f(x) = sin(x^2^3)`\",\n\"`f(x) = sin(x^2)^3`\",\n\"`f(x) = sin^3(x^2)`\"\n], 2)\n\n\nQuestion\nWhich of these functions will compute\n\\[\n\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x^2}?\n\\]\n#| echo: false\nradioq([\n\"`f(x) = 1/(2pi) * exp(-(1/2)*x^2)`\",\n\"`f(x) = 1/(2pi) * exp^(-(1/2)*x^2)`\",\n\"`f(x) = 1/sqrt(2pi) *  exp(-(1/2)*x^2)`\"\n], 3)\n\n\nQuestion\nDefine the function \\(f(x) = -16x^2 + 100\\).\nIs \\(f(4)\\) positive?\n#| echo: false\nf(x) = -16x^2 + 100\nbooleanq(f(4) > 0, labels=[\"yes\", \"no\"])\n\n\nQuestion\nDefine the function \\(f(x) = x^3 - 3x + 2\\)\nWhat is the value of \\(f(10)\\)?\n#| echo: false\nf(x) =  x^3 - 3x + 2\nnumericq(f(10))\n\n\nQuestion\nDefine the function \\(f(x) = x^5 + x^4 + x^3\\)\nWhat is the value of \\(f(2)\\)?\n#| echo: false\nf(x) =  x^5 + x^4 + x^3\nnumericq(f(2))\n\n\nQuestion\nWhich of these functions will compute \\(f(x) = x^2 -2x + 1\\)?\n#| echo: false\nradioq([\n\"`f(x) = x^2 + 2*x + 1`\",\n\"`f(x) = x^2 - 2x + 1`\",\n\"`f(x) = x^2 - 2x`\"\n], 2)\n\n\nQuestion\nWhich of these functions will compute\n\\[\nf(x) = \\frac{x^2 - 2x}{x^2 - 3x}?\n\\]\n#| echo: false\nradioq([\n\"`f(x) = x^2 - 2x / x^2 - 3x`\",\n\"`f(x) = (x^2 - 2x) / x^2 - 3x`\",\n\"`f(x) = (x^2 - 2x) / (x^2 - 3x)`\"\n], 3)\nWhich of these functions will compute\n\\[\nf(x) = e^{-x} \\sin(x)?\n\\]\n#| echo: false\nradioq([\n\"`f(x) = exp(x) * sin(x)`\",\n\"`f(x) = exp(sin(x))`\",\n\"`f(x) = exp(-x) * sin(x)`\"\n], 3)"
  },
  {
    "objectID": "functions.html#multi-step-functions",
    "href": "functions.html#multi-step-functions",
    "title": "2  Functions in Julia",
    "section": "2.6 Multi-step functions",
    "text": "2.6 Multi-step functions\nIf you want to define a more complicated function, say one with a few steps to compute, an alternate form for defining a function can be used:\nfunction function_name(function_arguments)\n  ...function_body...\nend\nThe last value computed is returned unless the function_body contains a return call.\nFor example, the following is a more verbose way to define \\(f(x) = x^2\\):\nfunction f(x)\n  return(x^2)\nend\nThe line return(x^2), could have just been x^2 as it is the last (and) only line evaluated.\n\nExample: Many parts\nImagine we have a complicated function, such as:\n\\[\ng(x) = \\tan(\\theta) x + \\frac{32}{200 \\cos\\theta} x -\n    32 \\log\\left(\\frac{200 \\cos\\theta}{200\\cos\\theta - x}\\right).\n\\]\nwhere \\(k\\) is the constant 1/2 and \\(\\theta=\\pi/4\\). To avoid errors in transcribing, it can be be useful to break such definitions up into steps. Here we note the repeated use of \\(200\\cos(\\theta)\\) in the defintion of \\(g(x)\\), so we give that value the intermediate name of a\nfunction g(x)\n     theta = pi/4\n     a = 200*cos(theta)\n     tan(theta)*x + (32/a)*x - 32*log(a/(a-x))\nend\nFrom this, we can easily see that we would need to be concerned as \\(x\\) approaches the value of a, as when \\(x \\geq a\\) the logarithm won’t be defined."
  },
  {
    "objectID": "functions.html#functions-defined-by-cases",
    "href": "functions.html#functions-defined-by-cases",
    "title": "2  Functions in Julia",
    "section": "2.7 Functions defined by cases",
    "text": "2.7 Functions defined by cases\n\nExample Hockey-stick functions\nHere is a different example, where we define a “hockey stick” function, a name for functions that are flat then increase linearly after some threshold.\nAn old-school cell-phone plan might cost $30 for the first 500 minutes of calling and 25 cents per minute thereafter. Represent this as a function of the number of minutes used.\nHere we need to do one of two things depending if \\(x\\) is greater or less than \\(500\\). There are different ways to do this, here we use an if-else-end statement, which takes the following form:\nfunction cell_phone(x)\n     if x < 500\n       return(30.0)\n     else\n       return(30.0 + 0.25*(x-500))\n     end\nend\nTo see what it would cost to talk for 720 minutes in a month, we have:\ncell_phone(720)\n\n\n\n\n\n\nA subtlety\n\n\n\nWe return 30.0 above – and not the integer 30 – when \\(x<500\\) so that the function always returns a floating point value and not an integer if less than 0 and a floating point value if bigger. In general it is a good programming practice to have functions return only one type of variable for a given type of input. In this case, as the answer could be real-valued – and not just integer-valued, we want to return floating point values.\n\n\nA quick plot will show why the above function is called a “hockey stick” function:\nplot(cell_phone, 0, 1000)\nWhen functions that have different rules based on the specific value of \\(x\\) that is input, the use “cases” notation is common. For example,\n\\[\nf(x) = \\begin{cases}\n\\cos(x) & x \\geq 0\\\\\n1 - e^{-1/x^2} & \\text{otherwise}.\n\\end{cases}\n\\]\nTranslating this notation to Julia can also be done with the if-else-end construct:\nfunction f(x)\n  if x >= 0\n    cos(x)\n  else\n    1 - exp(-1/x^2)\n  end\nend\nThe expression after if is a Boolean value (a true or false value). In these examples they are generated through the Boolean operators, which include the familiar comparison symbols <, <=, ==, >=, and >. (Only == takes learning, as double equal signs are used for comparison, a single one is for assignment.)\n\n\n2.7.1 The “ternary operator”, a simple alternative to if-else-end\nOne can use the so-called ternary operator a ? b : c for simple if-else-end statements as above.\nBasically, a ? b : c is the same as the more verbose\nif a\n   b\nelse\n   c\nend\nSo the cell-phone example could have been a one-liner:\ncell_phone(x) = x < 500 ? 30.0 : 30.0 + 0.25*(x - 500)\nWhen x < 500 the expression right after ? is evaluated, and if not, the expression after : is.\nFor mathematical functions, the directness of the ternary operator usually makes it a preferred choice over if-else-end.\n\nExample: Nesting the ternary operator\nIt can be convenient to nest ternary operators. In particular, when the cases involve have more than 2 possibilities. The following does something depending on whether x is positive, negative or zero:\nheaviside(x) = x > 0 ? 1.0 : x == 0.0 ? 0.0 : -1.0\nThat is a mess to read, but easy to write. It can be made a bit clearer by using parentheses around the case where x is not greater than 0:\nheaviside(x) = x > 0 ? 1.0 : (x == 0.0 ? 0.0 : -1.0)\nSimilarly, new lines can clear up the flow:\nheaviside(x) = x > 0 ? 1.0 :\n               x == 0.0 ? 0.0 :\n               -1.0\n\n\n\n2.7.2 Practice\n\nQuestion\nWhich of these definitions will be the equivalent of \\(f(x) = |x|\\)? (The abs function is already one):\n#| echo: false\nchoices =  [\"`f(x) = x`\",\n        \"`f(x) = x > 0 ? x : 0.0`\",\n        \"`f(x) =   x > 0.0 ? x : -x`\",\n        \"`f(x) = x > 0.0 ? -x : x`\"\n         ];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion\nThe sign function returns \\(-1\\) for negative numbers \\(1\\) for positive numbers and \\(0\\) for 0. Which of these functions could do the same?\n#| echo: false\nradioq([\"`f(x) = x/x`\",\n          \"`f(x) = x/abs(x)`\",\n          \"`f(x) = x > 0 ? 1 : (x < 0 ? -1 : 0)`\"],\n          3)\n\n\nQuestion\nT-Mobile has a pay as you go cell phone plan with the following terms:\n\nYou pay 30 per month and this includes the first 1500 minutes or text messages combined.\nEach additional minute or message costs 13 cents.\n\nWhich of these functions will model this?\n#| echo: false\nradioq([\"`f(x) = x > 30   ? 13*x + 1500.0        : 30.0`\",\n          \"`f(x) = x > 1500 ? 30.0                 : 30.0 + 0.13*x`\",\n          \"`f(x) = x > 1500 ? 30.0 + 0.13*(x-1500) : 30.0`\"\n         ], 3)"
  },
  {
    "objectID": "functions.html#functions-of-multiple-arguments",
    "href": "functions.html#functions-of-multiple-arguments",
    "title": "2  Functions in Julia",
    "section": "2.8 Functions of multiple arguments",
    "text": "2.8 Functions of multiple arguments\nThe concept of a function is of much more general use than its restriction to mathematical functions of single real variable. A natural application comes from describing basic properties of geometric objects. The following function definitions likely will cause no great concern when skimmed over:\nArea(w, h) = w * h                         # of a rectangle\nVolume(r, h) = pi * r^2 * h                    # of a cylinder\nSurfaceArea(r, h) = pi * r * (r + sqrt(h^2 + r^2)) # of a right circular cone\nThe right-hand sides may or may not be familiar, but it should be reasonable to believe that if push came to shove, they could be looked up. However, the left-hand sides are subtly different – they have two arguments, not one. In Julia it is trivial to define functions with multiple arguments – we just did.\nEarlier we saw the log function can use a second argument to express the base. This function is defined by log(b, x) = log(x) / log(b). The log(x) value is the natural log, and this definition just uses the change-of-base formula for logarithms.\nBut not so fast, on the left side is a function with two arguments and on the right side the functions have one argument – yet they share the same name. How does Julia know which to use? Julia uses the number, order, and type of the arguments passed to a function to determine which function definition to use. This is technically known as multiple dispatch or polymorphism. As a feature of the language, it can be used to greatly simplify the number of functions the user must learn. The basic idea is that many functions are “generic” in that they will work for many different scenarios. For example addition. It is defined for real numbers, integers, complex numbers, … . Each definition may be different, but to the end user only the operator + need be used. The rest happens behind the scenes. As an example, to see how many different definitions (“methods”) are defined in the base Julia language for the log operator, we can execute:\nmethods(log)\nThere are many, and likely more to be added as the language matures.\n\n2.8.1 An application of composition and multiple dispatch\nJulia’s multiple dispatch allows multiple functions with the same name. The function that gets selected depends on the arguments given to the function. We can exploit this to simplify our tasks. For example, consider this optimization problem:\n\nFor all rectangles of perimeter 20, what is the one with largest area?\n\nThe start of this problem is to represent the area in terms of one variable. We see next that composition can simplify this task, which when done by hand requires a certain amount of algebra.\nRepresenting the area of a rectangle in terms of two variables is easy:\nArea(w, h) = w * h\nBut the other fact about this problem – that the perimeter is 20 – means that height depends on width. For this question, we can see that \\(P=2w + 2h\\) so that\nh(w) = (20  - 2*w)/2\nBy hand we would substitute this last expression into that for the area (to get \\(A=w\\cdot (20-2 \\cdot w)/2 = -w^2 + 10\\)) and simplify. However, within Julia we can let composition do the substitution and leave algebraic simplification for Julia to do:\nArea(w) = Area(w, h(w))\nThis might seem odd, as now we have two different but related functions named Area. Julia will decide which to use based on the number of arguments when the function is called. This allows both to be used on the same line, as above. This usage is not common with computer languages, but is a feature of Julia which is built around the concept of generic functions with multiple dispatch rules to decide which rule to call.\nFor example, the plot function expects functions of a single numeric variable. Behind the scenes, then the function A(w) will be used in this graph:\nplot(Area, 0, 10)\nFrom this, we can see that that the width yielding the maximum area is \\(w=5\\), and so \\(h=5\\) as well."
  },
  {
    "objectID": "functions.html#functions-with-parameters",
    "href": "functions.html#functions-with-parameters",
    "title": "2  Functions in Julia",
    "section": "2.9 Functions with parameters",
    "text": "2.9 Functions with parameters\nParameters and function arguments are easily confused. We will use keywords for our parameters. Keywords also allow us to specify a default value. Using a keyword is as simple as specifying the desired argument with key=value.\nA simple case is a function which computes the \\(y\\) value on a line \\(y=mx+b\\) from a given \\(x\\) value. Here \\(m\\) and \\(b\\) are parameters. We will give them a default of \\(1\\) and \\(0\\):\nmxplusb(x; m=1, b=0) = m*x + b\nThe syntax is to use a semicolon to separate regular arguments from those with keywords. This is not needed when calling the function:\nmxplusb(2)              ## 1*2 + 0, using defaults\nmxplusb(2, m=2, b=3)                ## 2*2 + 3, using passed in values\nFor a more complicated example, we revisit this function\n\\[\ng(x) = \\tan(\\theta) x + \\frac{32}{200 \\cos\\theta} x -\n     32 \\log\\left(\\frac{200 \\cos\\theta}{200\\cos\\theta - x}\\right).\n\\]\nRather than define the value of and \\(\\theta\\) outside the function, we can pass in the value for this parameter in this definition\nfunction g(x; theta=pi/4)\n     a = 200*cos(theta)\n     tan(theta)*x + (32/a)*x - 32*log(a/(a-x))\nend\nThe default means g(50, theta=pi/4) would be the same as\ng(50)\nThe parameter make it easy to look at other types of problems. For example, if the angle were less, would the value of \\(f\\) be smaller or larger?\ng(50, theta=pi/8)       ## smaller in this case.\nPassing in parameters has the big advantage of explicitly showing how Julia will find variables used within a function, as otherwise you need to have an understanding of the scoping rules in place. (Scoping rules determine where variables that are not passed in as arguments are found when referred to within a function.)\nA common pattern in the Julia ecosystem is to use two positional arguments to pass in the function value(s) and the parameter(s) (through f(x, p)). A container is typically used for each, but in this example we pass in x as a number, and use a named tuple container to pass the parameters. The unpacking of parameters can be done in different ways, here we just access the named fields using Julia’s access notation (e.g. p.b gets the value named b from the tuple):\nfunction mxplusb(x, p)\n   m, b = p.m, p.b\n   m * x + b\nend\np = (m=2, b=1)\nmxplusb(10, p)  # computes 2*10 + 1\n\n2.9.1 Practice\n\nQuestion (transformations)\nWhich of these function definitions corresponds to shifting the function f to the right by c units and up by d units with a default of \\(0\\) and \\(0\\):\n#| echo: false\nchoices = [\n    \"`g(x; c=0, d=0) = f(c * (x - d))`\",\n    \"`g(x; c=0, d=0) = c + f(x - d)`\",\n    \"`g(x; c=0, d=0) = d + f(x - c)`\",\n    \"`g(x; c=0, d=0) = c + d(f - x)`\"\n    ];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion (transformations)\nWhich of these definitions will lengthen the period of a periodic function \\(f\\) by a factor of \\(c\\), with a default of \\(1\\)?\n#| echo: false\nchoices = [\n    \"`g(x; c=1) = f(c * x))`\",\n    \"`g(x; c=1) = f(x / c)`\",\n    \"`g(x; c=1) = c + f(x)`\",\n    \"`g(x; c=1) = c * f(x)`\"\n    ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion (Wavelet transform)\nThe following transform of a function is at the core of wavelet theory:\ng(t; a=1, b=0) = (1/sqrt(a)) * f((t - b)/a)\nIf \\(f(x) = \\sin(x)/x\\) and \\(a=2\\) and \\(b=1\\) compute \\(g(0, a=2, b=1)\\).\n#| echo: false\nf(x)  = sin(x)/x;\ng(t; a=1, b=0) =  (1/sqrt(a)) * f((t - b)/a);\nval = g(0, a=2, b=1);\nnumericq(val)\n\n\nQuestion\nLet \\(g\\) be defined by:\nfunction g(x; theta=pi/4)\n     a = 200*cos(theta)\n     tan(theta)*x + (32/a)*x + 32*log((a-x)/a)\nend\nFor x in 20, 25, 30, 35, 40, 45 degrees, what value will maximize g(125, theta=x*pi/180)?\n#| echo: false\nfunction g(x; theta=pi/4)\n     a = 200*cos(theta)\n     tan(theta)*x + (32/a)*x + 32*log((a-x)/a)\nend\nx = 20:5:45;\nout = map(u -> g(125, theta=u*pi/180), x);\nanswer, ind = findmax(out)\nnumericq(x[ind])"
  },
  {
    "objectID": "functions.html#anonymous-functions",
    "href": "functions.html#anonymous-functions",
    "title": "2  Functions in Julia",
    "section": "2.10 Anonymous functions",
    "text": "2.10 Anonymous functions\nA common mathematical notation for a function that emphasizes the fact that \\(f\\) maps \\(x\\) to some value \\(y\\) involving the rule of \\(f\\) is to use an arrow as:\n\\[\nx \\rightarrow -16x^2 + 32x\n\\]\nYou can do the exact thing in Julia to create a function:\nx -> -16x^2 + 32x\nThis expression creates a function object, but since we didn’t bind it to a variable (that is, we didn’t give the function a name) it will be immediately forgotten. Such functions without a name are known as anonymous functions.\nAnonymous functions are very useful when working with functions defined by parameters as they can fix values of a parameter.\nf(x, p) = cos(x) - x/p\nfn = x -> f(x, 2)  # fn fixes p=2 (a \"closure\")\n\n2.10.1 Operators\nIn calculus an operator is some operation that takes a function and produces a different, but related function. Calculus has two main operators: the derivative and the integral, as will be discussed elsewhere.\nIn Julia it is natural to use functions which mirror mathematical operators: functions which accept other functions as inputs and can output a function. In computer science terminology, Julia treats functions like first class objects.\nThe plot function has been previously used to illustrate some examples. The basic syntax for this call is plot(f, a, b). This fits into a more general template: verb(function_object, arguments....). Other upcoming examples are a “verb” for finding derivatives and a “verb” for finding integrals.\nLet’s look at a concrete example, where it is natural to both pass in a function and return a function.\nIn a precalculus course, we learn about transwerformations of functions where we relate the function \\(g(x) = d + af(c(x-b))\\) to the function \\(f(x)\\) in terms of the parameters \\(a\\), \\(b\\), \\(c\\), and \\(d\\). Here we focus on \\(d\\) and \\(b\\) which shift up and right.\nLet’s make a function that takes \\(f\\), some specifications, and returns \\(g\\):\nfunction tform(f; shift_up=0, shift_right=0)\n  x -> shift_up + f(x - shift_right)\nend\nThis basically is \\(g(x) = d + f(x-b)\\), but with longer names. This function takes as its main argument a function (f) and returns a function. (The “arrow” in the last line is defining an anonymous function for returning.)\nHere we look at \\(1/(x-2)\\) evaluated at \\(3\\):\nf(x) = 1/x\ntf(x) = tform(f, shift_right=2)(x) ## returns a function\ntf(3)\nWe can use the output of tform directly in a function call, or make a specific version of the function, as above, by defining it for certain values of its parameters.\n\n\n2.10.2 Practice\n\nQuestion\nWhat anonymous function will create \\(\\sin(x^2)\\)?\n#| echo: false\nchoices = [\n\"`x -> sin(x)^2`\",\n\"`x -> sin(x^2)`\",\n\"`x -> sin^2(x)`\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nWhat anonymous function of \\(x\\) will return the polynomial \\(x^2 - 2x\\):\n#| echo: false\nchoices = [\n\"`x ->x^2 - 2x`\",\n\"`() -> x^2 - 2x`\",\n\"`x^2 - 2x -> x`\"\n];\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nWhat does this operator do?\nfunction secant(f, a, b)\n  m = (f(b) - f(a)) / (b-a)\n  x -> f(a) - m * (x - a)\nend\n#| echo: false\nchoices = [\n\"It computes the slope of the secant line.\",\n\"It returns a function to compute the secant line between a and b.\",\n\"It produces an error.\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nWhat does this function do?\nfunction mystery(f)\n   x -> -f(x)\nend\n#| echo: false\nchoices=[\n \"It is a mystery\",\n \"It returns a function whose graph is that of `f` reflected through the \\$x\\$ axis\",\n \"It returns a function whose graph is that of `f` reflected through the \\$y\\$ axis\"]\nanswer=2\nradioq(choices, answer)"
  },
  {
    "objectID": "functions.html#additional-details",
    "href": "functions.html#additional-details",
    "title": "2  Functions in Julia",
    "section": "2.11 Additional details",
    "text": "2.11 Additional details\nThis section presents some additional details on writing functions in Julia that are here for informational purposes only.\n\n2.11.1 Return values, tuples\nAs mentioned, the value returned by a function is either the last value executed or any value returned by return. For a typical real valued function \\(f\\) this is usually just a number. Sometimes it is convenient to return more than one value. For this a tuple proves useful:\nA tuple is a container for holding different objects at once. They are made quite simply by enclosing the values in parentheses:\n(1, \"one\")\nTuples have many uses, but here we want to focus on their use as return values. Here is a somewhat contrived example. Imagine you write a function to compute the value of \\(f(x) = x^x\\), but you want to ensure \\(x\\) is positive, as otherwise there will be an error. You can do this, where we return a value of NaN and a message when the user tries to use a negative number:\nf(x) = x > 0 ?  (x^x, \"\") : (NaN, \"You can't use non-positive numbers\")\nWe include a message even when the value of \\(x\\) is okay, as it is good practice –though not a requirement of Julia – to always return the same type of object, regardless the input.\nA simple call would be:\nf(-1)\nWe get a tuple back. Julia makes working with tuple return values very easy. We can destructure them by simply placing two variable names on the left-hand side:\na, msg = f(-1)          # alternatively: (a, b) = f(-1)\nA less artificial example will be discussed later: the quadgk function which estimates the value of an integral. For this computation both the value and an estimated maximum error are of interest, so both are returned as a tuple.\n\n\n2.11.2 Specializing functions by argument type\nTypical functions here are real-valued functions of a single variable. The easiest way to use these is to just mimic the regular mathematical notation as much as possible. However, there are times where we want to be specific about what possible values a user can place into a function. For example, a naive function to compute the binomial coefficients,\n\\[\n{ n \\choose k } = \\frac{n!}{(n-k)! k!},\n\\]\ncan be specialized to just integer values with:\nbinom(n::Integer, k::Integer) = factorial(n)/(factorial(n-k) * factorial(k))\nThe extra bit ::Integer specializes n and k so that this function only is called with both n and k are of this type.\nThen we can call our binom function as:\nbinom(10,4)\nBut not as follows, as \\(\\pi\\) is not an integer:\nbinom(10, pi)\n(The actual binomial function is much better than this, as it doesn’t divide a big number by a big number, which can cause real issues with loss of precision, though it does specialize to integers, and any sub-type. It also always returns an integer, whereas ours returns a floating-point value.)\nTypes in Julia are a more complicated matter than we want to get into here, but we do want to list the common types useful for basic calculus: Function, Real, Integer, Rational, Complex, and Number (real or complex).\nClearly the latter ones should nest, in that an object of type Integer should also be of type Real. This means when we specialize a mathematical function, it is enough to specify values of Real.\n\n\n2.11.3 Generic and anonymous functions\nIn Julia there are really two types of functions: generic functions and anonymous functions. A generic function is created when we use this form to create a function:\ng1(x) = sin(3x^2 - 2x^3)\nAn anonymous function is made when we do something like\ng2 = x -> sin(3x^2 - 2x^3)\nFor the most part the end user can’t tell the difference:\n(g1(1), g2(1))\nBut, there are times when there can be a conflict, in particular when you try to redefine a generic function as an anonymous function:\ng2 = x -> sin(2x^2)\nOr vice versa. Basically, Julia has assigned a certain function type to that name and you can’t change that type though you can change the function’s definition. (This is one exception to the “dynamic” aspect of Julia.)\nWe use the generic function approach in these notes to define our named functions, as the basic notation so closely mirrors the standard math notation."
  },
  {
    "objectID": "graphing.html",
    "href": "graphing.html",
    "title": "3  Graphing functions with Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "graphing.html#introduction",
    "href": "graphing.html#introduction",
    "title": "3  Graphing functions with Julia",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThe Julia language is a new language and as such, certain design decisions are still being made. One key decision is the interface for creating graphics. At this point there are many different ones (Makie, PyPlot, plotly, plotlyjs, GR, Winston, Gadfly, Gaston,…), and perhaps more will be generated before a dominant one is arrived at. As such, we don’t try to teach the details of any one of them.\nCurrently, the the Plots package provides a unified interface to many backend plotting packages. We will use the Plots package in these examples.\nFor the impatient, this is all that is needed to know to get up and running.\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings\nThen, graphing a function is as easy as specifying the function and the domain to graph over, e.g.:\nf(x) = exp(-x^2/2)\nplot(f, -3, 3)          # plot f over [-3,3]\n\n\n\n\n\n\nplotly\n\n\n\nThe default graphics of Plots are static. Adding one additional call, plotly(). will use an interactive backend for Plots which will show the (x,y) position of points on the graph when a mouse hovers over them. (The default can be re-loaded by the command: gr().)\n\n\nGraphs can be layered by using the plot! function (with an exclamation point indicating a current graph is begin modified):\nf(x) = cos(x)\ng(x) = 1 - x^2/2\nplot(f, -pi/2, pi/2)\nplot!(g)        #  the domain to plot is optional if adding a layer\nFor the more patient, the rest of the sections cover some additional details including how to specify a graph by defining the points that are used to make the plot."
  },
  {
    "objectID": "graphing.html#the-plot-function",
    "href": "graphing.html#the-plot-function",
    "title": "3  Graphing functions with Julia",
    "section": "3.2 The plot function",
    "text": "3.2 The plot function\nThe most basic usage for plotting a function follows this pattern:\n#| eval: false\nplot(function_object, from, to)     # or plot(f, a, b)\nas in\nplot(sin, 0, 2pi)\nThat creates the graphic. The Plots package is an interface to several plotting “backends.” Within IJulia and using plotly() the graph will be automatically displayed as an SVG graphic that allows you to zoom and pan with the mouse.\n\n\n\n\n\n\nAlert\n\n\n\nThis is another example of a general template action(function_object, args…) for performing some action on a function. In this case, the action is to plot a function and the additional args… indicate the domain to plot over.)\n\n\nAgain, we plot a function, this time a basic polynomial:\nf(x) = x^2 - 2x + 2\nplot(f, -3, 3)\n\n3.2.1 Adding layers using “plot!”\nA graph can have layers added to it using plot! or other such functions. For example, adding the function zero will emphasize the x axis:\nf(x) = x^2 - 2x + 2\nplot(f, -3, 3)\nplot!(zero)     # x axis\nThe automatic legend can be supressed by passing the argument legend=false to the initial plot command.\nAdding points can be done with the scatter! command. We put the x and y values into containers defined by []. For example, the polynomial \\(x^2 - 3x +2\\) has roots at \\(2\\) and \\(1\\), we emphasize this through:\nf(x) = x^2 - 3x + 2\nrts = [1, 2]\nplot(f, 0, 3)\nscatter!(rts, [0, 0])\n\n\n3.2.2 Inf, NaN values\nPlots plots functions by creating a large number of paired points \\((x, f(x))\\); it then plots these points; and, finally, connects the points with line segments. In the numerous function evaluations, it is of course quite possible that some of the points will return Inf or NaN. (Where Inf is a floating point value for infinity and results from evaluations like 1/0 and NaN stands for “not a number”, and results from indeterminate evaluations such as 0/0.)\nThe values which are Inf can not reasonably be plotted. Values which are NaN can not reasonably plotted. What to do? Such points are simply not plotted, and no line segments are drawn causing the plot to be discontinuous. This convention can be utilized to good effect.\nFor example, to create bounded graphs, we can trim out any large values and replace them with NaN. A function that can be used to modify an arbitrary function (like \\(f(x) = 1/x\\)) and return a function that can be plotted can be defined as follows:\ntrim(f; val=10) = x -> abs(f(x)) > val ? NaN : f(x)\nThis action is very similar to clamping.\nThe MTH229 package implements this in the function rangeclamp(f, hi=20, lo=-hi). (Base julia has a clamp function.)\nUsing rangeclamp is fairly simple. The output is a function, so can be passed directly to the plot call:\nf(x) = 1/x\nplot(rangeclamp(f), -3, 3)\nOr\nplot(rangeclamp(f, 100), -3, 3)\nThis trimming also works when Inf and -Inf values are encountered, as both can be ordered by >.\n\n\n3.2.3 Plotting with anonymous functions\nConsider a function with a parameter, theta, defined by:\nfunction g(x; theta=pi/4)\n     a = 200*cos(theta)\n     tan(theta)*x + (32/a)*x - 32*log(a/(a-x))\nend\nPlotting g will use the default value of \\(\\pi/4\\). To plot with a different value, say \\(\\pi/3\\) we can create a new function:\nf(x) = g(x, theta=pi/3)\nplot(f, 0, 100)\nWhich works, but is a bit verbose. It would be more convenient to use an anonymous function, to bypass the creation of a throwaway function:\nplot(x -> g(x, theta=pi/3), 0, 100)\nThere are many instances where plotting with anonymous functions are convenient. It can be hard to get used to seeing that arrow, but it can simplify many expressions if used properly.\n\n\n3.2.4 Practice\n\nQuestion\nPlot the function \\(f(x) = x^3 - x\\) over \\([-2,2]\\). How many zeros are there?\n#| echo: false\nval = 3;\nnumericq(val, 1e-16)\n\n\nQuestion\nPlot the function \\(f(x) = x^3 - x\\). When is the function positive?\n#| echo: false\nchoices = [\"`(-Inf, -1)` and `(0,1)`\",\n    \"`(-Inf, -0.577)` and `(0.577, Inf)`\",\n    \"`(-1, 0)` and `(1, Inf)`\"\n    ];\nanswer=3;\nradioq(choices, answer)\n\n\nQuestion\nPlot the function \\(f(x) = 3x^4 + 8x^3 - 18x^2\\). Where (what \\(x\\) value) is the smallest value? (That is, for which input \\(x\\) is the output :f(x) as small as possible.\n#| echo: false\nf(x) = 3x^4 + 8x^3 - 18x^2\nval = -3;\nnumericq(val, 0.25)\n\n\nQuestion\nPlot the function \\(f(x) = 3x^4 + 8x^3 - 18x^2\\). What is the smallest value?\n#| echo: false\nx = -3;\nval = f(x)\nnumericq(val, 10)\n\n\nQuestion\nPlot the function \\(f(x) = 3x^4 + 8x^3 - 18x^2\\). When is the function increasing?\n#| echo: false\nchoices = [\"`(-Inf, -3)` and `(0, 1)`\",\n    \"`(-3, 0)` and `(1, Inf)`\",\n    \"`(-Inf, -4.1)` and `(1.455, Inf)`\"\n    ];\nanswer=2;\nradioq(choices, answer)"
  },
  {
    "objectID": "graphing.html#asymptotes",
    "href": "graphing.html#asymptotes",
    "title": "3  Graphing functions with Julia",
    "section": "3.3 Asymptotes",
    "text": "3.3 Asymptotes\nA rational function is nothing more than a ratio of polynomial functions, say \\(f(x) = p(x)/q(x)\\). One interesting thing about such function is there can be asymptotes. These can be vertical (which can happen when \\(q(x)=0\\)), horizontal (as \\(x\\) gets large or small), or even slanted.\nThe vertical asymptotes require care when plotting, as the naive style of plotting where a collection of points is connected by straight lines can render poor graphs when the scale of \\(y\\) values get too large. The really large values plotted near the asymptote can wipe out the possibility of seeing other features of interest in a graph.\nSome features of interest for a graph that are identifiable by calculus concepts are:\n\nzeroes\nvertical asymptotes\nhorizontal asymptotes (or even slant ones)\nrelative maximum and minimum\nincreasing and decreasing parts\nchanges in inflection\n\nFor example, if you want to find zeroes of a function, you really want to look at areas of the graph where the \\(y\\) values are close to \\(0\\). However, if you have a vertical asymptote on the same graph, the \\(y\\) values might also be asked to show very large or small values. With only a finite number of pixels available, it is impossible to easily do both.\nWhat to do? If you were on a smartphone, you might be tempted to pan around to avoid the asymptotes, then pinch and zoom narrow the graph to the feature of interest. With julia you basically do the same thing, though panning and zooming is done by changing the domain of the \\(x\\) values used in plotting.\nLet’s look at the function \\(f(x) = 1/x\\), which has an obvious vertical asymptote at \\(0\\).\nOne can try a simple plot:\nplot(x -> 1/x, -3, 3)\nThe issue at \\(0\\) is avoided, as the points chosen by Plots do not include \\(0\\). The asymptote appears as a strongly slanted line, as individual points are simply connected in a dot-to-dot manner.\nDoing better without much work is done by simply restricting the part that is plotted. (Alternatively, you can use NaN values or multiple functions on one.) For this example, we can easily draw the positive part:\nplot(x -> 1/x, 0, 3)\nIt is best to avoid the asymptote at \\(0\\) completely by backing away by enough to avoid the large range on the \\(y\\) axis. In this case, starting around \\(1/10\\) is reasonable:\nplot(x -> 1/x, 1/10,  3)\nLet’s look at the rational function\n\\[\nf(x) = \\frac{(x-2)(x-3)}{x-1}\n\\]\nThis will have a vertical asymptote at \\(1\\), zeros at \\(2\\) and \\(3\\) and a slant asymptote. A quick graph from \\(-10\\) to \\(10\\) shows just some of this:\nf(x) = (x-2)*(x-3)/(x-1)\nplot(f, -10, 10)\nWe can see the slant asymptote and the vertical asymptote, but have no chance of seeing the zeros or the local extrema. For that, we can restrict the domain to plot over.\nFor example, to graph to the right of the asymptote can be done with:\nplot(f, 1 + 0.5, 4)\nThis shows the two zeros and gives an idea of the relative minimum. Similarly, a plot of the left of the asymptote can be illustrative. Here we step back by a bit:\nplot(f, -3, 1 - 0.1)\nIt appears that the relative maximum occurs between \\(-1\\) and \\(0\\).\nHere we see what happens to the asymptote. The scale of the \\(y\\) values is huge. We added a small amount to the left endpoint in case the function is not defined there, but this function takes the reciprocal of a small amount and makes it huge. Clearly we need to really avoid the issue. It isn’t hard – just add a little bit more to \\(0\\).\nOne solution to avoiding this issue is to use the rangeclamp function that was previously described. This just caps off really large values so that the vertical asymptotes don’t affect the scale of the graph. We can see the asymptotes pretty clearly with:\nplot(rangeclamp(f), -10, 10)\n\nExample Trigonometric functions\nLet\n\\[\nf(x) = \\frac{5}{\\cos x} + \\frac{10}{\\sin x}.\n\\]\nEstimate graphically the minimum value over \\((0, \\pi/2)\\).\nThe domain comes from the fact that \\(\\sin(0) = 0\\) and \\(\\cos(\\pi/2) = 0\\), so we will have asymptotes at each. A simple graph shows there are issues:\nf(x) = 5/cos(x) + 10/sin(x)\nplot(f, 0, pi/2)\nAs typical with vertical asymptotes, we can’t see finer features of the graph when the asymptotes are drawn. To remedy, we again back off from the boundaries. Since \\(\\sin(x)\\) behaves like \\(x\\) near \\(0\\), we pick delta = 0.3 again and expect a max near \\(10/(3/10) \\approx 33\\).\ndelta = 0.3;\nplot(f, 0 + delta, pi/2 - delta)\nWith this, we see the minimum value is near \\(y=20\\) and occurs around \\(0.9\\).\n\n\n3.3.1 Practice\n\nQuestion\nThe function \\(f(x) = (x^3 - 2x) / (2x^2 -10)\\) is a rational function with issues when \\(2x^2 = 10\\), or \\(x = -\\sqrt{5}\\) or \\(\\sqrt{5}\\).\nPlot this function from \\(-5\\) to \\(5\\). How many times does it cross the \\(x\\) axis?\nval = 3;\nnumericq(val, .2)\n\n\nQuestion\nThe function \\(f(x) = (x^3 - 2x) / (2x^2 -10)\\) has a slant asymptote. One can find the slope of this line using algebra, but if you prefer the computer, you can graph. Define both\nf(x) = (x^3 - 2x) / (2x^2 -10)\ng(x) = abs(x) > 5 ? f(x) : NaN\nthen plot g over \\([-20, 20]\\). Using algebra or this graph, estimate the slope?\n#| echo: false\nval = 1/2;\nnumericq(val, 5e-1)\n\n\nQuestion\nThe rational function \\(f(x) = (x^2 - 3x - 2) / (x^2 - 4)\\) has issues at \\(-2\\) and \\(2\\). How many times does its graph cross the \\(x\\) axis?\nval = 2;\nnumericq(val, 1e-16)"
  },
  {
    "objectID": "graphing.html#arrays",
    "href": "graphing.html#arrays",
    "title": "3  Graphing functions with Julia",
    "section": "3.4 Arrays",
    "text": "3.4 Arrays\nWhen we learn how to make a graph using paper and pencil, the “T” method is employed, so called as we draw a “T” and fill in values to plot for \\(x\\) and \\(y\\).\nFor example, a chalkboard after the instructor shows how to plot \\(f(x) = x^2\\) might have this drawn on it:\n#| eval: false\nx |  y\n------\n1 |  1\n2 |  4\n3 |  9\n4 | 16\nAs these are the steps done to create the ordered pairs for a plot, we would like to be able to mimic the following procedures used above in julia:\n\nchoose a collection of \\(x\\) values\ncreate the corresponding \\(y\\) values\nplot the pairs \\((x,y)\\) and connect with lines\n\nWe have seen how variables can be used to refer to a single value, but we want to refer to more than one value now. A container for holding such is an Array. Arrays are implemented in most all computer languages, though the term can mean different things. We are looking for vectors, or one-dimensional arrays. In general, an array is a multidimensional grid of values – all of the same type (integer, floating point, functions, …, or ANY).\nFor our purposes, we want vectors (one dimensional, \\(n\\) by 1 arrays in julia). These can be easily constructed in different ways.\n\n3.4.1 Creating 1-dimensional arrays with []\nIn many different contexts, julia uses [] to create collections from individual components.\nFor example, to directly create a 1-dimensional array with the [] syntax one simply types in the values separated by commas:\n[1, 2, 3, 4, 5]\nOr\n[1, 1, 2, 3, 5, 8]\nThese create “vectors.” Row vectors (which are arrays, but not of type Vector) are created when no commas are specified:\n[13 21 34 55]\nThe notation is that [a, b, c] combines a, b, and c vertically and [a b c] combines them horizontally. The former is good to make column vectors for single values (scalars).\nRow and column vectors are different! We will primarily use column vectors going forward.\nContainers are for like values…\nIn general, julia uses [ and ] to create containers for like values. These containers can be more complicated than a single row or column. One subtle thing is that each object must be of the same value, though sometimes this happens by a silent conversion. So, mixing integer and floating point numbers will produce a container of just floating point values:\n[1, 2.0]\n\n\n3.4.2 Creating arithmetic sequences\nA basic set of numbers used in programming are the values 1,2, …, n. These are the simplest example of an arithmetic progression or sequence, which in general can start in a different place and have steps of a size different from \\(1\\):\n\\[\na, a + h, a+2h, a+3h, ..., a + nh\n\\]\nIt should be possible to specify arithmetic sequences either by\n\nthe start and end points and the number of points employed\nthe start and end points and step size.\n\nIn julia the range function will do the former and the range operator the latter.\nHere are 5 evenly spaced numbers from \\(0\\) to \\(\\pi/2\\) given by range\nrange(0, pi/2, length=5)\nThe values are not displayed, but will be if collected:\ncollect(range(0, pi/2, length=5))\n\n\n3.4.3 The range operator\nThe “range” operator, :, is used to specify a step size, like \\(h\\) in the definition above. To get values which step by 1 we simply specify the start and end values:\n1:4\nThat isn’t so impressive. The description julia uses to show this value is exactly how we defined it, but this range is specifying the values 1, 2, 3, 4. To see that, we collect the values to make an array:\ncollect(1:4)\nThe range operator returns a Range object which is much more compact to store than the array. (The range object is an iterator, something to be stepped through one at a time. Iterating over the elements specified by a range does not require all the elements at once, so they are not generated.)\nThe range operator can also work with a step size:\na=0; b=10; h=3\na:h:b\ncollect(a:h:b)\nNotice, the value for b is treated as as suggestion, the range will stop without exceeding b.\nThe \\(x\\) values for a plot are typically a sequence of increasing values from \\(a\\) to \\(b\\). We would generally like to be able to specify the number of values to plot. This makes range the go-to choice to use.\n\n\n3.4.4 Practice\n\nQuestion\nWhich command will produce the sequence \\(1,3,5,7,9,11, ..., 99\\)?\n#| echo: false\nchoices=[\"`range(1, 99, length=2)`\",\n       \"`[1,3,5,7,9,11, ..., 99]`\",\n       \"`1:2:99`\",\n       \"`1:99`\"];\nanswer=3;\nradioq(choices, answer)\n\n\nQuestion\nWhich command produces 10 numbers between 0 and 10 that are evenly spaced?\n#| echo: false\nchoices=[\n\"`range(0, 10, length=10)`\",\n\"`0:10`\",\n\"`0:1:101`\",\n\"`[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`\"\n];\nanswer=1;\nradioq(choices, answer)\n\n\nQuestion\nWhich command does not produce the numbers \\(1, 2, 3, 4, 5\\)?\n#| echo: false\nchoices=[\n\"`range(1, 5, length=5)`\",\n\"`[1, 2, 3, 4, 5]`\",\n\"`1:5`\",\n\"`1:5:1`\"\n];\nanswer=4;\nradioq(choices, answer)\n\n\nQuestion\nWhich command does produces the numbers \\(1, 1, 2, 3, 5, 8, 13\\)?\n#| echo: false\nchoices=[\n\"`[1,1,2,3,5,8,13]`\",\n\"`1:2:13`\",\n\"`range(1, 13, length=7)`\",\n\"`[0, 1, 1, 2, 3, 5]`\"\n];\nanswer=1;\nradioq(choices, answer)"
  },
  {
    "objectID": "graphing.html#indexing",
    "href": "graphing.html#indexing",
    "title": "3  Graphing functions with Julia",
    "section": "3.5 Indexing",
    "text": "3.5 Indexing\nA column vector has a natural sense of first, second, …, the \\(n\\)-th element. This allows julia to refer to the values by index (\\(1\\)-based, unlike some other computer languages). So, if x is an array, x[1] is the first value in that array. One can extract and assign values using indices. A simple example is:\nx = [2, 3, 5, 7, 11, 13, 17]\nx[1]\nx[3]\nThere are some special values. The end value refers to the last (\\(n\\) th):\nx[end]\nThe \\(n\\) – or number of elements – can be returned by length:\nlength(x)\nA range object can be used for indices:\nx[1:3]\nThe value end can be used in a range when indexing:\nx[2:end]\n(But not without indexing, as you can see by typing 2:end by itself.)\n\n\n\n\n\n\nLeft side of an equals sign\n\n\n\nJulia allows only three different types of expressions on the left side of an equals sign:\n\na variable name, as in x = 42,\na function definition, as in f(x) = x^2 - 2, or\na assignment setting an index, as in x[1] = 2.\n\nThe left side is quite unlike a math equation, where arbitrary expressions are typical.\n\n\n\n3.5.1 Practice\n\nQuestion\nLet\nx = [1, 1, 2, 3, 5, 8, 13]\nWhat is the value of x[end - 1] + x[end]?\n#| echo: false\nval = x[end - 1] + x[end];\nnumericq(val, 1e-16)\n\n\nQuestion\nLet\nx = [1, 1, 2, 3, 5, 8, 13]\nWhat is the value of x[3]?\n#| echo: false\nval = x[3];\nnumericq(val, 1e-16)\n\n\nQuestion\nWhen a vector is created, if possible, the resulting values are converted to be the same type. Let\nx = [1, 2.0]\ny = [1, 2.0, \"three\"]\nFor x[1] and y[1] what does typeof return?\n#| echo: false\nchoices = [\"(Float, Integer)\",\n    \"(Integer, Integer)\",\n    \"(Integer, ASCIIString)\"\n    ];\nanswer = 1;\nradioq(choices, answer)\n(The y container is of type Any which allows it to hold any type of object, the x container only holds values of a certain type.)"
  },
  {
    "objectID": "graphing.html#mapping-a-function-to-multiple-values",
    "href": "graphing.html#mapping-a-function-to-multiple-values",
    "title": "3  Graphing functions with Julia",
    "section": "3.6 Mapping a function to multiple values",
    "text": "3.6 Mapping a function to multiple values\nTo specify the \\(y\\) values we wish to “map” the function f to each \\(x\\) value. In julia there are many different ways to do this, we list four for completeness, but will restrict our attention to just the first three styles.\n\n3.6.1 The map function\nThe map function. In many areas of mathematics, one refers to a function as a “map” from the domain to the range. The implication is that the function takes all the \\(x\\) values to the corresponding \\(y\\) values at once (conceptually) and not one at a time. The map function will apply the function f to each value in the array x, basically taking [x1, x2, ..., xn] and returning [f(x1), f(x2), ..., f(xn)].\nFor example, let’s look at the simple polynomial \\(f(x) = -16x^2 + 32x\\). We define our julia function with:\nf(x) = -16x^2 + 32x\nIf we want to look at this function for \\(x\\) values between \\(0\\) and \\(2\\) we might define the \\(x\\) values with:\nx = range(0, 2, length=5)\nThen the map function will create the corresponding \\(y\\) values:\nmap(f, x)\nThe syntax of map requires a slight pause. Here we do not actually call the function f, as in f(2). Rather, we pass the name of the function object to the map argument – and map calls the function for each value in the column vector x and returns a corresponding column vector.\nIt is also quite common to use anonymous functions with map. For example:\nmap(u -> 10 * u^2, x)\nWe use u for the dummy variable in the anonymous function, so as not to get it confused with the variable x holding our values, but this is not necessary.\n\n\n3.6.2 Broadcasting\nJulia allows a function to be broadcast over a collection of values with a simple notational trick or inserting a “.” before the parenthesis. To see, we have:\nsin.([1,2,3])\nIn this use, the output is the same as though map(sin, [1,2,3]) were called. In general, this “.” notation is a bit different, as there can be multiple arguments passed and the size of the values is matched if possible by replication. For example, this command find the logarithm of 5 for different bases. The value 5 is replicated once for each of the bases:\nlog.([2,pi,5,10], 5)\n\n\n\n\n\n\nNote\n\n\n\nThe “dot” broadcasting is very succinct and useful, but using map is more explicit and easier to reason about. We will mostly use broadcasting due to the simplicity.\n\n\n\n\n3.6.3 Comprehensions\nMathematicians are fond of set notation, as in this way to describe the \\(y\\) values in a graph:\n\\[\ny = \\{ f(x): x \\text{ in } [0, 2] \\},\n\\]\nThis is read: “the values \\(f(x)\\) for each \\(x\\) in the interval \\([0,2]\\).”\nHere we define values xs to represent the continuum of values in the interval \\([0,2]\\), then use a “comprehension” to create the set notation above. The syntax is similar:\nxs = range(0, 2.0, length=5)\n[f(x) for x in xs]\nThe two approaches, broadcasting/maps and comprehensions, are equally useful. Perhaps map is a bit less trouble, but comprehensions mirror a more familiar mathematical syntax and generalize to functions of more than one variable nicely. One difference to keep in mind when deciding which to use, is that broadcasting/mapping requires a function, whereas comprehensions use expressions.\n\n\n3.6.4 For loops\nFinally, for completeness, we mention another means to generate vectors of numbers that is more familiar to users of other computer languages.\nThe for loop is a very common pattern in computer programming. For speed reasons, some languages (e.g., MATLAB and R) try to avoid for loops for a “vectorized” approach (see below), but julia works well with for loops, and they are sometimes easier to understand than a vectorized approach.\nA for loop simply loops over each value in the iterable data vector x giving it a temporary name as it goes. To use a for loop to create the \\(y\\) values requires several steps. The first creates a container to hold the new values, using the similar function to make a vector of the same size as x below (but fills it with nonsense):\ny = similar(x);\nfor i in 1:length(x)\n   y[i] = f( x[i] )\nend\nThe for loop ends with the keyword end. Here we loop over each index of x and assign to the corresponding y value f(x[i]).\nConceptually this is the opposite of map where we think of the function acting on the entire column vector x. Instead, we iterate one-by-one over the values of x saving the function values as we go. The use of for loops is called imperative programming, as you describe each step. The use of functions like map is called declarative programming as you simply declare what you want and the computer language does the rest.\nIn some languages for loops are avoided if possible, as they can be slower. As well, they can require extra bookkeeping, such as needing to allocate a container for the answers. That being said, in julia they are widely used for speed and storage reasons. As well, they are used when we need to refer to more than one index. An example of that is the following way to create a Fibonacci pattern from the formula \\(x_i = x_{i-1} + x_{i-2}\\):\nx = zeros(Int, 10);         ## pre-allocate an integer array\nx[1:2] = [1,1]\nfor i in 3:length(x)\n   x[i] =  x[i-1] + x[i-2]\nend\nRelated to a for loop is the while loop. This will repeat as long as some condition is true. The following pattern reproduces a for loop:\n#| eval: false\ni, n = 1, length(x)\nwhile (i <= n)\n  print( x[i], \" \" )            ## do something ...\n  i = i + 1\nend\nWe will use while loops when we iterate some process and are waiting until some computed value gets close to \\(0\\).\n\n\n3.6.5 Example\nPutting this altogether, to create the “T”-table used to graph \\(y=x^2\\), we could do any of these:\nf(x) = x^2\nxs = 1:4\nys = map(f, xs)\n[xs ys]\nor\nf(x) = x^2\nxs = 1:4\nys = f.(xs)\n[xs ys]\nor\nxs = [1, 2, 3, 4]\nys = [x^2 for x in xs]\n[xs ys]\nor\nxs = 1:4\nys = similar(xs)\nfor i in 1:length(xs)\n    ys[i] = xs[i]^2\nend\n[xs ys]\nMany options, but the shortest to type is simply [xs f.(xs)], so that is what is used most commonly.\n\n\n3.6.6 Practice\n\nQuestions\nDoes this command produce the values \\(\\{.1, .01, .001, .0001\\}\\)?\n#| eval: false\nx = [(1/10)^i for i in 1:4]\n#| echo: false\nbooleanq(true)\n\n\nQuestions\nLet \\(f(x) = x^2 - 2x\\). Which command will produce the \\(y\\) values for plotting \\(f\\) over \\([0, 2]\\)?\n#| echo: false\nchoices=[\n\"`[f(x) for x in [0,2]]`\",\n\"`map(f(x), [0,2])`\",\n\"`f.(range(0, 2, length=100))`\"];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestions\nWill this command produce \\(y\\) values for plotting \\(f(x)\\) over \\([0,1]\\)?\n#| eval: false\nf(x) = x^2 - 2x\n[f(x) for x in 0:1/100:1];\n#| echo: false\nbooleanq(true)"
  },
  {
    "objectID": "graphing.html#graphing-points-connected-with-lines",
    "href": "graphing.html#graphing-points-connected-with-lines",
    "title": "3  Graphing functions with Julia",
    "section": "3.7 Graphing points connected with lines",
    "text": "3.7 Graphing points connected with lines\nIf one has two vectors xvals and yvals of equal size then creating a graphic for them is straightforward. The basic syntax is\n#| eval: false\nplot(xvals, yvals)\nFor example, to plot \\(y=x^2\\) over \\([-1,1]\\) we might do:\nf(x) = x^2\nxs = range(-1, 1, length=101)\nys = f.(xs)\nplot(xs, ys)\nOne can place both to get both points and lines. The scatter function will plot the points, but not connect the lines. In the following, the scatter! function is used. (Not the ! at the end.) This form adds the plot of the lines to the last graph, rather than make a new one.\nxs = range(-2, 2, length=5)\nys = f.(xs)\nplot(xs, ys)\nscatter!(xs, ys, markersize=5)"
  },
  {
    "objectID": "graphing.html#two-functions-at-once",
    "href": "graphing.html#two-functions-at-once",
    "title": "3  Graphing functions with Julia",
    "section": "3.8 Two functions at once",
    "text": "3.8 Two functions at once\nWe use layering to plot two or more functions at once, though there are alternatives (plotting a vector of functions will do the same).\nFor example, to graph both the sine and cosine function we have:\nplot(sin, 0, 2pi)\nplot!(cos)\nOr to compare the effects of a simple transformation:\nf(x) = x^2\ng(x) = 15 + f(x-3)\nplot(f, -10, 10)\nplot!(g)\nTo print a heavier \\(x\\)-axis, we can graph the function \\(y=0\\), specified through the anonymous function x -> 0:\nf(x) = x^2 - 2\nplot(f, -2, 2)\nplot!(x -> 0)\nThe above, may also be done with zero:\nplot(f, -2, 2)\nplot!(zero, -2, 2)   # zero is a function returning 0, useful for programming in general.\n\nExample: Operators, aka. derived functions”\nOften we wish to plot a function derived from another function. For example, this is used to add a secant line to a graph. The following function (which is in the MTH229 package) will create a function which represents the secant line of \\(f(x)\\) between two points, \\(a\\) and \\(b\\):\n#| eval: false\nfunction secant(f, a, b)\n     m =  (f(b) - f(a)) / (b-a) # slope of secant line\n     x -> f(a) + m * (x - a)\nend\nPause for a moment to see what this function does. The first line simply finds the slope between the two points \\((a,f(a))\\) and \\((b,f(b))\\). The second does something with the point-slope form of a line using the point \\((a, f(a))\\). The tricky part is that last line defines an anonymous function to be returned (the x -> part). So secant is an operator – a function which accepts a function for an argument and returns a function.\nUsing this function makes it simple to add a secant line to a graph.\nf(x) = sin(x)\na, b = 0, pi/2\nplot(f, a, b)\nplot!(secant(f, a, b))\n\n\n3.8.1 Practice\n\nQuestion\nDefine \\(f(x)\\) to be a triangular function as follows:\nf(x) = max(0, 1.0 - abs(x))\nIn many applications, the following transformation is employed:\n\\[\ng(x, c, h) = \\frac{1}{h} f(\\frac{x - c}{h})\n\\]\nFor constants \\(h\\) and \\(c\\).\nMake a graph of both \\(f(x)\\) and \\(g(x, 1, 1/2)\\) over the interval \\([-2,3]\\). Consult the graph to see which statement is true?\n#| echo: false\nchoices = [\"The graph of g is centered at c=1 and has maximum height h=1/2\",\n       \"The graph of g is centered at c=1 and has area h=1/2\",\n       \"The graph of g is centered at c=1 and has area 1/h=2\",\n       \"The graph of g is centered at c=1 and has the same area as f\"\n       ];\nanswer = 4;\nradioq(choices, answer)\n\n\nQuestion\nWe saw that this will produce two graphs:\nplot(sin, 0, 2pi)\nplot!(x -> cos(x) > 0 ? 0.0 : NaN)\nWhat is the sine curve doing when the flat line is drawn?\n#| echo: false\nchoices = [\"Oscillating: Going up and down\",\n       \"Only decreasing\",\n       \"Only increasing\",\n       \"Only concave up\"\n       ];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion\nMake a graph of \\(f(x) = x\\), \\(g(x) = \\tan(x)\\), and \\(h(x) = \\sin(x)\\). Over the interval \\([0,\\pi/4]\\). Based on this graph which of the following below seems correct?\n#| echo: false\nchoices = [\n    raw\" ``f < g < h``\",\n    raw\" ``g < f < h``\",\n    raw\" ``h < f < g``\",\n    raw\" ``h < g < f``\"];\nanswer = 3;\nradioq(choices, answer)"
  },
  {
    "objectID": "zeros.html",
    "href": "zeros.html",
    "title": "4  Solving for zeros with julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "zeros.html#introduction",
    "href": "zeros.html#introduction",
    "title": "4  Solving for zeros with julia",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nA zero of the function \\(f\\) is a value \\(x\\) with \\(f(x) = 0\\).\nSolving for zero of a function is a mathematical skill taught early on. In some cases, such as with linear equations, solving for zeros can be done directly using algebra. Similarly, in the case of factorable polynomials, we are taught to factor and then set each term to 0 to find the possible solutions, utilizing the fact that for the real numbers the product of two numbers is \\(0\\) only if one or both of the numbers is as well.\nHowever, in general, the problem of finding one (or all) solutions to the equation\n\\[\nf(x) = 0.\n\\]\nfor an arbitrary \\(f\\) has no well-defined process.\nA related problem is to find one (or all) solutions to an equation of this type:\n\\[\nf(x) = g(x)\n\\]\nConceptually this is identical to the above, as we just set \\(h(x) = f(x) - g(x)\\) and solve for when \\(h(x)\\) is \\(0\\).\nHere we discuss a few different elementary means to do find zeros with Julia, leaving some others for a later time.\nWe will use the add-on package Roots which provides implementations of a few zero- and root-finding algorithms.\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings"
  },
  {
    "objectID": "zeros.html#zeros-of-a-polynomial",
    "href": "zeros.html#zeros-of-a-polynomial",
    "title": "4  Solving for zeros with julia",
    "section": "4.2 Zeros of a polynomial",
    "text": "4.2 Zeros of a polynomial\nUnivariate polynomials are algebraic expessions involving an indeterminate. Polynomial functions are functions whose body evaluates a polynomial expression. These are special functions, in that their relatively simple form allows for many explicit things to be known. A famous example is the quadratic formula which for polynomials of degree 2 gives an explicit formula for the roots:\n\\[\n\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}.\n\\]\n\n\n\n\n\n\nAlert\n\n\n\nA “root” of a polynomial is just a polynomial-specific name for a zero of the polynomial viewed as a function.\n\n\nFor example, if we have the quadratic polynomial \\(2x^2 + 3x - 2\\) we can solve for the roots with:\na = 2; b = 3; c = -2\ndiscr = b^2 - 4*a*c\n(-b + sqrt(discr))/(2a), (-b - sqrt(discr))/(2a)\nIf you wanted to write a function to do this, it would be straightforward, save the detail of needing to make a negative number complex in order to take its square root:\n## find roots of ax^2 + bx + c\nfunction quadratic(a, b, c)\n  discr = b^2 - 4*a*c\n  sq = (discr > 0) ? sqrt(discr) : sqrt(discr + 0im)\n\n  [(-b - sq)/(2a), (-b + sq)/(2a)]\nend\n\n\n\n\n\n\nAlert\n\n\n\nThis is an example where the function is not type-stable as it returns either real-valued answers or complex-valued answers depending on the values of the input variables. In general, Julia functions avoid this behaviour, as it leads to less performant code.\n\n\nTo find the roots of \\(x^2 + x - 1\\) we could simply use:\nquadratic(1, 1, -1)\nThere are also such formula for third and fourth degree polynomials. However, Galois – at the tender age of 20 – demonstrated that, in general, there can be no such formula for the roots of a fifth or higher degree polynomial. There are still facts known about such polynomials. For example, the Fundamental theorem of algebra states that every real-valued polynomial of degree \\(n\\) will have \\(n\\) roots, where we count complex roots and multiplicities."
  },
  {
    "objectID": "zeros.html#graphical-solutions",
    "href": "zeros.html#graphical-solutions",
    "title": "4  Solving for zeros with julia",
    "section": "4.3 Graphical solutions",
    "text": "4.3 Graphical solutions\nMore generally, the equation \\(f(x) = 0\\) may not have any special form leading to a known solution. In this case, there are various techniques to find zeros. Here we mention graphing, such as is done with a graphing calculator. In the next section, we discuss the bisection algorithm for root finding.\n\nFinding a zero\nThe flight of an arrow can be modeled using various functions, depending on assumptions. Suppose an arrow is launched in the air from a height of 0 feet above the ground at an angle of \\(\\theta = \\pi/4\\). With a suitable choice for the initial velocity, a model without wind resistance for the height of the arrow at a distance \\(x\\) units away may be:\n\\[\nj(x) = \\tan(\\theta) x - (1/2) \\cdot g(\\frac{x}{v_0 \\cos\\theta})^2.\n\\]\nIn Julia we have, taking \\(v_0=200\\):\nj(x; theta=pi/4, g=32, v0=200) = tan(theta)*x - (1/2)*g*(x/(v0*cos(theta)))^2\nWith a velocity-dependent wind resistance given by \\(\\gamma\\), again with some units, a similar equation can be constructed. It takes a different form:\n\\[\ny(x) = (\\frac{g}{\\gamma v_0 \\cos(\\theta)} + \\tan(\\theta)) \\cdot x  +\n      \\frac{g}{\\gamma^2}\\log(\\frac{v_0\\cos(\\theta) - \\gamma x}{v_0\\cos(\\theta)})\n\\]\nAgain, \\(v_0\\) is the initial velocity and is taken to be \\(200\\) and \\(\\gamma\\) a resistance, which we take to be \\(1\\). With this, we have the following Julia definition (with a slight reworking of \\(\\gamma\\)):\nfunction y(x; theta=pi/4, g=32, v0=200, gamma=1)\n     a = gamma * v0 * cos(theta)\n     (g/a + tan(theta)) * x + g/gamma^2 * log((a-gamma^2 * x)/a)\nend\nFor each model, we wish to find the value of \\(x\\) after launching where the height is modeled to be 0. That is how far will the arrow travel before touching the ground?\nFor the model without wind resistance, we can graph the function easily enough. Let’s guess the distance is no more than 500 feet:\nplot(j, 0, 500)\nWell, we haven’t even seen the peak yet. Plotting over a wider interval will show that \\(1250\\) is the largest root. So we plot over this domain to visualize the flight:\nplot(j, 0, 1250)\nAs for the model with wind resistance, a quick plot over the same interval, \\([0, 1250]\\) yields:\nplot(y, 0, 1250)\nOh, “Domain Error.” Of course, when the argument to the logarithm is negative we will have issues.\nWe solve for when \\(a-\\gamma^2 x\\) is \\(0\\):\ngamma = 1\na = 200 * cos(pi/4)\nb = a/gamma^2\nWe try on the reduced interval avoiding the obvious asymptote at b by subtracting \\(1\\):\nplot(y, 0, b - 1)\nNow we can see the zero is around 140. We re-plot:\nplot(y, 135, 141)\nplot(y, 140, 141)\nplot!(zero)\nThe answer is approximately \\(140.7\\)\nFinally, we plot both graphs at once to see that it was a very windy day indeed.\nb = 140.7\nplot(j , 0, 1250)\nplot!(y, 0, b)\n\n\nExample: Finding a zero\nSometimes, the equation \\(f(x)=0\\) is actually presented as \\(h(x)= g(x)\\). This form can be rewritten as \\(f(x) = h(x) - g(x) = 0\\), or if working graphically we can just look for crossing points of the graphs of \\(g(x)\\) and \\(h(x)\\). Here we shall do that.\nWe wish to compare two trash collection plans\n\nPlan 1: You pay 47.49 plus 0.77 per bag.\nPlan 2: You pay 30.00 plus 2.00 per bag.\n\nThere are some cases where plan 1 is cheaper and some where plan 2 is. Categorize them.\nBoth plans are linear models and may be expressed in slope-intercept form:\nplan1(x) = 47.49 + 0.77x\nplan2(x) = 30.00 + 2.00x\nAssuming this is a realistic problem and an average American household might produce 10-20 bags of trash a month (yes, that seems too much!) we plot in that range:\nplot(plan1, 10, 20)\nplot!(plan2)\nWe can see the intersection point is around 14 and that if a family generates between 0-14 bags of trash per month that plan 2 would be cheaper, otherwise they should opt for plan 1.\n\n\n4.3.1 Practice\n\nQuestion\nGraphically estimate the one zero of \\(f(x) = e^x - x^3\\) over the interval \\([0,4]\\).\nval = fzero(x -> e^x - x^3, [0,4])\nnumericq(val, 1e-1)\n\n\nQuestion\nSolving equations of the type \\(f(x)=g(x)\\) for \\(x\\) can also be done graphically. One method is to plot both functions and look for crossing points. Use this approach to graphically estimate all solutions to \\(\\cos(x) = x^2\\) over the interval \\((-\\pi/2, \\pi/2)\\). What are they?\n#| echo: false\nchoices = [\"-1.57, 1.57\",\n    \"-0.82, 0.82\",\n    \"0.0\"]\nanswer = 2\nradioq(choices, answer)\n\n\nQuestion\nIn an analysis of rainbows, Airy developed a special function implemented as airyai in Julia’s SpecialFunctions package, which is loaded with the MTH229 package. The zeros of this function are all negative. The first one is between \\(-3\\) and \\(-1\\). Find it graphically.\n#| echo: false\nval = fzero(airyai, -3, -1);\nnumericq(val, 1e-1)\n\n\nQuestion\nThe polynomial \\(f(x) = x^5 - 6x^3 - 6x^2 -7x - 6\\) has three real roots. Which of the following values is one of them? Try to solve this graphically.\n#| echo: false\nusing Random\nrts =[-2, -1, 3];\nx = rts[randperm(3)[1]];\nchoices = [5, -1, 3, -2]\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nLet \\(y(x)\\) be defined as above to model the flight of an arrow. If \\(\\gamma=1/2\\) when will the arrow strike the ground after launch?\n#| echo: false\nfunction y(x; theta=pi/4, g=-32, v0=200, gamma=1)\n     a = gamma * v0 * cos(theta)\n     (g/a + tan(theta)) * x - g/gamma^2 * log((a-gamma^2 * x)/a)\nend\ngamma = 1/2\na = gamma * 200 * cos(pi/4)\nb = a/gamma^2\nval = fzero(x ->y(x, gamma=gamma), b/2)\nnumericq(val, 2)\n\n\nQuestion\nLet \\(y(x)\\) be defined as above to model the flight of an arrow. Suppose a hill is in the path of the arrow. The hill is given by this function:\nhill(x) = x > 100 ? 2.0*(x-100) : 0.0\nBy solving y(x) = hill(x) solve for how far the arrow will fly before hitting the hill.\n#| echo: false\nfunction y(x; theta=pi/4, g=-32, v0=200, gamma=1)\n     a = gamma * v0 * cos(theta)\n     (g/a + tan(theta)) * x - g/gamma^2 * log((a-gamma^2 * x)/a)\nend\nhill(x) = x > 100 ? 2.0*(x-100) : 0.0\nval = fzero(x ->y(x) - hill(x), 100)\nnumericq(val, 2)"
  },
  {
    "objectID": "zeros.html#bisection-algorithm",
    "href": "zeros.html#bisection-algorithm",
    "title": "4  Solving for zeros with julia",
    "section": "4.4 Bisection algorithm",
    "text": "4.4 Bisection algorithm\nThe last example had us graphically “zoom” in on a zero, and led us to an estimate to \\(1\\) or \\(2\\) decimal points. Trying to get more accuracy than that graphically is at best tedious. Here we discuss a method to get as much accuracy as is numerically possible based on the intermediate value theorem:\nThe intermediate value theorem: If \\(f(x)\\) is a continuous function on \\([a,b]\\) then at some point in the interval \\(f(x)\\) takes on any value between \\(f(a)\\) and \\(f(b)\\).\nIn particular if \\(f(x)\\) is continuous with \\(f(a)\\) and \\(f(b)\\) having different signs then there must be a point \\(c\\) in \\([a,b]\\) where \\(f(c) = 0\\). (When \\(f(a)\\) and \\(f(b)\\) have different signs, we say \\(a\\) and \\(b\\) bracket a root.) This observation is due to Bolzano.\nThe bisection algorithm utilizes Bolzano’s observation. It is a simple iterative procedure for finding such a value \\(c\\) when we have a continuous function and a bracketing interval.\n\n\n\n\n\n\nAlert\n\n\n\nThe bisection method does not work when the function does not cross the \\(x\\) axis at the root. For example, the zero at \\(0\\) of \\(f(x) = x^2 e^x\\) would not be found with this method.\n\n\nMathematically the basic idea is simple.\nStarting with \\([a,b]\\), the midpoint \\(M = (a + b)/2\\), is tested for its function value. If \\(f(M) = 0\\), great, we are done. If it has opposite sign of \\(f(a)\\), then a root must be in the interval \\([a,M]\\), so the problem is reduced a smaller interval. Otherwise, it has opposite sign of \\(f(b)\\) and the problem is reduced to \\([M,b]\\). Either way, the algorithm is repeated for the smaller interval where a root is known. As each step halves the interval length, it must eventually converge to an answer.\nGraphically, we could do this. For example, Let’s consider \\(f(x) = x^2 - 2\\) with the bracketing interval \\([1,2]\\). We first plot:\nf(x) = x^2 - 2\na,b = 1, 2\nplot(f, a, b)\nWe can see that \\(c = (a + b)/2 = 3/2\\) will have \\(f(c) > 0\\), so the new bracket is \\([a,c]\\):\na, b = a, (a + b)/2\nplot(f, a, b)\nNow the midpoint is negative, so we modify a:\na, b = (a + b)/2, b\nplot(f, a, b)\nAnd again, this has a midpoint in the negative territory so again we modify a:\na, b = (a + b)/2, b\nplot(f, a, b)\nAnd now, as the midpoint is in positive territory we would modify \\(b\\) …\nThis gets tedious to do graphically. But it can be easily programmed. The main step might look something like this:\nf(x) = x^2 - 2\na, b = 1, 2\n\nc = (a + b) /2\n\nif f(a) * f(c) < 0\n  a, b = a, c\nelse\n  a, b = c, b\nend\na,b\nThough some check if f(c) == 0 is also needed.\nHere \\(c=1.5\\) and the new interval is \\([1.0, 1.5]\\), as we had graphically. We just need to repeat the above.\nIt seems as though we could be here all day. Indeed, if doing this by hand it might take up quite a bit of time. We should automate this. Before automating this, we need to think: when would we stop?\nMathematically we can keep taking halves using the concept of a limit. See for example Zeno’s paradox. On a computer we don’t have such a luxury. In fact, for floating point numbers we couldn’t keep taking halves – even if we wanted – as ultimately we should expect tp get a and b being floating point values that are next to each other – and hence there is no midpoint. (Well, there are some cases that suggest a more careful numeric approach to the above.)\nSo even though this doesn’t make mathematical sense we can try stopping when the following condition is no longer true:\na < c < b\nA while loop is used to repeat the central step until the above (or some variant) is false.\nThe MTH229 package has a bisection method implemented for this which also outputs a graphical indication of the first few steps taken.\nOkay, let’s look at the function \\(f(x) = -16x^2 + 32x\\). We know that 0 and \\(2\\) are roots. Let’s see if our algorithm finds them:\nf(x) = -16x^2 + 32x\nbisection(f, -1, 1) ## should find 0\nbisection(f, 1, 3)  ## should find 2\nOkay, it seems to work. Lets try it on a less trivial problem. We know \\(\\sin(x)\\) and \\(\\cos(x)\\) cross in the interval \\([0, \\pi/2]\\). If we are too tired to remember where, we can simply ask:\nf(x) = cos(x) - sin(x)\nx = bisection(f, 0, pi/2)\nIs x really a zero?\nx, f(x)\nHmm, the answer is 1.1102230246251565e-16. So technically this is not a zero. But computationally it is a zero! First it should be clear that it is really close to zero. We will see it is as close as computationally possible to a zero.\nThe nextfloat and prevfloat functions find the floating point values just bigger than x and just smaller. In this case we have that f(x) and f(nextfloat(x)) have different signs:\nf(x),  f(nextfloat(x))\nSo \\(f\\) is crossing \\(0\\) between the value we found, x and, the floating point value just a bit bigger. We can’t realistically expect to get any closer than that, as there are no machine numbers in between these two.\n\n4.4.1 The Roots package and find_zero\nThe bisection method, while easy to describe and understand, can be made a bit more efficient. The find_zero function from the Roots package does so. This package is loaded when MTH229 is. This function uses a tuple to specify the bracketing interval. but does not need to typed in.\nFor example, to find a root of \\(f(x) = 2x \\cdot \\exp(-20) - 2 \\cdot \\exp(-20x) + 1\\) in the interval \\([0,1]\\) we have:\nusing Roots\nf(x) = 2x * exp(-20) - 2 * exp(-20x) + 1\nfind_zero(f, (0, 1))\nThe find_zero function is actually an interface to various root-finding algorithms. When called as above – with two intial starting points – it uses a bracketing approach as discussed here, though with a different notion of the midpoint.\nA slightly different interface is given by the fzero function, where that above would be:\nfzero(f, 0, 1)\n\nExample: Graphical and numerical answers\nOne needs to know where to look in order to use the bisection method. The basic “one-two punch” is:\n\ngraph the function to identify quickly values \\([a,b]\\) which bound a zero, then\nuse the bisection method to find the zero to many decimal points.\n\nHere we illustrate with the problem of finding all intersection points of \\(e^x = x^4\\) over the interval \\([0,10]\\).\nRecall, solving for \\(g(x) = h(x)\\) is identical to the problem of solving \\(f(x) = 0\\), where we define \\(f(x) = g(x) - h(x)\\). So our problem is to find solutions to \\(e^x - x^4 = 0\\).\nA quick plot shows that the function has such a wide range that looking over the entire domain at once will be problematic:\nf(x) = exp(x) - x^4\nplot(f, 0, 10)\nInstead, we look between \\([0,3]\\) and \\([8,9]\\). A quick confirmation shows these are good choices to use. For example, between \\(8\\) and \\(9\\) we have:\nplot(f, 8, 9)\nSo we find the values of the zero in the bracketed region \\([8,9]\\):\nfind_zero(f, (8, 9))\nThe root within \\([0, 3]\\) is found with:\nfind_zero(f, (0, 3))\n\n\n\n4.4.2 Problems\n\nQuestion\nIn the bisection method algorithm we checked that the value of \\(f\\) at \\(a\\) and \\(b\\) had opposite signs by looking at \\(f(a)\\cdot f(b)\\). Why did this work?\n#| echo: false\nchoices = [\"The product of two numbers is never negative\",\n       \"The product of 2 numbers with opposite signs is negative, the product of 2 numbers with the same signs is positive\",\n       \"The product of two numbers will have the sign of the first one.\"\n      ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion: Are there other roots in [-10, 0]?\nThere is another root in the interval \\([-10, 0]\\) for the function \\(f(x) = e^x - x^4\\). Find its value numerically:\nf(x) = exp(x) - x^2\nval = find_zero(f, (-10, 0));\nnumericq(val, 1e-3)\n\n\nQuestion: Relation between \\(x^2\\) and \\(x \\log(x)\\)\nLet \\(f(x) = x^2 - 10 \\cdot x \\cdot \\log(x)\\). This function has two zeros on the positive \\(x\\) axis. You are asked to find the largest (graph and bracket…):\n#| echo: false\nb = 10\nf(x) =  x^2 - b * x * log(x)\nval = find_zero(f, (10, 500))\nnumericq(val, 1e-3)\n\n\nQuestion\nThe airyai function has infinitely many negative roots, as the function oscillates when \\(x < 0\\). In a previous problem we graphically found the largest root. Now find the second largest root using the graph to bracket the answer, and then solving.\n#| echo: false\nval = find_zero(airyai, (-5, -4))\nnumericq(val, 1e-8)\n\n\nQuestion: What goes up must come down…\n\n\n\nUp and down\n\n\nIn 1638, according to Amir D. Aczel, an experiment was performed in the French Countryside. A monk, Marin Mersenne, launched a cannonball straight up into the air in an attempt to help Descartes prove facts about the rotation of the earth. Though the experiment was not successful, Mersenne later observed that the time for the cannonball to go up was greater than the time to come down. According to “Vertical Projection in a Resisting Medium: Reflections on Observations of Mersenne”.\nThis isn’t the case for simple ballistic motion where the time to go up is equal to the time to come down. We can “prove” this numerically. For simple ballistic motion, \\(f(t) = -(1/2)\\cdot 32 t^2 + v_0t\\). The time to go up and down are found by the two zeros of this function. The peak time is related to a zero of a function given by D(f), which for now we’ll take as a mystery function, but later will be known as the derivative.\nLet \\(v_0= 390\\). The three times in question can be found from the zeros of f and f'. What are they?\n#| echo: false\nchoices = [L\"(0.0, 12.1875, 24.375)\",\n    L\"(-4.9731, 0.0, 4.9731)\",\n    L\"(0.0, 625.0, 1250.0)\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion: What goes up must come down… (again)<\nFor simple ballistic motion you find that the time to go up is the time to come down. For motion within a resistant medium, such as air, this isn’t the case. Suppose a model for the height as a function of time is given by\n\\[\nh(t) = (\\frac{g}{\\gamma^2} + \\frac{v_0}{\\gamma})(1 - e^{-\\gamma t}) - \\frac{gt}{\\gamma}\n\\]\n(From “On the trajectories of projectiles depicted in early ballistic Woodcuts”)\nHere \\(g=32\\), again we take \\(v_0=390\\), and \\(\\gamma\\) is a drag coefficient that we will take to be \\(1\\). This is valid when \\(h(t) \\geq 0\\). In Julia, rather than hard-code the parameter values, for added flexibility we can pass them in as keyword arguments:\nh(t; g=32, v0=390, gamma=1) = (g/gamma^2 + v0/gamma)*(1 - exp(-gamma*t)) - g*t/gamma\nNow find the three times: \\(t_0\\), the starting time; \\(t_a\\), the time at the apex of the flight; and \\(t_f\\), the time the object returns to the ground.\n#| echo: false\nt0 = 0.0\ntf = find_zero(h, (10, 20))\nta = find_zero(D(h), (t0, tf))\nchoices = [L\"(0, 13.187, 30.0)\",\n    L\"(0, 32.0, 390.0)\",\n    L\"(0, 2.579, 13.187)\"]\nanswer = 3\nradioq(choices, answer)"
  },
  {
    "objectID": "zeros.html#the-find_zeros-function",
    "href": "zeros.html#the-find_zeros-function",
    "title": "4  Solving for zeros with julia",
    "section": "4.5 The find_zeros function",
    "text": "4.5 The find_zeros function\nSo, find_zero finds one value within a bracket. But this suggests a means to find all (most?) of the zeros within an interval – split the interval up into many pieces; identify those that bracket a zero; use find_zero on those intervals; accumulate the results.\nThis is basically implemented in the find_zeros(f, a, b) function. So, to find the zeros of \\(e^x - x^4\\) over \\([-10, 10]\\) we have:\nf(x) = exp(x) - x^4\nfind_zeros(f, -10, 10)\nThe above description will only work for zeros which cross the \\(x\\) axis, but find_zeros tries a bit more. So, it will find the zero of \\(f(x) = x^2 \\cdot e^x\\):\nf(x) = x^2 * exp(x)\nfind_zeros(f, -1, 1)\nThat being said, find_zeros can miss zeros, so a graph is always suggested to verify the zeros are exhausted.\nThe fzeros function is an alternate name for find_zeros."
  },
  {
    "objectID": "zeros.html#polynomials-of-higher-degrees",
    "href": "zeros.html#polynomials-of-higher-degrees",
    "title": "4  Solving for zeros with julia",
    "section": "4.6 Polynomials of higher degrees",
    "text": "4.6 Polynomials of higher degrees\nFor Polynomials of higher degree, there are some specific methods that can be used to identify the roots. We will demonstrate the methods from the SymPy package. These work on symbolic expressions. These will be described in more detail later, but for now, we have to make a symbolic variable, x to proceed:\n@syms x\nThe two functions we discuss are sympy.roots and sympy.real_roots.\nFirst consider the quadratic equation below. We can identify the real roots of algebraic type with:\nf(x) = x^2 + x - 1\nsympy.real_roots(f(x))\nThat was so easy, we’ll do it again. What are the roots of the polynomial \\(f(x) = -16x^2 + 32x + 6\\)?\nf(x) = -16x^2 + 32x + 6\nsympy.real_roots(f(x))\nAs can be seen, \\(f\\) has two real roots. This next polynomial has none:\nf(x) = x^2 + x + 1\nsympy.real_roots(f(x))\n\n4.6.1 All algebraic roots\nThese are examples of the general template action(function_object, args…) for performing some action on a function. In this case, the action is to find the roots of a function which specifies a polynomial function and the additional args… are not necessary–if only complex values are desired.\nFor some problems only the possible real roots are desired.\nThe following polynomial has both real roots and complex roots. The real one are\nf(x) = (x^2 + x + 1) * (x^2 + x - 1)\nsympy.real_roots(f(x))\nCompare to\nsympy.roots(f(x))\nThe word “algebraic” was used, as some problems have answers, but not readily expressible ones. For example, x^5 -x - 1:\nf(x) = x^5 - x - 1\nsympy.roots(f(x))\nHowever, the solve function (which solves f(x)=0) does hint at answers:\nsolve(f(x))\nThese can be revealed, but converting them to numeric with N:\nN.(solve(f(x)))\n\n\n4.6.2 Practice\n\nQuestion\nFind all roots of the function \\(f(x) = x^4 - 4x^2 -4x + 2\\). Are they all real numbers?\n#| echo: false\nchoices = [\"Yes, the are all real\", \"No, some are real, some are complex\", \"No, none are real\"]\nanswer = 2\nradioq(choices, answer)\n\n\nQuestion\nFind the largest real root of the polynomial \\(x^2 + x - 5\\)\n#| echo: false\n@syms x\np = N.(sympy.real_roots(x^2 + x - 5))\nval = maximum(p);\nnumericq(val, 1e-3)\n\n\nQuestion\nFind the largest real root of the polynomial \\(x^3 - x - 17\\)\n#| echo: false\n@syms x\nzs = N.(sympy.real_roots(x^2 - x - 17))\nval = maximum(zs)\nnumericq(val, 1e-3)\n\n\nQuestion\nThe rule of signs of Descartes is a simple means to give an upper bound on the number of positive real roots a polynomial has. One counts the number of sign changes amongst the polynomials coefficients. Suppose this is \\(k\\), then the number of positive real roots (counting multiplicities) is one of \\(k\\), \\(k-2\\), \\(k-4\\), … . In particular if \\(k\\) is odd, there must be at least one real root.\nFor example, the polynomial \\(x^3 -x^2 -x - 1\\) has signs + - - -, so there is just one sign change. This implies there must be exactly one positive real root, which is identifyied with:\nf(x) = x^3 -x^2 -x - 1\nN.(sympy.real_roots(f(x)))\nFor the polynomial \\(f(x) = x^5 -x + 1\\) has potentially 2 positive, real roots? Are there \\(0\\) or \\(2\\) positive, real roots?\n#| echo: false\nchoices = [\"zero\", \"two\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion\nThe number of possible negative, real roots can also be found from Descartes’ rule. Instead of looking at the sign changes of \\(f(x)\\), one must look at the sign changes of \\(g(x) = f(-x)\\).\nIf \\(f(x) = x^5 - x +1\\) we have \\(g(x) = -x^5 +x + 1\\) (just change the signs of the coefficients of the odd powers). Then \\(g(x)\\) has one sign change. This means there is one negative real root. What is it?\n#| echo: false\nval = fzeros(x -> x^5 - x +1, -5, 5)[1]\nnumericq(val, 1e-2)"
  },
  {
    "objectID": "limits.html",
    "href": "limits.html",
    "title": "5  Investigating limits with Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "limits.html#introduction",
    "href": "limits.html#introduction",
    "title": "5  Investigating limits with Julia",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nThe concept of a limit is what makes calculus possible. Limits are used to define the two main concepts of calculus: derivatives and integrals. The formal definition of a limit is a bit difficult to appreciate and grasp. It involves an “\\(\\epsilon-\\delta\\)” formulation:\n\nThe limit of \\(f(x)\\) as \\(x\\) approaches \\(c\\) is \\(L\\) if for every \\(\\epsilon > 0\\) there exists a \\(\\delta > 0\\) such that whenever \\(0 < |x - c| < \\delta\\) then \\(|f(x) - L| < \\epsilon\\).\n\nWhen a limit exists, we write:\n\\[\n\\lim_{x \\rightarrow c} f(x) = L.\n\\]\nHowever the intuition of limits is more accessible. This intuition was known as early as the Greeks: Archimedes figured out the area under a parabola over 2000 years ago by the method of exhaustion, a limiting process. Fermat in 1629 essentially took a limit to find the slope of a tangent line to a polynomial curve. Newton in the late 1600s, exploited the idea in his development of calculus (as did Leibnez). Yet it wasn’t until the 1800s that Bolzano, Cauchy, and Weierstrass put the idea on a firm footing, as above.\nTo get the intuition behind a limit we replace the absolute value inequalities in the definition with “close” and read as follows: as \\(x\\) gets “close” to \\(c\\) (but not equal), then \\(f(x)\\) should get “close” to \\(L\\)."
  },
  {
    "objectID": "limits.html#many-limits-are-found-just-by-evaluating-the-function",
    "href": "limits.html#many-limits-are-found-just-by-evaluating-the-function",
    "title": "5  Investigating limits with Julia",
    "section": "5.2 Many limits are found just by evaluating the function",
    "text": "5.2 Many limits are found just by evaluating the function\nBefore beginning, it should be noted that for most values of \\(c\\), the answer is simply \\(L=f(c)\\). This is because most all the functions encountered will be continuous which is basically a statement that for any \\(c\\) the limit is given through \\(L=f(c)\\).\nFor example, let \\(f(x) = \\sin(x)/x\\). For any \\(c\\) except \\(0\\), \\(f(x)\\) is continuous and the limit exists and is simply \\(f(c)\\). In particular, at \\(c=1\\) we have\n\\[\n\\lim_{x \\rightarrow 1} \\frac{\\sin(x)}{x} = \\frac{\\sin(1)}{1}.\n\\]\nHowever, at \\(c=0\\) we can’t say \\(f(x)\\) is continuous – it isn’t even defined. When \\(c\\) is non-zero, the function \\(f(x)\\) is simply the ratio of two continuous functions. Such a ratio will be continuous except when dividing by \\(0\\), as is the case when \\(c=0\\)\nWhen discussing limits of combinations of continuous functions it is generally true that the limit is found by evaluating the function at \\(c\\) unless this yields an indeterminate form which is of the type: \\(0/0\\), \\(\\infty/\\infty\\), \\(0 \\cdot \\infty\\), \\(\\infty - \\infty\\), \\(0^0\\), \\(1^\\infty\\), and \\(\\infty^0\\). Such forms can have limits of many different values, depending on the functions involved.\nFor this particular problem what does Julia return when we try to evaluate \\(f(c)\\)?\nf(x) = sin(x)/x\nc = 0\nf(c)\nThe value NaN arises when a floating-point computation is indeterminate.\nSo, does \\(\\sin(x)/x\\) have a limit at \\(c=0\\)? If it does, it isn’t simply \\(f(0)\\).\n\n\n\n\n\n\nNaN values\n\n\n\nOperations involving NaN will also return NaN. In this example, the ratio defining \\(f(x)\\) is like \\(0/0\\) when \\(c=0\\) – an indeterminate form. The value NaN is returned by most of the indeterminate forms listed above, but not all. For example, 0^0 is 1 to Julia:\n“It proved more useful to adhere to the simply stated rule *anything raised to the \\(0\\) gives \\(1\\) then special case \\(0^0\\). Some comments by the “father of floating point” can be read near the end of this.”"
  },
  {
    "objectID": "limits.html#graphical-approach-to-limits",
    "href": "limits.html#graphical-approach-to-limits",
    "title": "5  Investigating limits with Julia",
    "section": "5.3 Graphical approach to limits",
    "text": "5.3 Graphical approach to limits\nA graphical approach to this problem can show if a function is likely to have a limit. The basic idea is to simply make a graph around \\(c\\) and look to see if \\(f(x)\\) gets close to some value as \\(x\\) gets close to \\(c\\):\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings\nf(x) = sin(x)/x\nc, delta = 0, pi/2\nplot(f, c - delta, c + delta)\nFrom the graph it looks like the function value should be \\(1\\) at \\(0\\). Which is indeed the case, as was understood as early as 1735 by Euler.\nRecall that the graph is made by choosing a large number of points between the limits and then evaluating the function at each of these points. The values \\((x,f(x))\\) are then connected like a dot-to-dot figure. If a value is NaN, the line will break to indicate this. In the above graph, it appears that \\(0\\) is not one of the points sampled, as no break is indicated. The graph gives the appearance that \\(f(x)\\) is continuous, though we know that isn’t the case, as \\(f(x)\\) is undefined at \\(x=0\\).\n\n5.3.1 Removable singularities\nConsider now the following limit\n\\[\n\\lim_{x \\rightarrow 2} \\frac{x^2 - 5x + 6}{x^2 +x - 6}\n\\]\nNoting that this is a ratio of continuous functions, we first check whether there is anything to do:\nf(x) = (x^2 - 5x + 6) / (x^2 + x - 6)\nc = 2\nf(c)\nThe NaN indicates that this function is indeterminate at \\(c=2\\). A quick plot gives us an idea that the limit exists and is roughly \\(-0.2\\):\nc, delta = 2, 1\nplot(f, c - delta, c + delta)\nThe graph looks continuous. In fact, the value \\(c=2\\) is termed a removable discontinuity as redefining \\(f(x)\\) to be \\(-0.2\\) when \\(x=2\\) results in a continuous function.\nAs an aside, you can redefine f using the “ternary operator”:\nf(x) = x == 2.0 ? -0.2 :  (x^2 - 5x + 6) / (x^2 + x - 6)\nThis particular case is a textbook example: one can easily factor \\(f(x)\\) to get:\n\\[\nf(x) = \\frac{(x-2)(x-3)}{(x-2)(x+3)}\n\\]\nWritten in this form, we clearly see that this is the same function as \\(g(x) = (x-3)/(x+3)\\) when \\(x \\neq 2\\). The function \\(g(x)\\) is continuous at \\(x=2\\). So were one to redefine \\(f(x)\\) at \\(x=2\\) to be \\(g(2) = (2-3)/(2+3) = -0.2\\) it would be made continuous, hence the term removable singularity.\n\n\n5.3.2 Problems\n\nQuestion\nBy graphing near \\(1\\), find the limit:\n\\[\nL = \\lim_{x \\rightarrow 1}  \\frac{x^2−3x+2}{x^2−6x+5}\n\\]\n#| echo: false\nanswer = 1/4\nnumericq(answer, 1e-1)\n\n\nQuestion\nGraphically look at the following limit\n\\[\nL = \\lim_{x \\rightarrow -2} \\frac{x}{x+1} \\frac{x^2}{x^2 + 4}\n\\]\nWhat is the value?\n#| echo: false\nf(x) = x/(x+1)*x^2/(x^2+4)\nval = f(-2)\nnumericq(val, 1e-3)\n\n\nQuestion\nGraphically investigate the limit\n\\[\nL = \\lim_{x \\rightarrow 0} \\frac{e^x - 1}{x}.\n\\]\nWhat is the value of \\(L\\)?\n#| echo: false\nval = exp(0)\nnumericq(val, 1e-1)\n\n\nQuestion\nGraphically investigate the limit\n\\[\n\\lim_{x \\rightarrow 0} \\frac{\\cos(x) - 1}{x}.\n\\]\nThe limit exists, what is the value?\n#| echo: false\nval = 0\nnumericq(val, 1e-2)\n\n\nQuestion\nThe following limit is commonly used:\n\\[\nL = \\lim_{h \\rightarrow 0} \\frac{e^{x + h} - e^x}{h}.\n\\]\nFactoring out \\(e^x\\) from the top and using rules of limits this becomes,\n\\[\nL = e^x \\lim_{h \\rightarrow 0} \\frac{e^h - 1}{h}.\n\\]\nWhat is \\(L\\)?\n#| echo: false\nchoices = [L\"0\", L\"1\", L\"e^x\"]\nanswer = 3\nbuttonq(choices, answer, explanation=\"The limit part is ``1`` not the limit.\")\n\n\nQuestion\nThe following limit is commonly used:\n\\[\n\\lim_{h \\rightarrow 0} \\frac{\\sin(x + h) - \\sin(x)}{h} = L.\n\\]\nThe answer should depend on \\(x\\), though it is possible it is a constant. Using a double angle formula and the rules of limits, this can be written as:\n\\[\nL = \\cos(x) \\lim_{h \\rightarrow 0}\\frac{\\sin(h)}{h} + \\sin(x) \\lim_{h \\rightarrow 0}\\frac{\\cos(h)-1}{h}.\n\\]\nUsing the last result, what is the value of \\(L\\)?\n#| echo: false\nchoices = [L\"\\cos(x)\", L\"\\sin(x)\", L\"1\", L\"0\", L\"\\sin(h)/h\"]\nanswer = 1\nbuttonq(choices, answer, explanation=\"\"\"\nThe two limits are ``1`` and ``0``, respectively, leaving just ``\\\\cos(x)`` for the answer.\n\"\"\")\n\n\nQuestion\nThe function \\(f(x) = (x^2 - 4)/(x-2)\\) has a removable singularity at \\(x=2\\). What value would you redefine \\(f(2)\\) to be, to make \\(f\\) a continuous function?\n#| echo: false\nf(x) = (x^2 -4)/(x-2);\nnumericq(f(2.00001), .001)\n\n\nQuestion: Squeeze theorem\nLet’s look at the function \\(f(x) = x \\sin(1/x)\\). A graph around \\(0\\) can be made with:\nf(x) = x == 0 ? NaN : x * sin(1/x)\nc, delta = 0, 1/4\nplot(f, c - delta, c + delta)\ng(x) = abs(x); h(x) = - abs(x)\nplot!(g)\nplot!(h)\nThis graph clearly oscillates near \\(0\\). To the graph of \\(f\\), we added graphs of both \\(g(x) = |x|\\) and \\(h(x) = - |x|\\). From this graph it is easy to see by the “squeeze theorem” that the limit at \\(x=0\\) is \\(0\\). Why?\n#| echo: false\nchoices=[\"The functions g and h both have a limit of 0 at x=0 and the function f is in between both g and h, so must to have a limit of 0.\",\n         \"The functions g and h squeeze each other as g(x) > h(x)\",\n         \"The function f has no limit -- it oscillates too much near 0\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion\nThe highly oscillatory function\n\\[\nf(x) = x^2 (\\cos(1/x) - 1)\n\\]\nhas a removable singularity at \\(x=0\\). What value would you redefine \\(f(0)\\) to be, to make \\(f\\) a continuous function?\n#| echo: false\nnumericq(0, .001)\n\n\nQuestion: No limit\nSome functions do not have a limit. Make a graph of \\(\\sin(1/x)\\) from \\(0.0001\\) to \\(1\\) and look at the output. Why does a limit not exist?\n#| echo: false\nchoices=[\"The limit does exist -- it is any number from -1 to 1\",\n  \"Err, the limit does exists and is 1\",\n  \"The function oscillates too much and its y values do not get close to any one value\",\n  \"Any function that oscillates does not have a limit.\"]\nanswer = 3\nradioq(choices, answer)"
  },
  {
    "objectID": "limits.html#getting-close-graphically",
    "href": "limits.html#getting-close-graphically",
    "title": "5  Investigating limits with Julia",
    "section": "5.4 Getting close graphically",
    "text": "5.4 Getting close graphically\nConsider again the limit of \\(f(x) = \\sin(x)/x\\), whose answer is not obvious from the formula, but from the graph we could see that \\(f(x)\\) goes to \\(L=1\\) as \\(x\\) goes to \\(0\\).\nWe can further illustrate how the function gets close to the limit of \\(1\\) by restricting the graph to values near \\(c\\):\nf(x) = sin(x) / x\nc, delta = 0, 1e-1\nplot(f, c-delta, c+delta)\nWe see a similar picture, with an answer of \\(1\\). A smaller \\(\\delta\\) yields a similar picture:\nc, delta = 0, 1e-3\nplot(f, c-delta, c+delta)\nThe graphs have a similar shape – but different scales. A closer look at the \\(y\\) axis shows that for delta = 1e-1 (or \\(1/10\\)) the range of \\(y\\) values is about \\(1/1000\\) and for delta = 1e-3 it is about \\(1/10,000,000\\).\nWe can be more precise. The following function estimate the length of the range of the plotted values:\nfunction epsilon(f, c, delta)\n     xs = range(c - delta, stop=c + delta, length=100)\n     ys = f.(xs)        # like drawing a plot\n     m, M = extrema(ys) # minimum and maximum\n     M - m\nend\n\n(epsilon(f, 0, 1e-1), epsilon(f, 0, 1e-3))\nNumerically we see as \\(x\\) gets close to \\(0\\) (delta gets small) \\(f(x)\\) gets close to a limit (epsilon gets small).\nIn fact for this problem we can be a bit more precise, as one can infer that \\(\\epsilon/(1/6 \\cdot\\delta^2)\\) is basically 1.\nWe can empirically verify this for one value of \\(\\delta\\) with\ndelta = 1e-2\nepsilon(f, 0, delta) / (1/6*delta^2)\nThe ratio is basically \\(1\\), as advertised.\nOf course, using a comprehension we can do this comparison for different sized values of \\(\\delta\\) at once:\ndeltas = [1/10, 1/10^2, 1/10^3, 1/10^4, 1/10^5]\n[epsilon(f, 0, delta)/(1/6*delta^2) for delta in deltas]\nThis isn’t quite what needs to be shown in the proof of a limit: we are essentially finding an epsilon for a given delta rather than a delta for a given epsilon. It does suggest that were we to attempt a formal proof, we should look at \\(\\delta\\) which is basically \\(\\sqrt{6 \\epsilon}\\).\n\n5.4.1 Problem\n\nQuestion\nConsider the limit\n\\[\nL = \\lim_{h \\rightarrow 0} \\frac{(1 + h)^2 - 1^2}{h}\n\\]\nGuess the relationship between epsilon and delta\n#| echo: false\nchoices = [\nL\" $\\epsilon/\\delta$ is constant\",\nL\" $\\epsilon/\\delta^2$ is constant\",\nL\" $\\epsilon/\\delta^3$ is constant\"]\nanswer = 1\nradioq(choices, answer, keep_order=true)"
  },
  {
    "objectID": "limits.html#using-a-table-to-investigate-limits",
    "href": "limits.html#using-a-table-to-investigate-limits",
    "title": "5  Investigating limits with Julia",
    "section": "5.5 Using a table to investigate limits",
    "text": "5.5 Using a table to investigate limits\nA table can be used to investigate limits of functions. The basic idea is that if\n\\[\n\\lim_{x \\rightarrow c} f(x) = L\n\\]\nthen for values of \\(x\\) close to \\(c\\), we should have that the values of \\(f\\) for these \\(x\\) are close to \\(L\\). For example, let’s look at this limit again:\n\\[\n\\lim_{x \\rightarrow 2} \\frac{(x+2)(x-3)}{(x+2)(x+3)}\n\\]\nwhich we know is simply \\(-1/5\\). To approach this problem using a table we would first need to produce some values of \\(x\\) getting close to \\(2\\). Here we get values approaching 2 from above:\nhs = [1/10, 1/100, 1/1000, 1/10000, 1/100000]  # or [1/10^i for i in 1:5]\nxs = 2 .+ hs\nThe corresponding \\(y\\) values are found by applying \\(f\\) to each:\nf(x) = ((x+2)*(x-3)) / ((x+2)*(x+3))\nys = f.(xs)\nThe ys are clearly getting closer to \\(-0.2\\), as expected.\nThe pairs of values xs and ys can be more naturally displayed with a table, the square-bracket notation is useful here to put the values into two columns:\n[xs ys]\nThe above investigates the right limit, as the values chosen for xs are always more than 2 but getting closer. The left limit might have used xs defined with:\nxs = [2 - 1/10, 2 - 1/100, 2 - 1/1000, 2 - 1/10000, 2 - 1/100000]\nys = f.(xs)\n[xs ys]\nWe see the same phenomenon – \\(f(x)\\) gets close to \\(-0.2\\) as \\(x\\) gets close to \\(c=2\\) from the left or the right.\nThe three steps above are bit tedious to type for each problem, so for convenience we encapsulate them into a function (available in the MTH229 package) call lim defined along these lines:\n#| eval: false\nfunction lim(f::Function, c::Real; n::Int=6, dir=\"+\")\n    hs =  [(1/10)^i for i in 1:n]\n     if dir == \"+\"\n       xs = c .+ hs\n     else\n       xs = c .- hs\n     end\n     ys = f.(xs)\n     [xs ys]\nend\nWe used keywords, n, to allow the user to change how close the xs get to \\(c\\) and dir to indicate the direction. The default direction is from the right.\nNow consider the limit of \\(x^x\\) as \\(x\\) goes to \\(0\\) from the right. Though julia – following a standard – defines this function at \\(0\\), it is of indeterminate form so should be investigated.\nf(x) = x^x\nc = 0\nf(c)\nAnd we see that the output from lim agrees with an answer of \\(1\\) for the right limit:\nlim(f, c; dir=\"+\")\nFor our next example, we compute numerically (a tedious problem to do algebraically)\n\\[\n\\lim_{x \\rightarrow 25} \\frac{\\sqrt{x} - 5}{\\sqrt{x-16} - 3}\n\\]\nf(x) = (sqrt(x) - 5) / (sqrt(x-16) - 3)\nc = 25\nlim(f, c)\nA quick investigation of the table demonstrates the limit should be \\(0.6\\).\n\nExample: The slope of the secant line\nA very important limit in calculus is the derivative formula, written here to emphasize the secant line aspect:\n\\[\n\\lim_{x \\rightarrow c} \\frac{f(x) - f( c)}{x-c}.\n\\]\nLet’s take \\(c = 1\\) and \\(f(x) = x^x\\) and compute the limit above:\nf(x) = x^x\nc = 1;\ng(x) = (f(x) - f(c)) / (x - c)\nlim(g, c)\nThe left limit has a similar tale. We take this as strong evidence that the limit is \\(1\\)\n\n\n5.5.1 Practice\n\nQuestion\nFind the limit as \\(x\\) goes to \\(2\\) of\n\\[\nf(x) = \\frac{3x^2 - x -10}{x^2 - 4}\n\\]\n#| echo: false\nf(x) = (3x^2 - x - 10)/(x^2 - 4);\nnumericq(f(2.00001), .001)\n\n\nQuestion\nFind the limit as \\(x\\) goes to \\(-2\\) of\n\\[\nf(x) = \\frac{\\frac{1}{x} + \\frac{1}{2}}{x^3 + 8}\n\\]\n#| echo: false\nf(x) = ((1/x) + (1/2))/(x^3 + 8)\nnumericq(-1/48, .001)\n\n\nQuestion\nFind the limit as \\(x\\) goes to \\(27\\) of\n\\[\nf(x) = \\frac{x - 27}{x^{1/3} - 3}\n\\]\n#| echo: false\nf(x) = (x - 27)/(x^(1/3) - 3)\nnumericq(0, 0.001)\n\n\nQuestion\nFind the limit\n\\[\nL = \\lim_{x \\rightarrow 0}(1+x)^{1/x}.\n\\]\n#| echo: false\nnumericq(exp(1), 0.001)\n\n\nQuestion\nFind the limit\n\\[\nL = \\lim_{x \\rightarrow \\pi/2} \\frac{\\tan (2x)}{x - \\pi/2}\n\\]\n#| echo: false\nf(x) = tan(2x)/(x-pi/2)\nnumericq(f(pi/2-.0001), 0.001)\n\n\nQuestion: limit properties\nThere are several properties of limits that allow one to break down more complicated problems into smaller subproblems. For example,\n\\[\n\\lim (f(x) + g(x)) = \\lim f(x) + \\lim g(x)\n\\]\nis notation to indicate that one can take a limit of the sum of two function or take the limit of each first, then add and the answer will be unchanged, provided all the limits in question exist.\nUse one or the either to find the limit of \\(f(x) = \\sin(x) + \\tan(x) + \\cos(x)\\) as \\(x\\) goes to \\(0\\).\n#| echo: false\nf(x) = sin(x) + tan(x) + cos(x)\nnumericq(f(0), 1e-5)\n\n\nQuestion: From Strang, attributed to Stein\nLook at the figure of a sector of a circle of radius 1 and the subtended section.\n\n\n\nsubtended angle\n\n\n#| echo: false\n# <script>\n# // theta = pi/6\n# // r = 1\n# // plot.new()\n# // plot.window(xlim=c(0,1), ylim=c(0,sin(theta)))\n# // polygon(c(0, cos(theta), cos(theta)), c(0, 0, sin(theta)))\n\n# // t = seq(0, theta, length=100)\n# // polygon(c(cos(theta), 1, cos(t)), c(0, 0, sin(t)), col=\"gray\")\n# // text(.15 * cos(theta/2), .15 * sin(theta/2), \"theta\")\n# // text(.5, 0, \"1\", pos=1)\n# </script>\nnothing\nLet \\(f(\\theta)\\) be the area of the triangle and \\(g(\\theta)\\) the shaded region. What is the limit\n\\[\n\\lim_{\\theta \\rightarrow 0+} \\frac{f(\\theta)}{g(\\theta)}?\n\\]\n#| echo: false\nnumericq(1, 1e-3)\n\n\nQuestion\nDoes this function have a limit as \\(h\\) goes to \\(0\\) from the right (that is, assume \\(h>0\\))?\n\\[\n\\frac{h^h - 1}{h}\n\\]\n#| echo: false\nchoices = [\n\"Yes, the value is `-9.2061`\",\n\"Yes, the value is `-11.5123`\",\n\"No, the value heads to negative infinity\"\n];\nanswer = 3;\nradioq(choices, answer)\n\n\n\n5.5.2 Practice\n\nQuestion: \\(0^0\\)\nIs the form \\(0^0\\) really indeterminate?\nConsider this limit:\n\\[\n\\lim_{x \\rightarrow 0+} x^{1/\\log_k(x)} = L.\n\\]\nIn julia, \\(\\log_k(x)\\) is found with log(k,x). The default, log(x) takes \\(k=e\\) so gives the natural log. So, we would define f, for a given k, with\nk = 10              # say. Replace with actual value\nf(x) = x^(1/log(k, x))\nConsider different values of \\(k\\) to see if the limit depends on \\(k\\) or not. What is \\(L\\)?\n#| echo: false\nchoices = [L\"1\", L\"k\", L\"\\log(k)\", \"The limit does not exist\"]\nanswer = 2\nradioq(choices, answer)\n\n\nQuestion \\(0^0\\)\nNext, consider this limit:\n\\[\n\\lim_{x \\rightarrow 0+} x^{k\\cdot x} = L.\n\\]\nConsider different values of \\(k\\) to see if this limit depends on \\(k\\) or not. What is \\(L\\)?\n#| echo: false\nchoices = [L\"1\", L\"k\", L\"\\log(k)\", \"The limit does not exist\"]\nanswer = 1\nradioq(choices, answer)"
  },
  {
    "objectID": "limits.html#limits-at-infinity",
    "href": "limits.html#limits-at-infinity",
    "title": "5  Investigating limits with Julia",
    "section": "5.6 Limits at infinity",
    "text": "5.6 Limits at infinity\nThe concept of a limit can be extended. For example, the concept of a limit as \\(n\\) goes to infinity for some sequence of values parameterized by \\(n\\).\nLet’s compute \\(\\pi\\) as the circumference of a circle of radius 1 by approximating the circle by an inscribed regular polygon with \\(n\\) sides. The legnth, \\(k\\), of a given side is\n\\[\nk = 2 \\sin(\\frac{2\\pi}{2n})\n\\]\nAs can be seen by taking the isoceles triangle with angle \\(2\\pi/n\\) and dropping a horizontal with opposite length 1/2 the entire length.\n\n\n\ninscribed\n\n\n#| echo: false\n# <script>\n# // plot.new()\n# // plot.window(xlim=c(-1,1), ylim=c(-1,1))\n# // n <- 17\n# // plot_circ = function(n, ...) {\n# //   theta <- seq(0, 2*pi, length=n)\n# //   x <- cos(theta); y <- sin(theta)\n# //   lines(x, y, ...)\n# // }\n# // plot_circ(1000, col=\"gray\")\n# // plot_circ(n+1, col=\"black\")\n\n# // t <- 2*pi/17\n# // lines(c(1, 0, cos(t)), c(0,0, sin(t)))\n# // text(cos(t/2), sin(t/2), expression(k), pos=4)\n# </script>\nnothing\nThus the total length is\n\\[\nl_n = n \\cdot 2 \\sin(\\frac{2\\pi}{2n})\n\\]\nAs \\(n\\) goes to \\(\\infty\\) this should go to the circumference of the circle of radius 1 or \\(2\\pi\\). (This was used as early as the Egyptians with an octagon to approximate \\(\\pi\\).)\nLet’s see.\nn_to_infinity = [10^i for i in 1:15]\nl(n) =  n * 2sin( (2pi)/(2n) )\n[l(n) for n in n_to_infinity]\nTo compare to \\(2\\pi\\) we can divide instead:\n[ l(n)/(2pi) for n in n_to_infinity ]\nAs the ratio has a limit of \\(1\\) we conclude that \\(l(n)\\) goes to \\(2\\pi\\).\nThere isn’t much difference to the above than what we did before, except we take increasing larger values for \\(n\\), not values getting close to 0 for \\(x\\).\n\n5.6.1 Practice\n\nQuestion\nUse an inscribed octagon to approximate \\(\\pi\\) (e.g., take \\(n=8\\) and look at \\(l(n)/2\\), with \\(l\\) defined above). What do you get?\n#| echo: false\nnumericq(l(8)/2, .0001)\n\n\nQuestion\nArchimedes used interior \\(96\\)-gons and exterior ones to estimate \\(\\pi\\) from above and below. The circumference of the exterior polygon is:\nL(n) = n*2*tan((2*pi)/(2*n))\nWhat is the difference between \\(L(96)/2\\) and \\(l(96)/2\\)?\n#| echo: false\nnumericq(L(96/2) - l(96/2), .0001)\n\n\nQuestion: (and why not call it b?)\nJacob Bernoulli looked at the limit\n\\[\n\\lim_{x \\rightarrow \\infty} (1 + \\frac{1}{x})^x\n\\]\nWhat value did he find?\n#| echo: false\nnumericq(exp(1), .001)\n\n\nQuestion: The Basel problem\nEuler looked at \\(\\sin(x)/x\\) in his solution to the “Basel” problem, that is finding the sum of:\n\\[\n1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\frac{1}{4^2} + \\frac{1}{5^2} + \\cdots =\n\\lim_{n \\rightarrow \\infty} \\sum_n \\frac{1}{i^2}.\n\\]\nEuler rewrote a series expansion for \\(\\sin(x)/x\\) to get his famous answer of \\(\\pi^2/6\\). Using this function\nbasel(n) = sum( [1/i^2 for i in 1:n] )\nhow big must \\(n\\) be so that pi^2/6 - basel(n) < 1e-3?\n#| echo: false\nchoices=[\n\"`10`\",\n\"`100`\",\n\"`1000`\",\n\"`10_000`\"\n];\nanswer=3;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion\nThe sum \\(1 + 1/2 + 1/3 + 1/4 + \\cdots\\) does not converge. In fact, the sum of the first \\(n\\) terms gets closer and closer to \\(\\log(n)\\) plus a constant. That is, this function does have a limit as \\(n\\) goes to \\(\\infty\\):\neuler_mascheroni(n) = sum([1/i for i in 1:n]) - log(n)\nUse this:\n#| eval: false\n[euler_mascheroni(i) for i in (10.0).^(1:7)]\nto find an answer to \\(6\\) decimal points.\n#| echo: false\nnumericq(euler_mascheroni(10^7), 1e-4)"
  },
  {
    "objectID": "limits.html#floating-point-uncertainties",
    "href": "limits.html#floating-point-uncertainties",
    "title": "5  Investigating limits with Julia",
    "section": "5.7 Floating point uncertainties",
    "text": "5.7 Floating point uncertainties\nA related limit to \\(\\sin(x)/x \\rightarrow 0\\) is:\n\\[\n\\lim_{x \\rightarrow 0} \\frac{1-\\cos(x)}{x^2} = \\frac{1}{2}.\n\\]\nRelated in that they are used to approximate related functions near \\(0\\): \\(\\sin(x) \\approx x\\) and \\(1 - \\cos(x) \\approx (1/2) x^2\\). A graphic shows the latter approximation:\nplot([x -> 1 - cos(x), x -> x^2/2], -pi, pi)\nNote in the figure how the parabola tracks the shape of the transformed cosine function very well near \\(x=0\\) but not necessarily far from \\(0\\).\nNumerically, we have a different story. We see that there are limitations to our approach to finding limits that show up in analyzing this.\nHere is a first attempt\nf(x) = (1 - cos(x))/x^2\nc = 0\nxs = [c + (1/10)^i for i in 1:10]\nys = f.(xs)\n[xs ys]\nWe notice something odd – the values ultimately become \\(0\\) when we just said they should become \\(1/2\\). At least for most of the output things look okay, but then something goes terribly wrong.\nThe culprit? Floating point approximation involves round off errors.\nLet’s look at the two pieces. First the denominator:\ndenominator = [ x^2 for x in xs ]\nThere is nothing here to speak of. Julia’s Float64 type follows the IEEE 754 floating point standard. Of the 64 bits, 1 is used for the sign (plus or minus) and 11 are used to store the exponent. See this informative blog post for more Anatomy of a floating-point number. As \\(2^{11} = 2048\\) roughly half are used for negative exponents, the other half for positive exponents. The range is from 1e-1022 to 1e1023. We aren’t even close to the lower range with 1e-20.\nNow, let’s look at the numerator. The issue is the difference between \\(\\cos(x)\\) and 1. Let’s look with the small values printed:\nnumerator = [ 1-cos(x) for x in xs ]\n[xs numerator]\nInstead of giving a value that is roughly \\(5 \\cdot 10^{-(2n+1)}\\), the value becomes \\(0\\) – not just numbers close to \\(0\\). Hence, when the numerator is divided by even the smallest of numbers, the answer is simply \\(0\\).\nIn general, we add to our few rules of thumb for computation with floating-point numbers:\n\nIf we subtract two like-sized quantities our answer may have dramatically reduced precision.\n\nIn this specific case by the time we get to \\(10^{-8}\\), the difference between \\(\\cos(x)\\) and \\(1\\) is looking to be around 5e-17. However, in floating point representation there are fundamental limits to how close different things can be. Of the 64 bits representing a number, 52 are used for the precision. (A number, \\(s \\cdot p \\cdot 10^e\\), is represented with a sign, the precision and an exponent.) This puts the restriction on what can be represented and ultimately gives a granularity if one looks too closely – without working harder. In this particular case, the floating point approximation for \\(1\\) and that for \\(\\cos(x)\\) are eventually the same value – even if they are different mathematically.\nThe value\neps()\nmeasures how much larger the next representable number after \\(1.0\\) is from \\(1.0\\). (Of course, this has no answer in the real numbers, but floating point is a discrete approximation.)\nWhat has happened with \\(1-\\cos(x)\\) is the mathematical value of \\(\\cos(x)\\) gets too close to 1 when \\(x = 10^{-8}\\) and so the difference is treated as \\(0\\) as the two numbers have the same representation. Since \\(0\\) divided by any non-zero number is zero, we get a reasonable answer for the at-first unexpected behavior.\nSo be careful, we can get too close when looking “close.”\n\n\n\n\n\n\nInvestigating how numbers are represented in floating point: prevfloat\n\n\n\nJulia has some functions for working with floating point numbers. Some of you might be thinking that since eps is the difference to the next representable number larger than 1, what is the same for the next representable number less than one. The prevfloat value gives this. Here we see the issue between \\(10^{-7}\\) and \\(10^{-8}\\):\n\n\nprevfloat(1.0) < cos(1e-7)\nprevfloat(1.0) < cos(1e-8)\nFloating point approximations differ depending on the location. Look at the difference between 1.0- prevfloat(1.0) and nextfloat(1.0) - 1. Then look at how small nextfloat(0.0) is.\n\n5.7.1 Practice\n\nQuestions\nis eps() == nextfloat(1.0)?\n#| echo: false\nbooleanq(true)\n\n\nQuestion (bitstring etc)\nThe bitstring function prints the bit representation of a number. For real numbers, the first bit is the sign, the next 11 the exponent and the last 52 are for the precision. Let’s look at the values for a few:\nbitstring(cos(1e-7))\nbitstring(cos(1e-8))\nbitstring(1.0)\nWe see here how two different real numbers have the same floating point representation.\nFor fun, what is the difference between bitstring(-1.0) and bitstring(1.0)?\n#| echo: false\nchoices = [\"The last bit on the right is different\",\n           \"The first bit on the left is different\",\n       \"The 2 through 12th bit (on the left) are all 1.\"\n       ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion: bitstring etc.\nWhat is the difference between bitstring(NaN) and bitstring(Inf)? (These two are coded specially in floating point.)\n#| echo: false\nchoices= [\"The first bit on the right is different\",\n      \"Bits 2-12 are the same, but bit 13 differs, that's all\",\n      \"They are identical, both are not numbers\"];\nanswer = 2;\nradioq(choices, answer)"
  },
  {
    "objectID": "limits.html#symbolic-answers",
    "href": "limits.html#symbolic-answers",
    "title": "5  Investigating limits with Julia",
    "section": "5.8 Symbolic answers",
    "text": "5.8 Symbolic answers\nThe SymPy package for Julia provides a means to for Julia users to interact with the SymPy add-on for the Python programming language. This package is loaded by the MTH229 package. The SymPy package provides symbolic math features. One such feature is the ability to perform symbolically the limit of \\(f(x)\\) as \\(x\\) approaches \\(c\\).\nThe limit function accesses these features. Its basic use is straightforward, just pass a symbolic expression, and indicate the variable going to c:\n@syms x\nf(x) = sin(x)/x\nc = 0\nlimit(f(x), x=>c)\nOr, with a limit at infinity\nf(x) = (1 + 1/x)^x\nc = oo                 # oo is symbolic infinity. Can also use Inf.\nlimit(f(x), x=>c)\nThe latter shows the results are not quite real numbers. Rather, they are symbolic values. We aren’t discussing these here, but the values are readily apparent.\nThe command @syms x creates x as a symbolic variable. The call f(x) returns a symbolic expression. These can also be created directly, as with sin(x)/x.\nThe limit function has one named argument, dir, used to adjust if a left, right (the default) limit is sought. For example, this function has different left and right limits at 0:\nf(x) = sign(x)\n@syms x\nlimit(f(x), x=>0, dir=\"-\"), limit(f(x), x=>0, dir=\"+\")\nThe algorithm implemented in SymPy for symbolic limits is quite powerful. It does not suffer from the floating point issues described before and gives exact values (though some coercion to floating point is possible). The following example shows this:\nThis function is pretty devious:\nf(x) = 1/ x^(log(log(log(log(1/x)))) - 1)\nIt has a right limit at \\(c=0\\), but not what is expected, which might appear to be 0:\nxs = [0 + 1/10^i for i in 2:6]\nys = f.(xs)\n[xs ys]\nBut in fact the limit is quite different from \\(0\\):\nlimit(f(x), x => 0, dir=\"+\")\n\n5.8.1 limits with parameters\nConsider the limit\n\\[\nL = \\lim_{x \\rightarrow 0} \\frac{b^x - 1}{x}.\n\\]\nIt’s answer depends on the value of \\(b\\). How would we approach this with SymPy? The interface described above where functions are used is not the only one SymPy knows of, and indeed is not typical of how one works with SymPy. Typically, symbolic values are defined and then symbolic expressions are used.\nHere is how we define a symbolic value (in fact two):\n@syms x b\nAnd here is how we use them:\nlimit((b^x - 1) / x, x=>0)\nWe see the \\(\\log(b)\\) value “magically” appearing. That may not have been expected.\n\n\n5.8.2 Problem\n\nQuestion\nWhat value is symbolically computed for\n\\[\n\\lim_{h \\rightarrow 0} \\frac{1 - \\cos(x)}{x^2}?\n\\]\n#| echo: false\nchoices = [\"Inf\", \"0\", \"1/2\", \"1\", \"NaN\"]\nanswer = 3\nradioq(choices, answer)\n\n\nQuestion\nWhat value is symbolically computed for\n\\[\n\\lim_{x \\rightarrow 0+} \\frac{x^x - 1}{x}?\n\\]\n#| echo: false\nchoices = [\"Inf\", \"0\", \"1\", \"NaN\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion\nWhat value is symbolically computed for\n\\[\n\\lim_{x \\rightarrow 0+} \\frac{x^x - 1}{x}?\n\\]\n#| echo: false\nchoices = [\"Inf\", \"0\", \"1\", \"NaN\"]\nanswer = 1\nradioq(choices, answer)\n\n\nQuestion\nWhat value is symbolically computed for\n\\[\n\\lim_{h \\rightarrow 0} \\frac{\\ln(1 + h)}{h}?\n\\]\n#| echo: false\nval = 1\nnumericq(val)"
  },
  {
    "objectID": "derivatives.html",
    "href": "derivatives.html",
    "title": "6  Approximate derivatives in Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "derivatives.html#introduction",
    "href": "derivatives.html#introduction",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nWe load our packages to begin.\nusing MTH229\nusing Plots\nSingle-variable calculus has two main concepts: the derivative and the integral, both defined in terms of a third important concept: the limit. The derivative is what we discuss here. The derivative allows us to talk about a tangent line to a curve. This is often called a line that touches the curve at just one point, but that isn’t quite correct, though often the case locally. A better idea would be to say it is the line that best approximates the curve at that point. That is, if we were to zoom in to the graph it might appear to look straight, and that straightness would have a slope that would match the tangent line. This idea leads to a primary use of the derivative – to approximate functions with simpler lines. Of course, this intuition is informal, a definition is in terms of the slope of approximating secant lines.\nHistorically, Fermat, in a treatise on finding maxima and minima, approached the problem of finding the tangent line by comparing the value of \\(f(x)\\) to a nearby value \\(f(x+h)\\). Working with polynomials, meant that subtracting \\(f(x+h) - f(x)\\) led to a polynomial in \\(h\\). Dividing by \\(h\\) and then setting \\(h=0\\) yields an answer for the slope.\nThe more modern approach (well Cauchy in the 1820s) defines the derivative of a function, \\(f\\), at a point \\(c\\) as the slope of the tangent line, defined in terms of the limit of the slopes of approximating secant lines. The notation is:\n\\[\nf'( c ) = \\lim_{h \\rightarrow 0} \\frac{f(c + h) - f( c)}{h}.\\quad\\text{Derivative at a point}\n\\]\nAs mentioned, intuitively, the tangent line is the best straight-line approximation to a function near the point \\((c, f( c))\\) and would have slope given by the derivative.\nThis graph shows \\(f(x) = 2 - x^2\\) and various secant lines when \\(c=-0.75\\).\nf(x) = 2 - x^2\nc = -0.75\nsec_line(h) = secant(f, c, c+h)                # secant in MTH229 package\nplot(f, -1, 1, legend=false)\nplot!(sec_line(1))\nplot!(sec_line(0.75))\nplot!(sec_line(0.5))\nplot!(sec_line(0.25))\nAs the value of \\(h\\) goes towards 0 along the path \\(1\\), \\(0.75\\), \\(0.5\\), \\(0.25\\), … the slope of the secant line heads towards the slope of the tangent line, in this case \\(2\\cdot 0.75 = 1.5\\).\nUsing the idea of a derivative at a point, one defines the derivative of the function \\(f\\) to be the function which for each \\(x\\) returns the derivative of \\(f\\) at the point \\(x\\). Notationally, this just replaces \\(c\\) above with \\(x\\), but conceptually there is a bit more to it."
  },
  {
    "objectID": "derivatives.html#forward-difference-quotients-slope-of-the-tangent-line",
    "href": "derivatives.html#forward-difference-quotients-slope-of-the-tangent-line",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.2 Forward difference quotients, Slope of the tangent line",
    "text": "6.2 Forward difference quotients, Slope of the tangent line\nThe rules of derivatives allow for a mechanical approach to taking derivatives with the power rule, chain rule and some special cases. In this project we look at approaching the derivative numerically. We start by investigating approximate derivatives computed with finite difference quotients.\nThe most naive approximation is simply to assume \\(h\\) is some small number and use that to approximate the limit above:\nf(x) = x^2 - 2x; fp(x) = 2x - 2\nh = .001\nc = 3\n( f(c + h) - f(c) ) / h\nThis is known as the forward difference quotient approximation to the derivative. For this example, the difference between the approximation and the actual slope is:\n( f(c + h) - f(c) ) / h - fp(c)\nThat is not too close, just to 3 digits of accuracy.\nNotationally, we may write this as:\n\\[\nf'( c) \\approx \\frac{f(c + h) - f( c) }{h}\n\\]\nFor some small value of \\(h\\). The equals sign is replaced by an approximation symbol, as there is no limit expression written.\n\nExample Derivative at a point\nLet’s try the derivative of some well known function. We know the derivative of \\(f(x) = \\sin(x)\\) is \\(f'(x) = \\cos(x)\\). Let’s see if the above works well:\nf(x) = sin(x); fp(x) = cos(x)\nc = pi/4; h = 0.0001\n( f(c + h) - f(c) )/h - fp(c)\nNot as good as we can get – the error is like 1e-5, but not too bad already.\n\n\nExample Finding profit\nSuppose the tractor company John Deere models its profit per units sold through the function \\(P(x) = 50 e^{x/250}/(1 - e^{x/250})\\). Find the marginal profit for \\(x=200\\).\nThe marginal profit is the change in profit per unit sold – or the derivative – at \\(x=200\\). We can find this quite simply by either differentiating directly, or as we do here, approximating the answer with julia. We first note that the function above, is a composition, so it may be written using two functions:\nf1(x) = exp(x)/(1 - exp(x))\nf(x) = 50 * f1(x/250)\nc = 200; h = 0.0001;\nres = (f(c+h) - f(c))/h\nIf \\(50\\) is the maximum profit, this is a percentage increase of:\n(res/50) * 100\nor a bit more than half a percent.\n\n\nExample Finding the tangent line at a point\nLet \\(f(x) = x^x\\). Find the tangent line at \\(c=2\\). Compare the difference between the value of the tangent line and the function at \\(x=2.1\\).\nThe tangent line is most easily expressed in terms of the point-slope formula for a line where the point is \\((c, f( c))\\) and the slope is \\(f'( c)\\). This gives:\n\\[\ny = f( c) + f'( c)\\cdot(x - c)\n\\]\nIn the following, the slope of the tangent line will be approximated using a numeric derivative. We use \\(h=0.0001\\):\nf(x) = x^x\nc = 2; h = 0.0001\nm = ( f(c + h) - f(c) ) / h\ntangent_line(x) = f(c) + m * (x - c)\nTo compare the difference, we have:\nf(2.1) - tangent_line(2.1)\nA graph shows this difference:\nplot([f, tangent_line], 1.85, 2.15)\n\n\n6.2.1 Practice\n\nQuestion\nFind the slope of the tangent line of \\(f(x) = x\\log(x)\\) at the value \\(x=1\\) using \\(h=0.0001\\) and the forward difference quotient method:\n#| echo: false\nf(x) = x*log(x)\nc, h = 1, 0.0001;\nval = (f(c+h) - f(c))/h;\nnumericq(val, 1e-6)\n\n\nQuestion\nFind the slope of the tangent line of \\(f(x) = x-\\log(x)\\) at the value \\(x=1\\) using \\(h=0.0001\\) and the forward difference quotient method:\n#| echo: false\nf(x) = x-log(x)\nc, h = 1, 0.0001;\nval = (f(c+h) - f(c))/h;\nnumericq(val, 1e-6)\n\n\nQuestion\nThe built-in airyai function, when called as airyai(x), returns the so-called Airy function, a special function named after\nGeorge Biddell Airy.\nCompute the derivative at \\(c=-3\\) using \\(h=0.0001\\).\n#| echo: false\nf(x) = airyai(x)\nc, h = -3, 0.0001;\nval = (f(c+h) - f(c))/h;\nnumericq(val, 1e-6)\n\n\nQuestion\nLet \\(f(x) = \\sin(x)\\). The slope of the tangent line at \\(c=\\pi/4\\) is well known to have slope \\(\\sqrt{2}/2\\).\nCompute the forward difference quotient for \\(f\\) at \\(c\\) using \\(h=0.01\\). What is the order of the difference between the two values?\n#| echo: false\nchoices=[\"3 parts in 100\",\n         \"3 parts in 1000\",\n     \"3 parts in 10,000\",\n     \"3 parts in 100,000\"]\nanswer = 2\nradioq(choices, answer, hint=\"Look at `sqrt(2)/2` minus the computed value\",keep_order=true)\n\n\nQuestion\nFor the function \\(f(x) = x^3 - 5x\\) use a forward difference quotient with \\(h=0.0001\\) to approximate the slope of the tangent line at \\(c=1\\). Use this value to create a tangent line at (c, f( c)). Plot both the function and the tangent. Estimate graphically where the tangent line crosses the \\(x\\) axis. The value is near:\n#| echo: false\nchoices = [-2, -1.5, -1, -0.5, 0, 1]\nanswer = 3\nradioq(choices, answer, keep_order=true)"
  },
  {
    "objectID": "derivatives.html#derivative-of-a-function",
    "href": "derivatives.html#derivative-of-a-function",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.3 Derivative of a function",
    "text": "6.3 Derivative of a function\nWe might be interested not in the derivative at a point, but in the derivative as a function. This is how we think of the derivative when we say if \\(f(x) = \\sin(x)\\), the \\(f'(x) = \\cos(x)\\). Mathematically, from this viewpoint, the derivative is referred to as an operator, as it takes a function and returns a function.\nWe can reproduce this behavior easily enough with julia, as functions are first class objects: they can be passed as arguments and returned as values.\nFirst, let’s define a function to find the derivative at a point using the “forward difference quotient”:\nforward_difference(f, x0, h) = (f(x0 + h) - f(x0))/h\nWe need three arguments of course as we have three ingredients to worry about: the function, the point and the size of \\(h\\).\nTo make an operator that takes \\(f\\) and returns a function (an anonymous function in this case) that computes our approximation to \\(f'\\) we can do the following:\nDf(f; h=1e-8) = x -> forward_difference(f, x, h)\nWe specified a default value of \\(h\\) for convenience, but allow it to be varied if desired.\nTo see this work, we can find and plot the derivative of \\(\\sin(x)\\):\nf(x) = sin(x)\nfp(x) = Df(f)(x)\nplot(f, 0, 2pi)\nplot!(fp)\nWell, we already knew that should just be \\(\\cos(x)\\). The point is we can easily make the an approximate derivative function from f with the definition fp(x) = Df(f)(x).\n\n\n\n\n\n\nParsing Df(f)(x)\n\n\n\nSeeing the pair of parenthesis can lead to confusion, as it isn’t common math notation. Here parentheses are not used for grouping, but rather function application. There are two function applications and the associativity rules for function application are left to right, as with most – but not all – operations. So Df(f) is done first. This returns a function (the approximate derivative) which is then evaluated at x.\n\n\n\n\n\n\n\n\nDefining fp or fp(x)\n\n\n\nWe could also have just plotted f and Df(f) without naming fp. As well, could have written fp = Df(f), but that creates fp as an anonymous function and we then couldn’t redefine it through fp(x) = ..., which would attempt to make it a generic function.\n\n\nLet’s look at a different function, where we don’t know in our heads the answer.\nf(x) = exp(x)/(1 + exp(x))\nplot(f, 0, 5)\nplot!(Df(f))\nIf we look, we can see from the graph that f is increasing and Df(f) is positive – this is no coincidence, of course.\n\nExample: Critical points\nA function’s critical points are where its derivative is \\(0\\) or undefined. We can examine these by graphing the function’s derivative. Let’s do so for the polynomial \\(f(x) = x^3 - 5x + 4\\):\nf(x) = x^3 -5x + 4\nfp(x) = Df(f)(x)\nplot(fp, -5, 5)\nYou can check the zeroes graphically, say by zooming in a bit and adding the line \\(y=0\\):\nplot(fp, -2, 2)\nplot!(zero)\nIf you want, we can find the roots numerically. For example,\nfind_zeros(fp, -10, 10)\n\n\nExample: When is a function increasing?\nLet \\(f(x) = \\cos(x)\\) over the interval \\([0, 360]\\) (in degrees). When is the function increasing?\nFrom the relationship of the derivative and the function, we know the answer is when \\(f'(x) > 0\\). For this example, we can solve this directly as \\(f'(x) = -\\sin(x)\\) and we know when that is positive (well you are supposed to anyways: when the angle is in the third and fourth quadrants). Let’s see how we would do this task with julia and compare.\nFirst, we only need the derivative, so we just ask:\nf(x) = cosd(x)          # using degrees\nfp(x) = Df(f)(x)                # use default h\nThen we wish to indicate on the graph where fp(x) > 0. We can do this by defining a function that is \\(0\\) when that is the case and NaN otherwise (so that those points are not plotted). We do so below using the plotif function from the MTH229 package\nplotif(f, fp, 0, 360)  # second color when fp > 0\n\n\n6.3.1 Practice\n\nQuestion\nLet \\(f(x) = e^x\\). Using a forward difference quotient and \\(h=0.001\\) graph both the function and its approximate derivative over the interval \\([0, 3]\\). Estimate graphically the largest difference between the function and its approximate derivative.\n#| echo: false\nchoices = [\"It is about 0.1\", \"It is about 0.01\", \"It is about 0\"]\nanswer = 3\nradioq(choices, answer)\n\n\nQuestion\nLet \\(f(x) = x^2 \\exp(-x)\\). Using \\(h=0.0001\\) and an approximate derivative, estimate graphically where \\(f'(x)\\) is positive on the interval \\([0,3]\\).\n#| echo: false\nchoices = [\"It is for the entire interval\",\n       \"Between 0 and 2\",\n       \"From 0 to about 0.45\"]\nanswer = 2\nradioq(choices, answer)\n\n\nQuestion\nThe critical points of a function are where its derivative is undefined or where its derivative is \\(0\\). For the function \\(f(x) = 3x^4 -28x^3 + 96x^2 - 144x\\) graphically find any critical points over the interval \\([0,10]\\)\n#| echo: false\nchoices=[\"There is one at 3\",\n     \"There are two distinct ones: 2, 3\",\n     \"There are two distinct ones: 2, 2.6667\",\n     \"There are two distinct ones: 2, 4.69\"]\nanswer = 2\nradioq(choices, answer)"
  },
  {
    "objectID": "derivatives.html#improvements-to-the-basic-forward-difference-quotient",
    "href": "derivatives.html#improvements-to-the-basic-forward-difference-quotient",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.4 Improvements to the basic forward difference quotient",
    "text": "6.4 Improvements to the basic forward difference quotient\nThe error in the approximation of the derivative depends on the size of \\(h\\). Mathematically, as \\(h\\) gets smaller we get better approximations, though with the computer other complications arise. To see mathematically that this is the case, let’s look at the difference between the approximate numeric derivative from the forward difference quotient and a known derivative.\nf(x) = sin(x)\nfp(x) = cos(x)\n[ Df(f,h=h)(.5) - fp(.5) for h=[.1, .01, .001, .0001, .00001] ]\nIt gets better as \\(h\\) gets smaller. In fact, it looks like when \\(h\\) gets smaller by a factor of \\(1/10\\) so does the error. Let’s look a little deeper though. Rather than type in the values of \\(h\\) as above, let’s use an expression to compute them. Here we find the powers \\(10^{-1}, \\dots, 10^{-16}\\) at once and then compute the differences:\nhs = [(1/10)^i for i in 1:16];\nout = [ Df(f,h=h)(.5) - fp(.5) for h in hs ];\n[hs out]\nWhen we look, we see that for awhile the approximation gets better (to about 1e-9), but then does a U-turn and starts getting worse. The mathematical approximation gets better and better, but what happens is the computational error gets worse. We’ll see below how to pick the \\(h\\) that best balances these off, but first lets look at how using different approximations for the derivative can improve the “mathematical” error.\n\n6.4.1 Central difference quotient\nIt turns out that just by looking to the left and the right we can improve the mathematical error from getting better at a rate of \\(h\\) to a rate of \\(h^2\\), provided our function is smooth enough and we don’t have issues on the boundaries. The formula, called the central difference quotient approximation to the derivative is:\n\\[\nf'(x) \\approx \\frac{ f(x + h) - f(x - h) }{2h}\n\\]\nFor this the mathematical error is like \\(h^2\\), not \\(h\\).\nLet’s compare. To make our life easier we again create some functions, as we did with Df above.\ncentral_difference(f, x0, h) = (f(x0 + h) - f(x0 - h)) / (2h)\nDc(f; h=0.0001) = x -> central_difference(f, x, h)\nNow to see whether a forward difference quotient or central difference quotient works better. We can do so with a table. Again with \\(f(x) = \\sin(x)\\)\nf(x) = sin(x)\nfp(x) = cos(x)\nusing_D =  [ Df(f,h=h)(.5) - fp(.5) for h in hs ];\nusing_Dc = [ Dc(f,h=h)(.5) - fp(.5) for h in hs ];\n[hs using_D using_Dc]\nThe errors for the central difference quotient are either much smaller for the same size \\(h\\) or the same. We see that we can use a larger \\(h\\) to get the most accuracy in this example.\n\nExample: When does the tangent line hit 0?\nLet \\(f(x) = 10/(1+x^2) - 10\\exp(-(1/2)x^2)\\). The tangent line at \\(x=c\\) is given by\n\\[\ny = f( c) - f'( c)(x - c)\n\\]\nand this intersects the \\(x\\) axis when \\(y=0\\). Solving this gives:\n\\[\nc - f( c)/f'( c)\n\\]\nOur goal is to compute this value for any \\(c > 0\\).\nDoing so is easy:\nf(x) = 10/(1+x^2) - 10*exp(-(1/2)*x^2)\nfp(x) = Dc(f)(x)\nintersection_point(c) = c - f(c)/fp(c)\nFor example, when \\(c=1\\) we have:\nc = 1;\nintersection_point(c)\nYou can tell from the graph of \\(f(x)\\) that this value should be more than 1, as it is.\nplot(f, .5, 2.1, legend=false)\nplot!(zero)\nplot!(x -> f(c) + fp(c)*(x-c))\n\nWe could have defined intersection_point to accept a function with:\nintersection_point(f, c) = c  - f(c)/Dc(f)(c)\nThen it could easily be reused for other problems.\n\n\n\n6.4.2 Practice\n\nQuestion\nLet\nf(x) = besselj(1, x)\nThis defines \\(f\\) as a Bessel function of the first kind with order \\(\\alpha=1\\). Plot the approximate derivative over the interval \\([0,5]\\). There is one zero. What is its approximate value:\n#| echo: false\nusing Roots\nval = find_zero(Dc(f), [0,5])\nnumericq(val, 1e-1)\n\n\nQuestion\nLet \\(f(x) = \\sin(\\cos(x))\\). Plot the approximate derivative of \\(f\\). How many zeros are there between \\(5\\) and \\(20\\)?\n#| echo: false\nanswer=5\nnumericq(answer, 1e-10)\n\n\nQuestion\nLet \\(f(x) = |x^2 - 2|\\). Plot the derivative of \\(f(x)\\) over the interval \\([-2,2]\\). How many critical points do you see? (A critical point is where the derivative is \\(0\\) or undefined.)\n#| echo: false\nanswer = 3\nnumericq(answer, 1e-10)"
  },
  {
    "objectID": "derivatives.html#automatic-differentiation",
    "href": "derivatives.html#automatic-differentiation",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.5 Automatic differentiation",
    "text": "6.5 Automatic differentiation\nWe discuss now Forward Mode Automatic Differentiation.\nAutomatic differentiation avoids the numeric instability issues of finite difference quotients by using a different approach. Whereas finite difference quotientss have a long history, automatic differentiation only dates back to the 50s.\nThe ForwardDiff package implements automatic differentiation.\nThe MTH229 package overloads the idea of ', so uses automatic differentiation when the notation f' is encountered.\nThat means, we can find derivatives, as familiarly as:\nf(x) = x^x\nf'(1)\nHere f is a function, f' is a derived function, and f'(1) is this derived function evaluated at 1 – just as with the use within a math text book.\nUnlike, finite difference quotients automatic differentiation does not have issues arising from the loss of precision encountered when subtracting two like-sized numbers. Unlike symbolic derivatives (such as those found by the Wolfram Alpha website used by your iPhone’s Siri) they can be computed quickly, even if the computations defining the function involve many steps.\nSo what is automatic differentiation? The idea of the forward mode is quite intuitive. The tangent line approximation of a function at the point \\(c\\) becomes\n\\[\nf(x) = f(c) + f'( c)(x-c) + O((x-c)^2)\n\\]\nWhere the notation \\(O(x-c)^2\\) means that the last term is not precisely spelled out, but is like some constant times the difference \\((x-c)^2\\). This has many applications, but for this one it reduces the knowledge of the function values at this level to two values \\((f(c), f'(c))\\)\nNow consider the product of two functions \\(f(x)\\) and \\(g(x)\\)? The above formula applied to \\(f \\cdot g\\) is:\n\\[\n(f\\cdot g)(x) = f(c) \\cdot g(c) + (f'( c)g( c) + f( c)g'( c))(x-c) + O((x-c)^2)\n\\]\nThis follows by the product rule. Again we have that two values determine the product \\(f\\cdot g\\) at this level, these being \\((f(c) \\cdot g(c)\\), and \\(f'( c)g( c) + f( c)g'( c)\\). But, this combination can be made from the values \\((f(c), f'(c))\\) and \\((g(c), g'(c))\\) which represent \\(f\\) and \\(g\\). Hence it is enough to know the two values for \\(f\\) and \\(g\\) to compute the two values for \\(f\\cdot g\\).\nIn fact, the rules of derivatives allow us to say the same for addition, subtraction, multiplication, division, powers and composition. For composition this is from the chain rule:\n\\[\n(f \\circ g)(x) = (f \\circ g)(c) + f'( g(c)) g'(c) (x-c) + O((x-c)^2).\n\\]\nAutomatic differentiation can be implemented by extending how we store a value, storing both \\((x, dx)\\) as above. With this, the rules of differentials inform us how we combine these values. For example:\n\n\\[\n(x, dx) + (y, dy) = (x + y, d(x+y)) = (x + y, 1dx +  1dy)\n\\]\n\\[\n(x, dx) \\cdot (y, dy) = (xy, d(xy)) = (xy, y dx + x dy)\n\\]\n\\[\n(x, dx)^n = (x^n, d(x^n)) = (x^n, n x^{n-1} dx)\n\\]\n\netc.\nFor functions we need to use the chain rule:\n\n\\[\nf((x, dx)) = (f(x), d(f(x))) = (f(x), f'(x) dx )\n\\]\n\n\n6.5.1 Examples\nUsing ', we see that plotting a function and its derivative is straightforward:\nf(x) = exp(-x)*sin(x)\nplot(f, 0, 2pi)\nplot!(f')\nSecond derivatives are also available:\nf(x) = x^2 - 2x\nplot(f, -2, 2)\nplot!(f')\nplot!(f'')\nHere is an example where we plot the tangent line and the function. The MTH229 package provides this function to compute a tangent line function:\n#| eval: false\ntangent(f, c) = x -> f(c) + f'(c)*(x-c)\nThis is employed as follows:\nf(x) = x^x\nc = 1\nplot(f, 1/2, 2)\nplot!(tangent(f, c))\n\n\nExample: AP Calculus question\nThe 2014 AP Calculus exam included this question:\nGrass clippings are placed in a bin, where they decompose. For \\(0 \\leq t \\leq 30\\), the amount of grass clippings remaining in the bin is modeled by \\(A(t) = 6.687(0.931)^t\\). Where \\(A(t)\\) is measured in pounds and \\(t\\) is measured in days.\n\nFind the average rate of change of \\(A(t)\\) over the interval of \\(0 \\leq t \\leq 30\\). Indicate units of measure.\nFind the value of \\(A'(15)\\). Using correct units, interpret the meaning of the value in the context of the problem.\nFind the time \\(t\\) for which the amount of grass clippings in the bin is equal to the average amount of grass clippings in the bin over the interval \\(0 \\leq t \\leq 30\\).\nFor \\(t > 30\\), \\(L(t)\\), the linear approximation to \\(A\\) at \\(t=30\\) is a better model for the amount of grass clippings remaining in the bin. Use \\(L(t)\\) to predict the time at which there will be 0.5% pound of grass clippings remaining in the bin. Show the work that leads to your answer.\n\nWe can do all this relatively quickly with the find_zero function from the Roots package.\nFirst, we define \\(A(t)\\):\nA(t) = 6.687 * (0.931)^t\nThe first question is answered by the slope of the secant line connecting \\((0,A(0))\\) and \\((30, A(30))\\):\nm = (A(30) - A(0)) / (30 - 0)\nThe units are in pounds per day.\nThe second question is done through the derivative, as follows:\nA'(15)\nThis also has units in pounds per day. This is the instantaneous rate of decomposition, and is less (in absolute value) than the average decay rate.\nThe mean value theorem tells us that there is at least one time where the instantaneous decomposition rate equals the average rate over the interval \\([0,30]\\). Thus the endpoints form a bracketing interval for the equation \\(A'(t) = m\\), which we solve with:\nfind_zero(t -> A'(t) - m, (0, 30))\nSo at 12.4 days, the instantaneous rate is equal to the average rate of decomposition over the first 30 days.\nBut this doesn’t really answer the question asked, which is about the average amount of grass clippings in the bin. For this we need the integral form of the mean value theorem. Skipping ahead a few lessons to solve this problem, we have:\na, err = quadgk(A, 0, 30)   # area under A from 0,30\navg = a/(30-0)\nfind_zero(t -> A(t) - avg, (0, 30))\nWe get the same answer – think about whether that is a coincidence.\nFinally, we can define \\(L(t)\\) using the point-slope form of the line. The point is \\((30, A(30))\\) and the slope is \\(A'(30)\\):\nL(t) = A(30) + A'(30) * (t - 30) # t > 30\nWe could restrict \\(L\\) to insist that \\(t > 30\\), but this isn’t necessary. We are asked to solve this. Using find_zero requires a bracket. We check that \\(L(30) > 0.5\\) and that \\(L(100)\\) is negative:\nL(30), L(100)\nSo, we can use \\([30, 100]\\) as a bracket for \\(L(t) - 0.5 = 0\\):\nfind_zero(t -> L(t) - 0.5, (30, 100))\nSo a bit over 35 days to decompose to half a pound.\nHere is a picture, showing the decay:\nf(t) = t <= 30 ? A(t) : L(t)\nplot(f, 0, 40)\n\n\n\n6.5.2 Practice\n\nQuestion\nWhich definition would be right for \\((x,dx) - (y, dy)\\)?\n#| echo: false\nchoices = [\n\"`(x - y, dx - y)`\",\n\"`(x-y, dx - dy)`\",\n\"`(x - dx, y -dy)`\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion (Find tangent line intersection)\nRedefine intersection_point as:\nintersection_point(f, c) = c - f(c)/f'(c)\nNow for \\(f(x) = 10/(1+x^2) - 10 \\cdot \\exp(-(1/2) \\cdot x^2)\\) and \\(c=1\\) find the intersection point.\n#| echo: false\nval = 2;\nnumericq(val, 1e-4)\n\n\nQuestion (What is the size of the error?)\nWe can compare the error at many different points with the following construct\n#| eval: false\nf(x) = exp(-x)*sin(x)\nfp(x) = exp(-x)*(cos(x) - sin(x))\n[abs(f'(x) - fp(x) ) for x in linspace(0, pi, 25)]\nWhat is the order (exponent) of the largest difference above?\n#| echo: false\nchoices = [\n\"`1e-10`\",\n\"`1e-14`\",\n\"`1e-17`\"\n];\nanswer = 3;\nradioq(choices, answer)"
  },
  {
    "objectID": "derivatives.html#error-analysis",
    "href": "derivatives.html#error-analysis",
    "title": "6  Approximate derivatives in Julia",
    "section": "6.6 Error analysis",
    "text": "6.6 Error analysis\nWe end with a digression on how big h should be to have the approximate derivatives as close as can be.\nThe choice of \\(h\\) in the derivative approximations above was done somewhat arbitrarily, with only the intuition that smaller \\(h\\)’s should produce more accurate approximations (which of course may be way off, as we are subtracting like-sized values in the derivative formula). Here we look a bit more closely at how to choose \\(h\\).\nAs mentioned, with a bit of work from the second semester of calculus one can learn that the mathematical error in the forward difference quotient is “order \\(h\\)” whereas the mathematical error in the central difference quotient is “order \\(h^2\\). This means that as \\(h\\) gets small the approximation error in the first is a multple of \\(h\\), but for the second a multiple of \\(h^2\\) – a much smaller error in general.\nHowever there is also error due to floating point approximation. Such error is different in that it gets bigger as \\(h\\) gets smaller. So one error gets bigger, the other gets smaller. So clearly if \\(h\\) gets too small, the floating point error will dominate and the overall error will not get smaller, rather larger.\nSo, how big is the floating point error? For any given number, it can be roughly as big as the the machine precision amount, \\(\\epsilon\\). So in the forward-difference quotient approximation we could have errors in both terms \\(f(x+h)\\) and \\(f(x)\\) so the total error could be as big as \\(2\\epsilon\\). But this is divided by \\(h\\) as we have:\n\\[\n\\frac{f(x+h) - f(x)}{h} = \\frac{float(f(x +h)) + \\epsilon - float(f(x_) + \\epsilon}{h} =\n         \\frac{float(f(x+h))-float(f(x))}{h} + \\frac{2\\epsilon}{h}.\n\\]\nThe errors may or may not cancel so the algebra with \\(\\epsilon\\) is unusual to the untrained eye. It basically takes into account the worse case.\nThe key is the \\(2\\epsilon/h\\) term – it gets bigger as \\(h\\) gets smaller.\nSo if each floating point approximation is no more off than \\(\\epsilon\\), we have this bound on the error:\n\\[\n\\text{error} \\leq \\frac{2\\epsilon}{h} + (M/2)h\n\\]\nWhere \\(M\\) is a constant that depends on the maximum absolute value of the second derivative and the \\(1/2\\) comes from second semester calculus. Choosing \\(h\\) to make this as small as possible is possible with some calculus involving the derivative, but for now we simply note the answer is \\(h=((2\\epsilon)/(M/2))^{1/2}\\).\nTaking \\(\\epsilon\\) as machine tolerance and (conveniently) \\(M=1\\) we get\n\\[\nh_{min} = \\sqrt((2\\epsilon)/(1/2)) \\approx 10^{-8}\n\\]\nOr more precisely:\nsqrt( (2*eps())/(1/2) )\nWe can check this is about right,but graphing on a different scale:\nf(h; M=1) = 2*eps()/h + (M/2)*h\ng(x) = log10(f(10.0^(-x)))\nplot(g, 1, 10)          # min near 8, which means h like 1e-8\nNumerically, we can check how this basically works for some test function:\nf(x) = exp(x) - x^3\nfp(x) = exp(x) - 3x^2\n[hs [Df(f,h=h)(.5) - fp(.5) for h in hs] ]\nWe see the best case is around \\(h=10^{-8}\\), as expected by the theory.\n\n6.6.1 Approximation errors for the central difference quotient\nFor the central difference quotient, the errors are different. The error in \\(h\\) becomes:\n\\[\n\\text{error} \\leq (2\\epsilon)/(2h) + (M/6) h^2\n\\]\nThis gives \\((3\\epsilon/M)^{1/3}\\) as the choice for \\(h\\) that minimizes the right-hand expression.\nTaking \\(\\epsilon\\) as the machine tolerance and (conveniently) \\(M=3\\) we get\n\\[\nh_{min} \\approx 10^{-6}\n\\]\nWe can again check how this works for our function and point:\n[hs [ Dc(f,h=h)(.5) - fp(.5) for h in hs] ]\n\n\n6.6.2 Practice\n\nQuestion (Best depends on the function and value)\nA subtle point above is that we are minimizing an upper bound in \\(h\\) with an assumption, not the actual error. The actual answer may differ as it depends on a function and the point of evaluation. Look at the function \\(f(x) = x^2 - 2x\\) and compare the values at \\(0.5\\) as above:\nhs = [(1/10)^i for i in 1:16]\nf(x) = x^2 - 2x\nfp(x) = 2x - 2\n[hs [Dc(f,h=h)(.5) - fp(.5) for h in hs] ]\nWhat is the best value of \\(h\\)?\nFor which of these values of \\(h\\) is the error smallest?\n#| echo: false\nchoices = [\n\"`1e-3`\",\n\"`1e-6`\",\n\"`1e-8`\",\n\"`1e-12`\"\n];\nanswer = 1;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion (Error analysis)\nConsider these commands:\n#| eval: false\nf(x) = sin(x)\nfp(x) = cos(x)\n[hs [ Dc(f,h=h)(.5) - fp(.5) for h in hs] ]\nDo they show the smallest error around \\(10^{-6}\\) as expected?\n#| echo: false\nbooleanq(true)"
  },
  {
    "objectID": "first-second-derivatives.html",
    "href": "first-second-derivatives.html",
    "title": "7  Exploring first and second derivatives with Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "first-second-derivatives.html#introduction",
    "href": "first-second-derivatives.html#introduction",
    "title": "7  Exploring first and second derivatives with Julia",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nThis project explores the relationship between a function, \\(f(x)\\) and its first and second derivatives.\nThe following definitions describe features of functions over an interval:\n\nThe function \\(f(x)\\) is positive on an interval \\(I=(a,b)\\) if \\(f(x) > 0\\) for any \\(x\\) in \\((a,b)\\).\nThe function \\(f(x)\\) is increasing (strictly) on an interval \\(I=(a,b)\\) if \\(f(x) < f(y)\\) whenever \\(a < x < y < b\\).\nThe function \\(f(x)\\) is concave up on an interval \\(I=(a,b)\\) if any secant line between values \\(x\\) and \\(y\\) with \\(a < x < y < b\\) lies above the graph of \\(f(x)\\).\n\n\n\n\n\n\n\nNote\n\n\n\nThere are similar definitions for negative, decreasing, and concave down.\n\n\n\n7.1.1 Consequences\nYou may be more familiar with these implications for functions with derivatives:\n\nAn increasing function will have the property that any secant line connecting \\(x\\) and \\(y\\) with \\(a < x < y < b\\) will have positive slope.\nAn increasing function on \\(I\\) that is differentiable has \\(f'(x) \\geq 0\\) on \\(I\\).\nIf \\(f'(x)\\) exists and is positive on \\(I=(a,b)\\), then \\(f(x)\\) is increasing on \\(I\\).\nIf \\(f'(x)\\) exists and is increasing on \\(I=(a,b)\\), then \\(f(x)\\) is concave up on \\(I\\).\nIf \\(f''(x)\\) exists and is positive on \\(I=(a,b)\\), then \\(f'(x)\\) is increasing on \\(I\\), and so \\(f(x)\\) is concave up on \\(I\\).\n\n\n\n\n\n\n\nPositive and negative\n\n\n\nPay attention to the difference between positive and non-negative. For example, an increasing, differentiable function on I=(a,b) is only guaranteed to have a non-negative derivative – not a positive derivative on I."
  },
  {
    "objectID": "first-second-derivatives.html#graphically-identifying-positive-increasing-concave-up-critical-points",
    "href": "first-second-derivatives.html#graphically-identifying-positive-increasing-concave-up-critical-points",
    "title": "7  Exploring first and second derivatives with Julia",
    "section": "7.2 Graphically Identifying positive, increasing, concave up, critical points, …",
    "text": "7.2 Graphically Identifying positive, increasing, concave up, critical points, …\nWe load MTH229 to provide access to graphing, the ' notation, and the plotif function:\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings\nThe plotif function from the MTH229 package makes it easy for us to highlight when a function is positive. This function (plotif(f, g, a, b)) plots the function \\(f(x)\\) twice over [a,b], the second time doing so only if \\(g(x) \\geq 0\\).\nWe can plot when a function is positive by using f for g. For example, when \\(f(x) = x^3 - 2x - 1/2\\) we make the plot\nf(x) = x^3 - 2x - 1/2\nplotif(f, f, -2, 2)\nIn this graph, we estimate graphically that the intervals \\((-1.2, 0.2)\\) and \\((1.5, 2)\\) are where \\(f\\) is positive within this viewing window.\nWe can do the same with the derivative, then our graph will show when the function is increasing:\nplotif(f, f', -2, 2)\nAgain, we eyeball from the graph to estimate that this occurs on \\((-2, -0.8)\\) and \\((0.8, 2)\\).\nAnd of course, using when the second derivative is positive shows where f is concave up:\nplotif(f,  f'', -2, 2)\nWe can see the function is concave up on \\((0, 2)\\).\n\nQuestion\nGraphically identify when the function \\(f(x) = x^x\\) is increasing on \\((0,2)\\)\n#| echo: false\nchoices = [\"(0,2)\", \"(0.4, 2)\"];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nGraphically identify when the function \\(f(x) = \\sqrt{|1 - x^2|}\\) is increasing on the interval \\([-2, 2]\\).\n#| echo: false\nchoices = [\"(-2, -1) and (0,1)\",\n    \"(-1, 0) and (1, 2)\",\n    \"(-2, 2)\"];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nGraphically identify when the function \\(f(x) = x^2 \\cdot e^{-x}\\) is concave up on the interval \\((0,10)\\).\n#| echo: false\nchoices = [\"(0, 0.6) and (3.5, 10)\",\n    \"(0.6, 3.5)\",\n    \"(0, 2)\",\n    \"(0,10)\"];\nanswer = 1;\nradioq(choices, answer)"
  },
  {
    "objectID": "first-second-derivatives.html#relationships",
    "href": "first-second-derivatives.html#relationships",
    "title": "7  Exploring first and second derivatives with Julia",
    "section": "7.3 Relationships",
    "text": "7.3 Relationships\nSuppose we only know indirect things about a function \\(f(x)\\), how much can we say?\nWe previously mentioned two basic relationships:\n\nIf \\(f'(x) > 0\\) on an interval \\((a,b)\\) then the function \\(f(x)\\) is increasing on \\((a,b)\\). (It may also increase when \\(f'(x)=0\\), but it isn’t guaranteed.)\n\n\nIf \\(f''(x) > 0\\) on \\((a,b)\\) then the function \\(f(x)\\) is concave up on \\((a,b)\\).\n\nSimilar statements can be made for negative values of the derivative and second derivative.\nFor example, lets suppose we know that the derivative of \\(f(x)\\) is \\(f'(x) = \\exp(x)\\). What can we say about \\(f(x)\\) on the interval \\((0,4)\\)?\nWe make two graphs:\nfp(x) = exp(x)\nplotif(fp, fp, 0, 4)\nplotif(fp, fp', 0, 4)\nFrom the graphs we see that \\(f'(x)\\) is always positive and increasing.\nFrom the first fact (\\(f'(x) > 0\\)) we know that \\(f(x)\\) is increasing on this interval.\nFrom the second fact (\\(f'(x)\\) is increasing) we know that \\(f(x)\\) is concave up on this interval.\nDo we know any specific values, or even less ambitiously, when \\(f(x)\\) is positive? The answer must be no – we could always add a constant to \\(f(x)\\) and not effect its derivative.\n\nNow suppose we have a different \\(f(x)\\). In this case all we know is the second derivative is \\(f''(x) = x^2 - 2x\\). What can we say about \\(f(x)\\) on the interval \\((-1,3)\\)?\nA plot to see where the second derivative is positive will show that this \\(f''(x)\\) is positive on \\((-1, 0)\\) and \\((2,3)\\):\nfpp(x) = x^2 - 2x\nplotif(fpp, fpp, -1, 3)\nThis means \\(f(x)\\) is concave up on these same intervals.\nCan we tell if our unknown \\(f(x)\\) is increasing? Nope, we have no such ability. We could always add a term \\(mx\\) to \\(f(x)\\) and keep the same second derivative. So we can’t tell if the function \\(f(x)\\) is increasing and we can’t tell where the function \\(f(x)\\) is positive, but we can say where it is concave up when we all we know is a second derivative.\n\nQuestion\nYou know that \\(f'(x) = |x|\\). Over \\([-1,1]\\) where if \\(f(x)\\) increasing and where is it concave up?\n#| echo: false\nchoices=[\n    \"You don't know -- the derivative of |x| does not exist\",\n    L\"f is increasing on $(0,1)$ and concave up on $(-1,1)$\",\n    L\"f is increasing on $(-1,1)$ and concave up on $(0,1)$\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nSuppose \\(f'(x) = (x^4 - x^2 + 2)/(x^4 - 2x^2 + 1)\\). When is \\(f(x)\\) increasing on \\((-2, 2)\\)?\n#| echo: false\nchoices = [\"On (-2, -1) and (0, 1)\",\n    \"On (-1, 1)\",\n    \"Wherever it is defined\"];\nanswer = 3;\nradioq(choices, answer)\n\n\nQuestion\nIf \\(f'(x) = \\tan(x) - 3x/2\\). When is \\(f(x)\\) concave down on the interval \\((-\\pi/3, \\pi/3)\\)?\n#| echo: false\nchoices = [\n    raw\"``(-\\pi/3, \\pi/3)``\",\n    raw\"``(-0.6, 0.6)``\",\n    raw\"``(-\\pi/3, 0)``\"\n];\nanswer = 2;\nradioq(choices, answer)"
  },
  {
    "objectID": "first-second-derivatives.html#classifying-critical-points",
    "href": "first-second-derivatives.html#classifying-critical-points",
    "title": "7  Exploring first and second derivatives with Julia",
    "section": "7.4 Classifying critical points",
    "text": "7.4 Classifying critical points\nThe first- and second-derivative tests are a means to classify if a critical point is also a local extrema. A local extrema will always correspond to a critical point – but not necessarily vice versa. There are two theorems that ensure a critical point will be a local extrema:\n\nThe first derivative test\nIf \\(c\\) is a critical point and \\(f'(x)\\) changes sign at \\(x=c\\), then \\((c,f( c))\\) will be a local extrema. (If the sign change is from positive to negative, it will be a local maximum.) If there is no sign change, the critical point is not a local extrema.\n\n\nThe second derivative test\nIf \\(c\\) is a critical point and \\(f''(x) \\neq 0\\) then \\((c,f( c))\\) will be a local extrema. If \\(f''( c) > 0\\) this will be a local minimum and if \\(f''( c) < 0\\) a local maximum. (Nothing conclusive can be said when \\(f''(c)=0\\).)\n\n\nFor example, let \\(f(x) = 2\\sin(x) + \\cos(2x)\\). Find all critical points on \\([0, 2\\pi]\\).\nAs \\(f(x)\\) is everywhere differentiable, these critical points would be where the derivative is \\(0\\). A plot helps us identify how many and roughly where:\nf(x) = 2sin(x) + cos(2x)\nplot(f', 0, 2pi)\nWe see four: one near 0.8, one near 1.5, one near 2.5 and one near\n\nWe use find_zeros to identify:\n\ncps = find_zeros(f', 0, 6)\nUse the first derivative test to classify these values as relative maximum or minimum. From the graph of f' we see at the first one the derivative is changing sign from positive to negative at the first one (hence a local maximum), and this alternates as we go along.\nThe MTH229 package has a sign_chart function to do check numerically for sign changes of a function:\nsign_chart(f', 0, 4)\nSo by the first derivative test we have a max, min, max, min which we see when we plot f:\nplot(f, 0, 2pi)\nTo get the same from the second derivative test, we evaluate \\(f''(x)\\) at these four points:\nf''.(cps)\n(Using the dot broadcasts f'' over all the values in cps.)\nIf you wanted something fancy, you could convert using sign:\n[\"max\", \"can't tell\", \"min\"][2 .+ Int.(sign.(f''.(cps)))]\n\nQuestion\nLet \\(f'(x) = x^4 - 4x^2 + 1\\). Classify all relative extrema of \\(f(x)\\) on the interval \\((-1, 1)\\).\n#| echo: false\nchoices =[\n    \"at 0 there is a maximum\",\n    \"Near -1.93185 and 0.51763 there are relative maxima, near 1.93185 and -0.51763 there are relative minima\",\n    \"Near -0.51763 there is a relative minimum, near 0.51763 there is a relative maximum\"];\nanswer = 3;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion\nLet fp(x) = (2x-1)/cbrt(x^2 - x - 2)^2). Over the interval \\((-1.5,1.5)\\) identify all relative maxima and minima of \\(f(x)\\).\n#| echo: false\nchoices=[\"-1 is a relative min and 0.5 is a maximum\",\n    \"-1 is a critical point but not an extram, 0.5 is a relative minimum\",\n    \"This function only has an asymptote at -1, no relative extrema\"];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nSuppose, \\(f(x)\\) has a critical at \\(0\\) and \\(1\\). If possible, classify them as relative maximum or minimum assuming \\(f''(x) = 1 - 2x - \\sin(x)\\)\n#| echo: false\nchoices = [\n    \"0 is  relative minimum, 1 is a relative max\",\n    \"0 is a relative maximum, 1 is a relative minimum\",\n    \"both are relative maximum\",\n    \"One can not say from the given information.\"\n];\nanswer = 1;\nradioq(choices, answer)"
  },
  {
    "objectID": "newton.html",
    "href": "newton.html",
    "title": "8  Newton’s method using julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "newton.html#introduction",
    "href": "newton.html#introduction",
    "title": "8  Newton’s method using julia",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nNewton’s method is an old method for approximating a zero of a function, \\(f(x)\\):\n\\[\nf(x) = 0\n\\]\nPreviously we discussed the bisection method which applied for some continuous function \\(f(x)\\) which changed signs between \\(a\\) and \\(b\\), points which bracket a zero. Not only did we need to find these bracketing points – which wasn’t hard from a graph, more importantly the actual algorithm is pretty slow.\nIf the function \\(f\\) is sufficiently differentiable, then Newton’s method may work to find a zero. Unlike the bisection method which is slow but guaranteed to find a root by the intermediate value theorem, Newton’s method is fast (once it is close) but has no such guarantee of converging. In this project, we’ll see how to implement the algorithm, try some examples, and then look at what can go wrong.\nThe MTH229 package provides a function newton for easily performing Newton’s method, utilizing a function from the Roots package. More usefully, we will see that find_zero, which we used for bisection, can also be used for root finding with an algorithm that is a bit more robust than Newton’s method.\nTo begin, we load MTH229 and Plots. In the background this loads Roots:\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings"
  },
  {
    "objectID": "newton.html#basic-idea",
    "href": "newton.html#basic-idea",
    "title": "8  Newton’s method using julia",
    "section": "8.2 Basic idea",
    "text": "8.2 Basic idea\nThe idea behind Newton’s method is simple – linear approximation. That is, most functions at any given point are well approximated by the tangent line at that point. If we have a good guess \\(x_n\\), then we can improve this guess iteratively by replacing it with the zero, \\(x_{n+1}\\), of the tangent line at \\((x_n, f(x_n))\\).\n\n\n\nNewton, one step\n\n\nA simple picture shows that we have a triangle with base \\(x_{n+1} - x_{n}\\), rise \\(0 - f(x_n)\\) and slope \\(f'(x_n)\\), using the “rise over run” formula:\n\\[\nf'(x_n) = \\frac{-f(x_n)}{x_{n+1} - x_{n}}.\n\\]\nThe basic algorithm of Newton’s methods solves this to get:\n\\[\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n\\]\nSome books write the right-hand side as \\(x_n - f'(x_n)^{-1} f(x_n)\\), a form that generalizes to different settings.\nLike the bisection method, Newton’s method is an iterative method. One begins with a (suitable) guess \\(x_0\\). From that the algorithm produces \\(x_1\\) which is used to produce \\(x_2\\), etc. The idea is that one eventually will settle on a value \\(x_n\\) sufficiently close to the desired root.\nMathematically, the indices indicate that the right hand side is computed and assigned to the left hand side. This is exactly what is done in assignment within julia, so the above simply becomes:\n#| eval: false\nx = x - f(x)/f'(x)\nWhere f(x) is the function and f'(x) its derivative. (In this case found by automatic differentiation.) This line starts with a previously defined value of x and updates it accordingly.\nThe updating is continued – by executing the exact same command – until either the algorithm has gotten close enough to an answer (i.e., it has converged) or we have given up on it converging.\nHere is an example to find a zero of the function: \\(f(x) = x^3 - 2x - 5\\).\nA quick graph shows a root near 2:\nf(x) = x^3 - 2x - 5\nplot(f, -3, 3)\nHere we improve the estimate for the root near 2 using Newton’s method. We will need the first derivative, which we denote fp\nfp(x) = 3x^2 - 2\nx = 2               # starting value, x_0\nx = x - f(x)/fp(x)      # new value, x_1\nx, f(x)\nWe can visualize our progress as follows, noting that x holds \\(x_1\\), and zooming into the domain \\([1,3]\\):\nx0, x1 = 2, x\nplot(f, 1, 3, legend=false)\nplot!([x0, x0, x1], [0, f(x0), 0])  # why these values?\nscatter!([x0, x1], [0, 0])\nContinuing, though without visualizing the progress, this next step will compute \\(x_2\\):\nx = x - f(x)/fp(x)\nx, f(x)\nThis next step will compute \\(x_3\\):\nx = x - f(x)/fp(x)\nx, f(x)\nThis next step will compute \\(x_4\\):\nx = x - f(x)/fp(x)\nx, f(x)\nThis next step will compute \\(x_5\\):\nx = x - f(x)/fp(x)      # x stopped changing\nx, f(x)\nWe see that \\(x_4=x_5\\), so the algorithm has stabilized. We also see that \\(f(x_4)\\) is basically \\(0\\) (Recall, eps() is the machine precision, or the size of the difference between floating point values at \\(1.0\\) is basically \\(10^{-16}\\), the size of \\(f(x_4)\\).)\nYou can see in this case that the convergence happens quickly as soon as the algorithm gets close.\nThe approximate root is \\(x_4\\). It is important to realize that the actual, exact, answer is not likely to be the value computed by Newton’s method, which we call xstar at times. In most cases, the true answer will be irrational and xstar a floating point number, which ultimately can never be better than an approximation to an irrational number.\nThe above example iterated until it was clear the algorithm does not improve itself, as the values returned did not change. This need not be the case for every problem.\nRather, we can determine two ways that the number is close enough to the answer:\n\nThe sequence of x’s stop changing by much\nthe values f(x) get close enough to zero.\n\nIn the above, the first one was used. In either case, rather than look for values to be equal (e.g. \\(x_{n+1} = x_{n}\\) or \\(f(x_n) = 0\\), we look at whether these two things are close enough to be so. That means for some tolerance, we stop when the change in the x’s is smaller than the tolerance or f(x) is smaller – in absolute value – than the tolerance.\n\n8.2.1 Repeating steps\nThe above approach – basically repeating steps – can be tedious. There will be a function to do this for you (newton). One can use copy and paste to do much of this though:\nf(x) = x^3 - 2x - 5\nx = 2\nx = x - f(x)/f'(x)\nx = x - f(x)/f'(x)\nx = x - f(x)/f'(x)\nx = x - f(x)/f'(x)\nx = x - f(x)/f'(x)\n\n(x, f(x))\n\n\n\n\n\n\nNote\n\n\n\nNewton looked at this same example in 1699 (B.T. Polyak, Newton’s method and its use in optimization, European Journal of Operational Research. 02/2007; 181(3):1086-1096.) though his technique was slightly different as he did not use the derivative, per se, but rather an approximation based on the fact that his function was a polynomial (though identical to the derivative). Raphson (1690) proposed the general form, hence the usual name of Newton-Raphson method.\n\n\n\n\n\n8.2.2 Practice\n\nQuestion\nUsing Newton’s method to find \\(\\sqrt{k}\\) (by solving for roots of \\(f(x) = x^2 - k\\)) is also referred to as the Babylonian method, due to its origins. The resulting method\n\\[\nx_{n+1} = \\frac{1}{2}(x_n + \\frac{k}{x_n})\n\\]\nis described by the first-century Greek mathematician Hero of Alexandria.\nLet \\(k=15\\) and \\(x_0\\) be \\(4\\). What is the value of \\(x_3\\)?\n#| echo: false\nx0 = 4\nf(x) =  1/2*(x + 15/x)\nval = f(f(f(x0)))\nnumericq(val, 1e-4)\n\n\nQuestion\nThe function \\(f(x) = \\sin(x)\\) has derivative \\(f'(x) = \\cos(x)\\). Use Newton’s method to solve \\(f(x) = 0\\) starting at \\(3\\). Repeat 5 times. What value do you get for x?\n#| echo: false\nf(x) = x - sin(x)/cos(x)\nx0 = 3\nval = f(f(f(f(x0))))\nnumericq(val, 1e-14)\n(This can be used to compute \\(\\pi\\) numerically, as the convergence is very fast. Here it takes 4 steps to verify.)\n\n\nQuestion\nLet \\(f(x) = x^2 - 3^x\\). This has derivative \\(2x - 3^x \\cdot \\log(3)\\). Starting with \\(x_0=0\\), what does Newton’s method converge on?\n#| echo: false\nusing Roots\nf(x) = x^2 - 3^x;\nfp(x) = 2x - 3^x*log(3);\nval = newton(f, fp, 0);\nnumericq(val, 1e-14)"
  },
  {
    "objectID": "newton.html#implementing-a-newtons-method-function",
    "href": "newton.html#implementing-a-newtons-method-function",
    "title": "8  Newton’s method using julia",
    "section": "8.3 Implementing a Newton’s method function",
    "text": "8.3 Implementing a Newton’s method function\nFor iterative algorithms it is better to repeat the expression until something happens – not a fixed number of times. In this case, we need a criteria to decide if the algorithm has converged. We shall use the following:\n\nIf the value of \\(|x_{n+1} - x_n| < tol\\) the algorithm has converged\nIf the value of \\(|f(x_n)| < tol\\) the algorithm has converged\nIf the above hasn’t happened by \\(n=100\\) the algorithm fails to converge\n\nThis isn’t perfect, but will be sufficient. (Well, in fact no stopping rule can be perfect, but this one doesn’t account for the relative size of the \\(x_n\\)s which can be important.)\nThe first two steps require a tolerance. We will use 1e-14 for this. This is about 100 times the machine precision, eps(), which is sufficient when the answers are moderate in size. This is not very good if the answers are very large.\nA basic algorithm is to repeat a step of Newton’s method until the above occurs. We wrap this up in a function for reuse, and employ a while loop to repeat the update step until something happens:\nfunction nm(f, fp, x)\n     xnew, xold = x, Inf\n     fn, fo = f(xnew), Inf\n\n     tol = 1e-14\n     ctr = 1\n\n     while (ctr < 100) && (abs(xnew - xold) > tol) && ( abs(fn - fo) > tol )\n       x = xnew - f(xnew)/fp(xnew) # update step\n       xnew, xold = x, xnew\n           fn, fo = f(xnew), fn\n       ctr = ctr + 1\n     end\n\n     if ctr == 100\n        error(\"Did not converge in 100 steps\")\n         else\n       xnew, ctr\n         end\nend\n\nHere we use the nm function to find a zero of this polynomial:\nf(x) = x^3 - 5x + 1\nfp(x) = 3x^2 - 5\nxstar, ctr = nm(f, fp, 0)   # takes 6 steps\nHowever, the MTH229 package provides the newton function. So we shall use that in the sequel. To see the number of steps, the argument verbose=true may be given.\n\nWe revisit a problem from a previous project, finding zeroes of the function \\(f(x) = \\exp(x) - x^4\\). We know from previous work that there are three of them. Let’s find one near \\(x=2\\):\nf(x) = exp(x) - x^4\nx = 2\nnewton(f, 2)  # newton will use automatic differentiation for the derivative\nIt took 8 steps and we are this close:\nxstar, f(xstar)\nIn this case, the answer is exact up to floating point round off.\n\n8.3.1 Practice\n\nQuestion\nRepeat the problem of finding a root of \\(f(x) = \\exp(x) - x^4\\) starting at \\(x=2\\). (newton(f, 2, verbose=true)). How many iterations does it take with the default tolerances?\n#| echo: false\n#f(x) = exp(x) - x^4;\n#fp(x) = exp(x) - 4x^3;\n#xstar, ctr = nm(f, fp, 2);\nnumericq(6, 1e-1)\n\n\nQuestion\nIf we repeat with \\(f(x) = \\exp(x) - x^4\\) but start now at \\(x=8\\) where does the algorithm converge?\n#| echo: false\nxstar, ctr = nm(f, fp, 8);\nnumericq(xstar, 1e-6)\n\n\nQuestion\nLet \\(f(x) = \\sin(x) - \\cos(4\\cdot x)\\).\nStarting at \\(\\pi/8\\), solve for the root returned by Newton’s method\n#| echo: false\nk1=4\nf(x)  = sin(x) - cos(k1*x);\nfp(x) = cos(x) + k1*sin(k1*x);\nval = newton(f, fp, pi/(2k1));\nnumericq(val)"
  },
  {
    "objectID": "newton.html#numeric-derivatives",
    "href": "newton.html#numeric-derivatives",
    "title": "8  Newton’s method using julia",
    "section": "8.4 Numeric derivatives",
    "text": "8.4 Numeric derivatives\nIn order to use Newton’s method we need to evaluate \\(f'(x)\\). We have used automatic differentiation above through f'(x). Automatic differentiation returns a numerically accurate value for the derivative.\nHowever, Newton’s method is actually fairly robust to using other related values to the derivative. That is the method will converge, though perhaps not as fast as with the derivative.\n\n8.4.1 The secant method\nThe secant method is perhaps the oldest numerical linear algebra tool dating back over 3000 years well before Newton’s method. Rather than use the derivative at \\(x_i\\) to compute \\(x_{i+1}\\), the secant line is used between \\(x_{i-1}\\) and \\(x_i\\). This method will also converge to a zero with a good starting point, though not nearly as quickly as Newton’s method.\nYou can check – if you want – by repeating the last command until the change in x2 is within your tolerance:\nx2, x1 = 1, 2           # initial guess of 2\nf(x) = x^2 - 2          # some function\nfp(x1,x2) = (f(x1) - f(x2))/(x1 - x2)\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2 # update step\nWe can repeat via copy and paste:\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2\nx2, x1 = x2 - f(x2)/fp(x1, x2), x2\n\nx2, f(x2)\nThe last line shows the algorithm has basically converged, as the values agree to \\(10^{-14}\\). We have\n\n\n8.4.2 Using forward differences\nRecall the forward difference approximation to the derivative:\n\\[\nf'(x) \\approx \\frac{f(x + h) - f(x)}{h}\n\\]\nFor some small \\(h\\) (with \\(h=10^{-8}\\) a reasonable choice for many functions). This can be used\nOne can also use approximate derivatives based on forward differences in place of \\(f'(x)\\) in the formula. Again, this won’t be as fast.\nThe update step \\(x - f(x)/f'(x)\\) becomes\n\\[\nx - \\frac{h \\cdot f(x)}{f(x+h) - f(x)}.\n\\]\nThe issue with this approximation is when the estimated value gets close to the actual root, the value of \\(h\\) becomes too large. Steffenson’s method replaces \\(h\\) with \\(f(x)\\), which for values close to a root gets quite small. This improves the convergence rate to be on par with Newton’s method. In this case, the update step looks like\n\\[\nx - \\frac{f(x)^2}{f(x+ f(x)) - f(x)}.\n\\]\n\n\n8.4.3 Problems\n\nQuestion\nUse the secant method to find a root to \\(f(x) = \\cos(x) - x^3\\) starting with \\(x_0=1/2\\) and \\(x_1=1\\).\n#| echo: false\nusing Roots\nf(x) = cos(x) - x^3\nx1, x0 = 1, 1/2\nx = find_zero(f, (x0, x1), Roots.Secant())\nnumericq(x, 1e-10)\n\n\nQuestion\nUse the secant method to find a root to \\(f(x) = x^5 + x - 1\\) starting with \\(x_0=1/2\\) and \\(x_1=1\\).\n#| echo: false\nf(x) = x^5 + x - 1\nx1, x0 = 1, 1/2\nx = find_zero(f, (x0, x1), Roots.Secant())\nnumericq(x, 1e-10)"
  },
  {
    "objectID": "newton.html#the-find_zero-function",
    "href": "newton.html#the-find_zero-function",
    "title": "8  Newton’s method using julia",
    "section": "8.5 The find_zero function",
    "text": "8.5 The find_zero function\nThere are also very fast algorithms which do not require a derivative. The Roots package provides an interface to these through the find_zero function.\nThe find_zero function has two interfaces:\n\nwhen called with a bracketing interval, as in find_zero(f, (a,b)), it will use a bisection method to find a root.\nwhen called with a starting point, as in find_zero(f, a), it will use an iterative algorithm to search for a root.\n\nMany bracketing methods (like bisection) are guaranteed to converge, but can be slow. The iterative algorithm used by default with find_zero tries to speed the convergence up, but if along the way it finds a bracketing interval, that will guarantee convergence.\nWe focus on the simplest usage of find_zero where an initial guess is supplied and the default order is used. Here is an example to find \\(-\\sqrt{2}\\):\nf(x) = x^2 - 2\nfind_zero(f, -1)\n\n8.5.1 Using find_zero and a graph to find all roots.\nLet’s look, again, at the task of finding all zeros to the function \\(e^x - x^4\\). We follow a standard approach:\n\ngraph the function to roughly identify potential zeros\nuse these as starting points for find_zero to improve\n\nThe following graph suggests, perhaps, there may be \\(3\\) zeros, one near \\(9\\), one near \\(2\\) and one near \\(-1\\).\nf(x) = exp(x) - x^4\nplot(f, -5,9)\nWe can improve these guesses with\nfind_zero(f, 9), find_zero(f, 2), find_zero(f, -1)\nThe above can be written without repeating find_zero by using a comprehension:\n[find_zero(f, x) for x in [9, 2, -1]]\nOr even more compactly, using the broadcast notation:\nfind_zero.(f, [-1, 2, 9])\n\nAs another illustration, let \\(f(x) = \\cos^2(x^2)\\) on \\([-1,2]\\). Find all the zeros of the derivative of \\(f(x)\\).\nWe graph the derivative to identify starting points:\nf(x) = cos(x^2)^2\nplot(f', -1, 2)\nWe see there are 3 potential zeros, one near 0, one near 1.2 and close to 1.7. Here we improve our guesses:\nxs = find_zero.(f', [0, 1.2, 1.7])   # or [find_zero(f', x) for x in [0, 1.2, 1.7]]\nThe function values at these points can be found with\nf.(xs)               # or map(f, xs) or [f(x) for x in xs]\n\nfind_zeros\nFor such tasks, find_zeros also works well. This function looks for all zeros in the interval [a,b]:\nfind_zeros(f, -1, 2)\n\n\n\n8.5.2 Practice\n\nQuestion\nLet\n\\[\nf(x) = 4x^4 -5x^3 + 4x^2 -20x - 6\n\\]\nApply Newton’s method with \\(x_0=0\\) using an automatic derivative. What value does it converge to?\n#| echo: false\nf(x) = 4x^4 -5x^3 + 4x^2 -20x - 6\nval = newton(f, 0);\nnumericq(val, 1e-10)\n\n\nQuestion\nLet’s try with a function where the derivative is not known easily. If we set\n\\[\nf(x) = x^x - 2\n\\]\nCan we find a root using Newton’s method, where \\(x > 0\\)?\nWe graph the function to see, using a smallish interval at first:\nf(x) = x^x - 2\nplot(f, 0, 2)\nplot!(zero)\nEyeing this, we pick an initial point, \\(1\\), for Newton’s method (newton(f, 1)) to the right of the minimum, which appears to be around \\(x=0.35\\).\nWhat is the value of the approximate zero?\n#| echo: false\nxstar = newton(f, 1)\nnumericq(xstar, 1e-8)\n\n\nQuestion\nUse find_zero to find the one root of x^5 + x - 1. First plot to get an estimate.\n#| echo: false\nf(x) = x^5 - x - 1\nxstar = find_zero(f, 1)\nnumericq(xstar, 1e-8)\n\n\nQuestion\nLet \\(f(x) = 5/\\sin(x) + 8/\\cos(x)\\), Starting at \\(x=\\pi/4\\), use find_zero to find a root of the derivative of \\(f(x)\\) given by f'.\n#| echo: false\nf(x) = 5/sin(x) + 8/cos(x)\nxstar = find_zero(f', pi/4)\nnumericq(xstar, 1e-8)\n\n\nQuestion\nThe tangent line of f at c can be computed by\ntangent(f, c) = x -> f(c) + f'(c) * (x - c)\nLet \\(f(x) = x^2 - 3x + 5\\). Use find_zero to find the intersection point of the tangent line at \\(1\\) and the tangent line at \\(3\\). Where does this happen?\n(Hint, apply find_zero to h(x) = tangent(f, 1)(x) -  tangent(f, 3)(x) starting at 1.)\n#| echo: false\ntangent(f, c) = x -> f(c) + f'(c) * (x - c)\nf(x) = x^2 - 3x + 5\nh1(x) = tangent(f, 1)(x) - tangent(f, 3)(x)\nxstar = find_zero(h1, 1)\nnumericq(xstar, 1e-8)"
  },
  {
    "objectID": "newton.html#various-issues-with-newtons-method",
    "href": "newton.html#various-issues-with-newtons-method",
    "title": "8  Newton’s method using julia",
    "section": "8.6 Various issues with Newton’s method",
    "text": "8.6 Various issues with Newton’s method\nAs great as Newton’s method is, it won’t always work for various reasons, some of which are described in the following. Here is what you need to keep in mind. Newton’s method works well if\n\nThe zero is a simple root – that is of multiplicity 1\nThe magnitude, \\(|f'(x)|\\), is not too small (If the tangent line is nearly flat, the next guess is far from the previous)\nThe magnitude, \\(|f''(x)|\\), is not too big (function doesn’t have so much curve that the tangent line is a poor approximation)\nThe initial guess is not to far from a zero\n\nThe above points come from the following formula which you can find in many texts.\n\\[\n\\Delta x_{i+1} = \\frac{f' '(\\alpha)}{f'(\\alpha)}(\\Delta x_i)^2 + \\text{error}\n\\]\nwhich is valid when \\(f(x)\\) satisfies \\(f(\\alpha) = 0\\), the third derivative exists near \\(\\alpha\\), and \\(\\Delta x_i = x_i - \\alpha\\) is the error between the zero and the \\(i\\) th estimate. When the derivative at \\(\\alpha\\) is non-zero, the error is basically a constant times \\(\\Delta x_i^2\\). This is interpreted as saying there is quadratic convergence in the error, as the next one is related to the previous one squared.\nNow we look at some cases where the above three points do not hold.\n\n8.6.1 The initial guess is no where near the end results\nLet \\(f(x) = \\sin(x) - x/4\\) and \\(x_0 = 2\\pi\\). This value is deliberately a poor choice:\nf(x) = sin(x) - x/4\nfp(x) = cos(x) - 1/4\nnewton(f, fp, 2pi, verbose=true)\nThough julia makes this happen fast, it will take more than 20 steps before converging and the answer is no where near the guess. This trace might show why\n\n\n\nNewton, way off\n\n\n\nQuestion\nWhen \\(|f'(x)|\\) is too close to \\(0\\), the path can jump alot. In the figure, what was the longest jump?\n#| echo: false\nchoices = [\"From about 17 to -10\",\n     \"From about -12 to -3\",\n     \"From about 0 to -5\"\n     ];\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nThe method did find a zero, but the initial guess was nowhere near the final zero. How close was the closest zero to the initial guess?\n#| echo: false\nchoices = [\"`8.75`\", \"`2pi`\", \"`3.8`\"];\nanswer = 3;\nradioq(choices, answer)\n\n\n\n8.6.2 Function has a poor shape\nLet \\(f(x) = x^{1/3}\\). We know the root is 0. Let’s see what happens if we use Newton’s method. We have to be careful though as julia thinks that cube roots of negative numbers (via x^(1/3) are NaN, not a number. (You can avoid this, by making your number complex, e.g. x + 0*im, but then the real answer is not given as an answer. It is just one of three and not the chosen one.)\nSo we define our function using julia’s cbrt function, which works as we desire for negative numbers, as follows:\nf(x) = cbrt(x)\nxstar = newton(f, 2)\nStill an issue. Why?\n\nQuestion\nDespite all our care with the derivative, the method did not converge in \\(200\\) steps. Can you see why from this trace?\n\n\n\nNewton, cubic\n\n\n#| echo: false\nchoices = [\n    \"`|f'(x)|` gets too small\",\n    \"`|f''(x)|` gets too big at 0\",\n    \"Initial guess is too far from a zero.\"\n];\nanswer = 2;\nradioq(choices, answer, keep_order=true)\n\n\nQuestions Solve by hand\nFor \\(f(x) = x^{1/3}\\), simplify the expression by hand:\nx - f(x)/f'(x)\nWhat do you get?\n#| echo: false\nchoices =[\n    \"`x - (1/3)x^{-1/3}`\",\n    \"`-2x`\",\n    \"`x - 3/x`\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nApply Newton’s method to \\(f(x) = (x-2)^7 \\cdot (x-3) \\cdot (x-4)\\) starting at 1.9981. The algorithm does not converge to 2 – an obvious root. From a plot of \\(f(x)\\) explain why not:\n#| echo: false\nchoices = [\n    \"`|f'(x)|` gets too small\",\n    \"`|f''(x)|` gets too big at 0\",\n    \"Initial guess is to far from a zero.\"\n];\nanswer = 1;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion\nThe function f(x) = atan(x) is a strictly increasing function with one zero, \\(0\\). Yet it can pose problems with Newton’s method. For which values of \\(x\\) does Newton’s method converge:\n#| echo: false\nchoices = [\n    L\"For each of $1$, $2$ and $\\pi$\",\n    L\"For $1$ and $2$ but not $\\pi$\",\n    L\"For $1$ but not $2$ or $\\pi$\",\n    L\"For none of  $1$, $2$ and $\\pi$\" ]\nanswer = 3\nradioq(choices, answer, keep_order=true)\n\n\n\n8.6.3 Cycles\nSometimes, the process can cycle even for reasonable functions.\n\nQuestion\nLet \\(f(x) = x^3 - 5x\\). Starting with \\(x_0=1\\), compute three steps of Newton’s method. What are the terms in the series produced?\n#| echo: false\nchoices = [\n    L\"1, -2, -4,  ...\",\n    L\"-1.0, 1.0, -1.0, ...\",\n    L\"-1.0, 0.6666666666666667, -0.2850952524822228, ...\"\n];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion: Always cycles…\nHere is a pathological example where the value always cycles no matter where you start unless you start at \\(0\\).\nLet \\(f(x) = \\sqrt{|x|}\\). This is the one-sided square root function turned into an even function. We could also have defined it by:\nf(x) = x >= 0 ? sqrt(x) : sqrt(-x)\nwhere the ternary operator a ? b : c looks at a and if true will execute b otherwise c.\nThis makes it easier to write the derivative of the function in Julia:\nfp(x) = x >=0 ? (1/2)*sqrt(x)/x : -(1/2)*sqrt(-x)/(-x)\nTo see what happens when using Newton’s method, lets start at \\(x=2\\)\nx = 2\nx = x - f(x)/fp(x)\nx = x - f(x)/fp(x)\nx = x - f(x)/fp(x)\nTry again with \\(x=3.0\\) What sequence do you get:\n#| echo: false\nchoices =\n    [L\"3, -3.0, 3.0, -3.0, ...\",\n     L\"2, -2.0, 2.0, -2.0\",\n     L\"3, 2.0, 1.0, 0.0, -1.0, ...\"\n     ];\nanswer = 1;\nradioq(choices, answer)"
  },
  {
    "objectID": "extrema.html",
    "href": "extrema.html",
    "title": "9  Maximization and minimization with Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing"
  },
  {
    "objectID": "extrema.html#introduction",
    "href": "extrema.html#introduction",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\nThis project discusses a basic application of calculus to answer questions of the type: What is the largest value a function can take?\nFor example,\n\nOf all rectangles with perimeter 20, which has of the largest area?\n\nThere are a few basic theorems that will help us. First is our “hunting license” which tells us there is actually something to find if some assumptions are met:\n\n9.1.1 Extreme value theorem (Bolzano)\n\nA real-valued continuous function \\(f\\) on a closed interval \\([a,b]\\) will obtain its maximum (minimum) value. That is there exists at least one value \\(c\\) in \\([a,b]\\) for which \\(f( c) \\geq f(x)\\) (\\(f( c) \\leq f(x)\\)) for any \\(x\\) in \\([a,b]\\).\n\n\n\n9.1.2 Theorem of Fermat\nThe above complements a theorem of Fermat which can be expressed as:\n\nFurther, the extrema (maxima or minima) can only occur at a critical point of \\(f\\) or at the endpoints, \\(a\\) and \\(b\\).\n\n\nThough not all of our problems lend themselves to a description of a continuous function on a closed interval, if they do we have an algorithmic prescription to find the absolute extrema of a function:\n\nFind the critical points. For this we will can use a root-finding algorithm like Newton’s method to solve \\(f'(x) = 0\\), as appropriate.\nEvaluate the function values at the critical points and at the end points.\nIdentify the largest and smallest values.\n\nWith the computer we can take some shortcuts, as we will be able to graph our function to see where the extreme values will be."
  },
  {
    "objectID": "extrema.html#fixed-perimeter-and-area",
    "href": "extrema.html#fixed-perimeter-and-area",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.2 Fixed perimeter and area",
    "text": "9.2 Fixed perimeter and area\nThe simplest way to investigate the maximum or minimum value of a function over a closed interval is to just graph it and look.\nWe begin with the question of which rectangles of perimeter 20 have the largest area? The figure shows a few different rectangles with this perimeter and their respective areas.\n\n\n\nRectangles\n\n\nThe basic mathematical approach is to find a function of a single variable to maximize or minimize. In this case we have two variables describing a rectangle: a base \\(b\\) and height \\(h\\). Our formulas are:\n\\[\nP = 20 = 2b + 2h, \\quad A = bh.\n\\]\nWe see that \\(b\\) can be no bigger than 10 and no smaller than 0 from the restriction put in place through the perimeter. Solving for \\(h\\) in terms of \\(b\\) then yields this restatement of the problem:\nMaximize \\(A(b) = b \\cdot (10 - b)\\) over the interval \\([0,10]\\).\nThis is exactly the form needed to apply our theorem about the existence of extrema (a continuous function on a closed interval). Rather than solve analytically by taking a derivative, we simply graph to find the value:\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings\nA(b) = b * (10 - b)\nplot(A, 0, 10)\nYou should see the maximum occurs at \\(b=5\\) by symmetry, so \\(h=5\\) as well, and the maximum area is then \\(25\\). This gives the satisfying answer that among all rectangles of fixed perimeter, that with the largest area is a square.\nBefore moving on, let’s see a slightly different way to do this problem, where we trade off some algebra for a bit of abstraction. Let’s first write area as a function of both base and height:\nA(b, h) = b*h\nThen from the constraint given by the perimeter being a fixed value we can solve for h in terms of b. We write this as a function:\nh(b) = (20 - 2b) / 2\nThen to get A(b) we simply need to substitute h(b) into our formula for the area, A. However, instead of doing the substitution ourselves using algebra we let julia do it through composition of functions:\nA(b) = A(b, h(b))\nFrom this we can solve as before. This approach exploits julia’s multiple dispatch feature to reduce the need for sometimes unwieldy algebra.\n\n9.2.1 Norman Windows\nHere is a similar, though more complicated, example where the analytic approach can be a bit more tedious, but the graphical one mostly satisfying, though we do use the find_zero function to find the exact final answer.\nLet a “Norman” window consist of a rectangular window of top length \\(x\\) and side length \\(y\\) and a half circle on top. The goal is to maximize the area for a fixed value of the perimeter. Again, assume this perimeter is 20 units.\n#| echo: false\n# <script>\n# \\\\ ```{r echo=FALSE}\n# \\\\ plot.new()\n# \\\\ plot.window(xlim=c(-3, 3), ylim=c(-4, 2))\n# \\\\ lines(c(-2, -2, 2, 2), c(0, -4, -4, 0))\n# \\\\ theta = seq(0, pi, length=100)\n# \\\\ lines(2*cos(theta), 2*sin(theta))\n\n# \\\\ lines(c(-2, 2), c(0,0), lty=2, col=\"gray\")\n# \\\\ lines(c(0,sqrt(2)), c(0,sqrt(2)), lwd=2, col=\"black\")\n# \\\\ text(sqrt(2)/2, sqrt(2)/2, \"x/2\", pos=4)\n\n# \\\\ text(2, -2, \"y\", pos=4)\n# \\\\ text(0, -4, \"x\", pos=1)\n# \\\\ ```\n# </script>\nnothing\n\n\n\nNorman window\n\n\nThen we have two equations.\nThe area is the area of the rectangle plus the area of the half circle (\\(\\pi r^2/2\\)).\n\\[\nA = xy + \\pi(x/2)^2/2\n\\]\nIn julia this is\nA(x,y) = x*y + pi*(x/2)^2 / 2\nThe perimeter consists of 3 sides of the rectangle and the perimeter of half a circle (\\(\\pi r\\), with \\(r=x/2\\)):\n\\[\nP = 2y + x + \\pi(x/2) = 20\n\\]\nWe solve for \\(y\\) in the first with \\(y = (20 - x - \\pi(x/2))/2\\) so that in julia we have:\ny(x) = (20 - x - pi * x/2) / 2\nAnd then we substitute in y(x) for y in the area formula through:\nA(x) = A(x, y(x))\nOf course both \\(x\\) and \\(y\\) are non-negative. The latter forces \\(x\\) to be no more than \\(20/(1+\\pi/2)\\).\nThis leaves us the calculus problem of finding an absolute maximum of a continuous function over the closed interval \\([0, 20/(1+\\pi/2)]\\). Our theorem tells us this maximum must occur, we now proceed to find it.\nWe begin by simply graphing and estimating the values of the maximum and where it occurs.\nplot(A, 0, 20/(1+pi/2))\nThe naked eye sees that maximum value is somewhere around \\(27\\) and occurs at \\(x\\approx 5.6\\). Clearly from the graph, we know the maximum value happens at the critical point and there is only one such critical point.\nAs reading the maximum from the graph is more difficult than reading a \\(0\\) of a function, we plot the derivative using our approximate derivative.\nplot(A', 5.5, 5.7)     # uses A' notation defined in MTH229\nWe confirm that the critical point is around \\(5.6\\).\n\n\n9.2.2 Using find_zero to locate critical points.\nRather than zoom in graphically, we now use a root-finding algorithm, to find a more precise value. We know that the maximum will occur at a critical point, a zero of the derivative. Newton’s method, for example, can locate the precise values of these zeros. The find_zero function from the Roots package provides a non-linear root-finding algorithm similar to Newton’s method. The only thing to keep track of is that solving \\(f'(x) = 0\\) means we use the derivative and not the original function.\nOur initial guess will be taken from the graph we made, or \\(x=5.6\\). Here is how we use find_zero:\nx = find_zero(A', 5.6)\nThe value x is the critical point, and in this case gives the position of the value that will maximize the function. This value is sometimes referred to as the argmax, or argument which maximizes the function. The value and maximum area is then given by:\n(x, A(x))\n(Compare this answer to the previous, is the square the figure of greatest area for a fixed perimeter, or just the figure amongst all rectangles?)\n\n\n9.2.3 Practice\n\nQuestion\nA rancher with 20 meters of fence, wishes to make a pen adjacent to an existing fence. The pen will be a rectangle with one edge using the existing fence. Say that has length \\(x\\), then \\(20 = 2y + x\\), with \\(y\\) the other dimension of the pen. What is the maximum area that can be made?\n#| echo: false\nArea(y) = (20-2y)*y;\nval = find_zero(Area',  10) |> Area;\nnumericq(val, 1e-3)"
  },
  {
    "objectID": "extrema.html#trigonometry",
    "href": "extrema.html#trigonometry",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.3 Trigonometry",
    "text": "9.3 Trigonometry\nMany maximization and minimization problems involve triangles, which in turn use trigonometry in their description. Here is an example, the “ladder corner problem.” (There are many other ladder problems.\nA ladder is to be moved through a two-dimensional hallway which has a bend and gets narrower after the bend. The hallway is 8 feet wide then 5 feet wide. What is the longest such ladder that can be navigated around the corner? The figure shows a ladder of length \\(l_1 + l_2\\) that got stuck – it was too long.\n#| echo: false\n# <script>\n# \\\\ ```{r echo=FALSE}\n# \\\\ plot.new()\n# \\\\ plot.window(xlim=c(0, 17), ylim=c(0, 15))\n# \\\\ lines(c(0,0,17), c(15, 0, 0), lwd=1, col=\"gray\")\n# \\\\ lines(c(5,5,17), c(15, 8, 8), lwd=1, col=\"gray\")\n# \\\\ lines(c(0, 15), c(12, 0), lwd=2, col=\"black\")\n\n# \\\\ lines(c(0,5), c(8,8), lty=2, col=\"gray\")\n# \\\\ text(2.5, 8, \"5\", pos=1)\n\n# \\\\ lines(c(5,5), c(0,8), lty=2, col=\"gray\")\n# \\\\ text(5, 4, \"8\", pos=2)\n\n# \\\\ text(13, .8, expression(theta))\n# \\\\ x1 = 10\n# \\\\ text(x1, 12 - .5 - 4/5*x1, expression(l[1]))\n# \\\\ x1 = 2.5\n# \\\\ text(x1, 12 - .5 - 4/5*x1, expression(l[2]))\n# \\\\ ```\n# </script>\nnothing\n\n\n\nLadder\n\n\nWe approach this problem in reverse. It is easy to see when a ladder is too long. It gets stuck at some angle \\(\\theta\\). So for each \\(\\theta\\) we find that ladder length that is just too long. Then we find the minimum length of all these ladders that are too long. If a ladder is this length or more it will get stuck for some angle. However, if it is less than this length it will not get stuck. So to maximize a ladder length, we minimize a different function. Neat.\nNow, to find the length \\(l = l_1 + l_2\\) as a function of \\(\\theta\\).\nWe need to brush off our trigonometry, in particular right triangle trigonometry. We see from the figure that \\(l_1\\) is the hypotenuse of a right triangle with opposite side \\(8\\) and \\(l_2\\) is the hypotenuse of a right triangle with adjacent side \\(5\\). So, \\(8/l_1 = \\sin\\theta\\) and \\(5/l_2 = \\cos\\theta\\).\nThat is, we have\nl(l1, l2) = l1 + l2\nl1(t) = 8/sin(t)\nl2(t) = 5/cos(t)\n##\nl(t) = l(l1(t), l2(t))      # or simply l(t) = 8/sin(t) + 5/cos(t)\nOur goal is to minimize this function for all angles between \\(0\\) and \\(90\\) degrees, or \\(0\\) and \\(\\pi/2\\) radians.\nThis is not a continuous function on a closed interval – it is undefined at the endpoints. That being said, a quick plot will convince us that the minimum occurs at a critical point and there is only one critical point in \\((0, \\pi/2)\\).\ndelta = 0.2\nplot(l, delta, pi/2 - delta)\nThe minimum occurs between 0.5 and 1.0 radins, we will use a bracketing method:\nx = find_zero(l', (0.5, 1.0))\nSo the minimum of the function \\(l\\) is\nl(x)\nThat is, any ladder less than this length can get around the hallway.\n\n9.3.1 Practice\n\nQuestion\nRather than use a bracketing method to solve for the root of \\(l'(t)=0\\), we might have tried using find_zero(l', 0.8). Do so. What do you find?\n#| echo: false\nchoices = [\n    \"You get the same answer, 0.8634...\",\n    \"You get a different answer, 0.9834...\",\n    \"The method does not converge\"];\nanswer = 1;\nradioq(choices, answer)\n\n\nQuestion\nA rain gutter is constructed from a 30” wide sheet of tin by bending it into thirds. If the sides are bent 90 degrees, then the cross-sectional area would be \\(100 = 10^2\\). This is not the largest possible amount. For example, if the sides are bent by 45 degrees, the cross sectional area is:\n2 * (1/2 * 10*cos(pi/4) * 10 * sin(pi/4)) + 10*sin(pi/4) * 10\nFind a value in degrees that gives the maximum. (The first task is to write the area in terms of \\(\\theta\\).\n#| echo: false\nfunction A(t)\n     opp = 10 * sin(t)\n     adj = 10 * cos(t)\n     2 * opp * adj/2 + opp * 10\nend\nt = find_zero(A', pi/4, Roots.Order16());   ## Has issues with order=8 algorithm, tol > 1e-14 is needed\nval = t * 180/pi;\nnumericq(val, 1e-3)\n\n\nQuestion (Thanks https://www.math.ucdavis.edu/~kouba)\nA movie screen projects on a wall 20 feet high beginning 10 feet above the floor. What value of \\(x\\) gives the largest angle \\(\\theta?\\)\n\n\n\nMovie screen\n\n\nWhat is the value of theta in degrees?\n#| echo: false\ntheta(x) = atan(30/x) - atan(10/x)\nval = find_zero(theta', 20); ## careful where one starts\nval = theta(val) * 180/pi\nnumericq(val, 1e-1)"
  },
  {
    "objectID": "extrema.html#rate-times-time",
    "href": "extrema.html#rate-times-time",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.4 Rate times time",
    "text": "9.4 Rate times time\nEthan Hunt, a top secret spy, has a mission to chase a bad guy. Here is what we know:\n\nEthan likes to run. He can run at 10 miles per hour.\nHe can drive a car – usually some concept car by BMW – at 30 miles per hour, but only on the road.\n\nFor his mission, he needs to go 10 miles west and 5 miles north. He can do this by:\n\njust driving 10 miles west then 5 miles north, or\njust running the diagonal distance, or\ndriving \\(0 < x < 10\\) miles west, then running on the diagonal\n\nA quick analysis says:\n\nIt would take \\((10+5)/30\\) hours to just drive\nIt would take \\(\\sqrt{10^2 + 5^2}/10\\) hours to just run\n\nNow, if he drives \\(x\\) miles west (\\(0 < x < 10\\)) he would run an amount given by the hypotenuse of a triangle with lengths \\(5\\) and \\(10-x\\). His time driving would be \\(x/30\\) and his time running would be :/10$ for a total of:\n\\[\nT(x) = x/30 + \\sqrt{5^2 + (10-x)^2}/10, \\quad 0 < x < 10\n\\]\nWith the endpoints given by \\(T(0) = \\sqrt{10^2 + 5^2}/10\\) and \\(T(10) = (10 + 5)/30\\).\nLet’s plot \\(T(x)\\) over the interval \\((0,10)\\) and look:\nT(x) = x/30 + sqrt(5^2 + (10-x)^2)/10\nplot(T, 0, 10)\nThe minimum happens way out near 8. We zoom in a bit:\nplot(T, 7, 9)\nIt appears to be around 8.3. We now use find_zero to refine our guess at the critical point using a bracketing algorithm:\nx = find_zero(T', (7, 9))\nOkay, got it. Around 8.23. So is our minimum time\nT(x)\n(Hint: what is the title of this section?)\n\n9.4.1 Practice\n\nQuestions\nA maximum likelihood estimator is a value derived by maximizing a function. For example, if\nL(t) = t^3 * exp(-3t) * exp(-2t) * exp(-4t) ## 0 <= t <= 10\nThen \\(L(t)\\) is continuous and has single peak, so the maximum occurs at the lone critical point. It turns out that this problem is bit sensitive to an initial condition, so we bracket\nx = find_zero(L',  (0.1, 0.5))\nNow if \\(L(t) = \\exp(-3t) \\cdot \\exp(-2t) \\cdot \\exp(-4t), \\quad 0 \\leq t \\leq 10\\), explain why the same approach won’t work:\n#| echo: false\nchoices=[\"It does work and the answer is x = 2.27...\",\n     \"L(t) is not continuous on 0 to 10\",\n         \"L(t) takes its maximum at a boundary point -- not a critical point\"];\nanswer = 3;\nradioq(choices, answer)"
  },
  {
    "objectID": "extrema.html#unbounded-domains",
    "href": "extrema.html#unbounded-domains",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.5 Unbounded domains",
    "text": "9.5 Unbounded domains\nMaximize the function \\(xe^{-(1/2) x^2}\\) over the interval \\([0, \\infty)\\).\nHere the extreme value theorem doesn’t technically apply, as we don’t have a closed interval. However, if we can eliminate the endpoints as candidates, then we should be able to convince ourselves the maximum must occur at a critical point of \\(f(x)\\). (If not, then convince your self for all sufficiently large \\(M\\) the maximum over \\([0,M]\\) occurs at a critical point, not an endpoint. Then let \\(M\\) go to infinity.)\nSo to approach this problem we first graph it over a wide interval.\nf(x) = x * exp(-x^2)\nplot(f, 0, 100)\nClearly the action is nearer to 1 than 100. We try graphing the derivative near that area:\nplot(f', 0, 5)\nThis shows the value near \\(0.7\\). We use find_zero starting there:\nx = find_zero(f', 0.7)\nThe convergence is quick. The maximum is at\nf(x)\n\n9.5.1 Minimize surface area of a can\nFor a more applied problem of this type (infinite domain), consider a can of some soft drink that is to contain 355ml which is 355 cubic centimeters. (We use metric units, as the relationship between volume (cubic centimeters) and fluid amount (ml) is clear.) A can to hold this amount is produced in the shape of cylinder with radius \\(r\\) and height \\(h\\). The materials involved give the surface area, which would be:\n\\[\nSA = h \\cdot 2\\pi r + 2 \\cdot \\pi r^2\n\\]\nThe volume satisfies:\n\\[\nV = 355 = h \\cdot \\pi r^2\n\\]\nFind the values of \\(r\\) and \\(h\\) which minimize the surface area.\nFirst the surface area in both variables is given by\nSA(h, r) = h * 2pi * r + 2pi * r^2\nAnd solving from the constraint on the volume for h in terms of r we have\nh(r) = 355 / (pi * r^2)\nAnd composing gives us a function of r alone:\nSA(r) = SA(h(r), r)\nThis we minimize subject to the constraint that \\(r \\geq 0\\). A quick glance shows that as \\(r\\) gets close to \\(0\\), the can must get infinitely tall to contain that fixed volume, and would have infinite surface area as the \\(1/r^2\\) in the first term implies. On the other hand, as \\(r\\) goes to infinity, the height must go to 0 to make a really flat can. Again, we would have infinite surface area, as the \\(r^2\\) term at the end indicates. With this observation, we can rule out the endpoints as possible minima, so any minima must occur at a critical point.\nWe start by making a graph, making an educated guess that the answer is somewhere near a real life answer, or around 3-5 cms in radius:\nplot(SA, 2, 10)\nThe minimum looks to be around 4cm. We can use find_zero to zero in on the answer:\nr0 = find_zero(SA', 4)\nOkay, \\(3.837...\\) is our computation for \\(r\\). To get \\(h\\), we use:\nh(r0)\nThis produces a can which is about square in profile. This is not how most cans look though. Perhaps our model is too simple, or the cans are optimized for some other purpose than minimizing materials.\n\n\n9.5.2 Practice\n\nQuestions\nMinimize the function \\(f(x) = 2x + 3/x\\) over \\((0, \\infty)\\).\n#| echo: false\nf(x) = 2x + 3/x;\nval = find_zero(f', 1);\nnumericq(val, 1e-3)\n\n\nQuestion\nOf all rectangles of area 4, find the one with largest perimeter. What is the perimeter?\n#| echo: false\n# 4 = xy\nP(x) = 2x + 2*(4/x);\nval = find_zero(P', 1);\nnumericq(P(val), 1e-3)      ## a square!"
  },
  {
    "objectID": "extrema.html#implicit-derivates",
    "href": "extrema.html#implicit-derivates",
    "title": "9  Maximization and minimization with Julia",
    "section": "9.6 Implicit derivates",
    "text": "9.6 Implicit derivates\nMany problems are best done with implicit derivatives. A video showing such a problem along with how to do it analytically is here.\nThis video starts with a simple question:\n\nIf you have a rope and heavy ring, where will the ring position itself due to gravity?\n\nWell, suppose you hold the rope in two places, which we can take to be \\((0,0)\\) and \\((a,b)\\). Then let \\((x,y)\\) be all the possible positions of the ring that hold the rope taught. Then we have this picture:\n#| echo: false\n#<script>\n# \\\\ ```{r echo=FALSE}\n# \\\\ plot.new()\n# \\\\ plot.window(xlim=c(0,1), ylim=c(-5, 1.1))\n# \\\\ x <- seq(.1, .9, length=9)\n# \\\\ y <- c(-4.46262,-4.46866, -4.47268, -4.47469, -4.47468, -4.47267, -4.46864, -4.4626 , -4.45454)\n# \\\\ lines(c(0, x[3], 1), c(0, y[3], 1))\n# \\\\ points(c(0,1), c(0,1), pch=16, cex=2)\n# \\\\ text(c(0,1), c(0,1), c(\"(0,0)\", c(\"(a,b)\")), pos=3)\n\n# \\\\ lines(c(0, x[3], x[3]), c(0, 0, y[3]), cex=2, col=\"gray\")\n# \\\\ lines(c(1, x[3], x[3]), c(1, 1, y[3]), cex=2, col=\"gray\")\n# \\\\ text(x[3]/2, 0, \"x\", pos=1)\n# \\\\ text(x[3], y[3]/2, \"|y|\", pos=2)\n# \\\\ text(x[3], (1 + y[3])/2, \"b-y\", pos=4)\n# \\\\ text((x[3] + 1)/2, 1, \"a-x\", pos=1)\n\n# \\\\ text(x[3], y[3], \"0\", cex=4, col=\"gold\")\n\n# \\\\ ```\n#</script>\nnothing\n\n\n\nString\n\n\nSince the length of the rope does not change, we must have for any admissible \\((x,y)\\) that:\n\\[\nL = \\sqrt{x^2 + y^2} + \\sqrt{(a-x)^2 + (b-y)^2},\n\\]\nwhere these are the two hypotenuses in the figure, as computed through Pythagorean’s theorem.\n\nIf we assume that the ring will minimize the value of y subject to this constraint, can we solve for y?\n\nWell, with implicit differentiation you would regard \\(y=y(x)\\), implicitly differentiate and find the critical point of \\(y\\). Though messy to solve, the video shows a fundamental relationship which is a restatement of the reflection properties of ellipses.\nHere we show how we can do this numerically with julia. We don’t really have an easy way to work with implicit functions in julia, so we have some work to do to find an explicit function.\nFirst, lets assume \\(a=1\\) and \\(L=10\\) (\\(L\\) must be at least \\(\\sqrt{1 + b^2}\\)) , then we have:\na = 1; Len = 10\nf(x, y, a, b) = sqrt(x^2 + y^2) + sqrt((a-x)^2 + (b-y)^2)\nNow we solve for a value of \\(b\\), say \\(b=1\\). You could choose other values for \\(b\\), as long as \\(L\\) is long enough.\nb = 1;               ## some arbitrary choice for b\nf(x, y) = f(x, y, a, b)\nOur values \\((x,y)\\) must satisfy \\(f(x,y) = L\\) so for a fixed \\(x\\), \\(y\\) must be a zero of the function:\n\\[\nh(y) = f(x, y) - L = 0\n\\]\nThat is, if we start with \\(x\\) and solve this equation for \\(y\\) the resulting value \\((x,y)\\) will be on the curve. Call this function \\(g\\). We can define it with:\nfunction g(x)\n   h(y) = f(x, y) - Len\n   find_zero(h, zero(x))  # not 0, but zero(x) to get type right\nend\nLet’s see if it worked. For \\(x=0.4\\) we get that \\(y\\) is\ng(0.4)\nAnd furthermore, we have\nf(.4, g(0.4))\nThat this is \\(L\\), should be the case for any choice of \\(x\\) when we have convergence for \\(g\\). Try it yourself with a different value in \\([0,1]\\).\nNow, through this inversion trick, we have a function \\(y=g(x)\\). We graph to see that indeed this function will have a minimum value:\nplot(g, 0.2, 0.8)\n(The implicit function theorem will tell us that locally for any \\(x\\) we can find a function to return \\(y\\) provided a certain derivative is not \\(0\\) and the equation is reasonably behaved.)\nOkay, now to find the lowest point. This is what we minimize to find the resting position of the ring. Again, we turn to find_zero, but for minimization we use the first derivative, as we are finding critical points.\nx = find_zero(g', (0.3, 0.6))\n(The above only works due to how we defined g using zero(x) and not 0 for technical reasons related to automatic differentiation.)\nThe point where the ring rests is:\nx, g(x)\nIf you watch the video linked to above, you will see that the surprising fact here is the resting point is such that the angles formed by the rope are the same. Basically this makes the tension in both parts of the rope equal, so there is a static position (if not static, the ring would move and not end in the final position). We can verify this fact numerically by showing the arctangents of the two triangles are the same:\nt = g(x)\natan(abs(t)/x) - atan((b-t)/(a-x))\nNow, were we lucky and just happened to take \\(b = 1\\) in such a way to make this work? Well, no. But convince yourself by doing the above for different values of \\(b\\)."
  },
  {
    "objectID": "integration.html",
    "href": "integration.html",
    "title": "10  Numeric integration with Julia",
    "section": "",
    "text": "#| echo: false\n\nimport Logging\nLogging.disable_logging(Logging.Info) # or e.g. Logging.Info\nLogging.disable_logging(Logging.Warn)\n\nimport SymPy\nfunction Base.show(io::IO, ::MIME\"text/html\", x::T) where {T <: SymPy.SymbolicObject}\n    println(io, \"<span class=\\\"math-left-align\\\" style=\\\"padding-left: 4px; width:0; float:left;\\\"> \")\n    println(io, \"\\\\[\")\n    println(io, sympy.latex(x))\n    println(io, \"\\\\]\")\n    println(io, \"</span>\")\nend\n\n\nnothing\nA notebook for this material: ipynb (Pluto html) (With commentary)"
  },
  {
    "objectID": "integration.html#introduction",
    "href": "integration.html#introduction",
    "title": "10  Numeric integration with Julia",
    "section": "10.1 Introduction",
    "text": "10.1 Introduction\nLet \\(f(x)\\) be some non-negative, continuous function over the interval \\([a,b]\\). The area under the graph of \\(f(x)\\) is given by the definite integral:\n\\[\n\\text{Area under f} = \\int_a^b f(x) dx\n\\]\nComputing this area is often made easier with the Fundamental Theorem of Calculus which states in one form that one can compute a definite integral through knowledge of an antiderivative. In particular, if \\(F(x)\\) is an antiderivative for \\(f(x)\\), a continuous function, then\n\\[\n\\int_a^b f(x) dx = F(b) - F(a).\n\\]\nThis is great as long as some antiderivative is known. There are several different techniques for finding antiderivatives. The integrate function in the SymPy package can do many of them:\nusing MTH229\nusing Plots\n#| echo: false\nusing QuizQuestions\nusing LaTeXStrings\nf(x) = x^3 - cos(x) + x*log(x)\n@syms x\nintegrate(f(x), x)\nTo find the definite integral, say from \\(1\\) to \\(10\\) we have:\nintegrate(f(x), (x, 1, 10))\nIf all functions had antiderivatives that could be found symbolically, there wouldn’t be much more to say. However, it is a fact of life that not all nice functions will have an antiderivative in a convenient form. A test for such functions is provided in Risch’s algorithm. In cases where no workable antiderivative is available, the above approach is of no help. Rather, to find the area one can turn to numeric approximations that progressively get better as more approximations are taken.\nOne such approximation is given by the familiar Riemann sums, which we will look at here. However, the problem of trying to find the area of geometric figures did not start with Riemann some 150 years ago, indeed it has a much longer history. In the time of Pythagorus the idea of calculating area was one of being able to construct a square of equal area to a figure. This was known as quadrature. Finding such answers for figures bounded by curves was difficult, though Archimedes effectively computed the area under \\(f(x) = x^2\\) about 2,000 years before Riemann sums using triangles, not rectangles to approximate the area. By medieval Europe, the term quadrature evolved to be the computation of an area by any means. For example, Galileo and Roberval found the area bounded by a cycloid arch. Along the way, other approximations were used. We will see those due to Simpson and Gauss, both predating Riemann."
  },
  {
    "objectID": "integration.html#riemann-sums",
    "href": "integration.html#riemann-sums",
    "title": "10  Numeric integration with Julia",
    "section": "10.2 Riemann sums",
    "text": "10.2 Riemann sums\nIn 1854 Riemann was the first to give a rigorous definition of the integral of a continuous function on a closed interval, the problem we wish to solve here, using the concept of a Riemann sum. A Riemann sum is one of the simplest to understand approximations to the area under a curve. The basic idea is that the interval \\([a,b]\\) is partitioned through points \\(a = x_0 < x_1 < \\cdots x_n = b\\) and the area under \\(f(x)\\) between \\(x_i\\) and \\(x_{i+1}\\) is approximated by a rectangle with the base \\(x_{i+1} - x_i\\) and height given by \\(f(x_i^*)\\), where \\(x_i^*\\) is some point in the interval \\([x_i, x_{i+1}]\\). Typical choices are the left point or the right point of the interval, or the \\(x\\) value which minizes or maximizes \\(f\\) over the interval. The figure shows these four choices for some sample function. For a Riemann integrable function, such as a continuous function on \\([a,b]\\), any of the choices will yield the same value as the partition’s mesh shrinks to \\(0\\).\n\n\n\nRiemann\n\n\nAs with other limits, we can numerically approximate the limit by computing the Riemann sum for some partition. The steps for this include:\n\ncreating a partition of \\([a,b]\\). We will use evenly spaced points for convenience.\nSelecting the \\(x_i^*\\) within the partition\nComputing the values \\(f(x_i^*)(x_{i+1} - x_i)\\) for each \\(i\\)\nadding these values up\n\nIf we partition \\([a,b]\\) into \\(n\\) same sized intervals, then each has length \\(\\delta = (b-a)/n\\) and so the points are separated by this amount. As such, we can choose our \\(a = x_0 < x_1 < \\dots < x_n = b\\) with commands like:\na, b, n = 1, 3, 5;\ndelta = (b-a)/n;\nxs = a .+ (0:n) * delta\nTo apply a function to a range of values, we may use a map, a comprehension, a for loop or the “dot” notation. We will use broadcasting here. Recall, the syntax:\nf(x) = x^2\nfxs = f.(xs)\nNow to add the numbers up. For this task, the sum function is available\nsum(fxs)\nOkay, just one subtlety, we really only want the points\n[ a .+ (0:n-1) * delta ]\nfor the left Riemann sum and the points\n[ a .+ (1:n) * delta ]\nfor the right.\nPutting this together, here are commands to approximate the area under the curve \\(f(x)=x^2\\) using 10 left Riemann sums:\nf(x) = x^2\na, b, n = 1, 3, 10;        ## note n=10\ndelta = (b - a)/n;         ## nothing to change below here\nxs = a .+ (0:n-1) * delta;          ## n, right is 1:n * delta\nfxs = f.(xs);\nsum(fxs) * delta\nWe compare this value to the known value from the Fundamental Theorem of Calculus, as \\(F(x) = x^3/3\\) is an antiderivative:\nF(x) = x^3/3\nF(b) - F(a)\nBoy, not too close. We need a better approximation of course. This can be achieved by using larger values for n.\n\n10.2.1 Practice\n\nQuestion\nRepeat with n=100\nFor the same problem, let \\(n=100\\). What do you get?\n#| echo: false\nf(x) = x.^2\na=1; b=3; n=100;\nx = range(a, stop=b, length=n+1);\nval = sum(f(x[1:n])) * (b-a)/n;\nnumericq(val, 1e-4)\n\n\nQuestion\nRepeat with n=1,000\nFor the same problem, let \\(n=1000\\). What do you get?\n#| echo: false\nf(x) = x.^2\na=1; b=3; n=1000;\nx = range(a, stop=b, length=n+1);\nval = sum(f(x[1:n])) * (b-a)/n;\nnumericq(val, 1e-4)\n\n\nQuestion\nRepeat with n=10,000\nFor the same problem, let \\(n=10,000\\). is the difference between the answer and the actual answer within \\(0.001\\)?\n#| echo: false\nf(x) = x.^2\na=1; b=3; n=10_000;\nx = range(a, stop=b, length=n+1);\nval = sum(f(x[1:n])) * (b-a)/n;\nF(x) = x^3/3\nbooleanq(abs(F(b) - F(a) - val) < 1e-3)\n\n\nQuestion\nHow big should n be? (Strang)\nLet \\(f(x) = (10 + \\cos(2\\pi x))^{-1}\\). For the integral over \\([0,1]\\), the known answer is \\(1/\\sqrt{99}\\). How big must \\(n\\) be so that the error in the Riemann sum is less than \\(10^{-8}\\)?\n#| echo: false\n## This integral converges very fast, as the function is symmetric over the interval so the errors cancel out.\nchoices = [5, 10, 100, 1_000, 10_000];\nradioq(choices, 2)"
  },
  {
    "objectID": "integration.html#integrate-function",
    "href": "integration.html#integrate-function",
    "title": "10  Numeric integration with Julia",
    "section": "10.3 Integrate function",
    "text": "10.3 Integrate function\nHere we write a function to do the integration. This needs the basic inputs of\n\na function,\nthe interval’s start and end value, and\nthe number of equal-sized subintervals.\n\nIn addition, we allow for the possibility of using different methods to approximate the area over a sub interval. Different possibilities are:\n\nusing a rectangle with the left endpoint to determine the height (method=\"left\")\nusing a rectangle with the right endpoint to determine the height (method=\"right\")\nusing a trapezoid formed by joining the left and right endpoints (method=\"trapezoid\")\nmaking the cap a quadratic polynomial that goes through the left and right endpoints and the midpoint (method=\"simpsons\")\n\nThis function is defined in MTH229:\n#| eval: false\nfunction riemann(f::Function, a::Real, b::Real, n::Int; method=\"right\")\n  if method == \"right\"\n     meth = (f,l,r) -> f(r) * (r-l)\n  elseif method == \"left\"\n     meth= (f,l,r) -> f(l) * (r-l)\n  elseif method == \"trapezoid\"\n     meth = (f,l,r) -> (1/2) * (f(l) + f(r)) * (r-l)\n  elseif method == \"simpsons\"\n     meth = (f,l,r) -> (1/6) * (f(l) + 4*(f((l+r)/2)) + f(r)) * (r-l)\n  end\n\n  xs = range(a, b, length=n+1)\n  lrs = zip(Iterators.take(xs, n), Iterators.rest(xs, 1))\n  sum(meth(f, l, r) for (l,r) in lrs)\n\nend\n\n10.3.1 The integrate function in action\nThe basic usage of the riemann function is straightforward. Here we approximate the integral of \\(e^{-x^2}\\) from \\(0\\) to \\(3\\) using \\(10,000\\) subintervals:\nf(x) =  exp(-x^2)\nriemann(f, 0, 3, 10_000)\nHow big should the number of intervals be? More intervals will give better answers, but unlike Newton’s method we have no stopping criteria. For this problem, we look at various values based on n:\n[riemann(f, 0, 3, n) for n in [100, 1000, 10000, 100000]]   ## or use 10.^(2:5)\nWe see a value around \\(0.886\\) as the answer.\n\n\n10.3.2 left versus right\nUsing different methods allows us to compare the right and left Riemann sums. Let’s do so for the monotonic function \\(e^x\\) over the interval \\([0,2]\\).\nf(x) = exp(x)\nns = [10^i for i in 1:5]\nys = [riemann(f, 0, 2, n, method=\"right\") - riemann(f, 0, 2, n, method=\"left\") for n in ns];\n[ns ys]\nSince these are also the minimum and maximum Riemann sums, the above gives a bound on the error in the approximations. We can see it converges quite slowly, in that there are quite a few computations needed to get even a modest bound. (\\(100,000\\) for \\(0.00013\\)).\n\n\n10.3.3 Practice\n\nQuestion\nCompute the integral of \\(e^{-x^2}\\) over \\([0,1]\\) using a right Riemann sum with \\(n=1000\\). What is your answer?\n#| echo: false\nf(x) = exp(-x^2)\na,b,n = 0, 1, 10_000\nval = riemann(f, a, b, n, method=\"right\")\nnumericq(val, 1e-8)\n\n\nQuestion\nCompute the integral of \\((1 + \\cos(x)^2)^(1/2)\\) over the interval \\([0, \\pi]\\) using a right Riemann sum with \\(n=10,000\\). What is your answer?\n#| echo: false\nf(x) = sqrt(1 + cos(x)^2)\na, b, n = 0, pi, 10_000\nval = riemann(f, a, b, n, method=\"right\")\nnumericq(val, 1e-8)\n\n\nQuestion\nRepeat the above analysis comparing the right and left Riemann sums for \\(f(x)=e^x\\) over \\([0,2]\\). However, this time multiply by \\(n\\), as follows:\nns = [10^i for i in 1:5]\nf(x) = exp(x)\n[n * (riemann(f, 0, 2, n, method=\"right\") - riemann(f, 0, 2, n, method=\"left\")) for n in ns]\nThis shows what?\n#| echo: false\nchoices = [\"That it is constant says the difference between right and left Riemann sums never goes to 0\",\n        \"That it is constant says the difference between right and left Riemann sums goes to 0 like 1/n\",\n        \"That it is constant says the difference between right and left Riemann sums is constant.\"\n        ];\nanswer = 2;\nradioq(choices, answer)"
  },
  {
    "objectID": "integration.html#improvements-to-the-rectangle-method",
    "href": "integration.html#improvements-to-the-rectangle-method",
    "title": "10  Numeric integration with Julia",
    "section": "10.4 Improvements to the rectangle method",
    "text": "10.4 Improvements to the rectangle method\nThe basic left or right Riemann sum will converge, but the convergence is really slow. The value of using rectangles over a grid to approximate area is for theoretical computations, for numeric computations better approximations were known well before Riemann. We mention a few:\n\nThe trapezoid rule and Simpson’s rule approximate the area under the curve better, as instead of a rectangle they use a trapezoid (linear fit between two points) or a quadratic fit between the two points.)\nGauss quadrature uses non-evenly selected points within the range and a weighting which is exact for polynomials of a given degree.\nAdaptive methods pick a non-uniform set of points to use based on where a function is less well behaved.\n\n\n10.4.1 Trapezoid and Simpson’s rule\nThe trapezoid rule simply replaces the approximation of the area in a subinterval by a trapezoid, as opposed to a rectangle.\nWe can use this as follows. Let’s approximate the area under the curve \\(y=5x^4\\) between \\(0\\) and \\(1\\) (with known answer \\(1\\)):\nf(x) = 5x^4\nriemann(f, 0, 1, 1000, method=\"trapezoid\")\nPretty close to 1 with just 1,000 subintervals.\nWe now compare the error with the left Riemann sum for the same size \\(n\\):\nns = [10^i for i in 1:5]\nleft_r = [riemann(f, 0, 1, n) for n in ns];\ntrapezoid_r = [riemann(f, 0, 1, n, method=\"trapezoid\") for n in ns];\n[ns (1).-left_r (1).-trapezoid_r]\nOne can see that the errors are much smaller for the trapezoid method.\n\n\n10.4.2 Simpson’s rule\nThe trapezoid rule can be viewed as a simple linear approximation to the function \\(f(x)\\) over the subinterval \\([a, b]\\). That is, replace the function with the secant line between these two values and integrate the replacement. With this viewpoint, it is possible that other easy-to-integrate function approximations will lead to improved approximate integrals. Simpson’s method can be viewed in just this way. It replaces \\(f\\) by the parabola going through \\((a, f(a))\\), \\((c, f( c))\\) and \\((b, f(b))\\) where \\(c=(a+b)/2\\) is the midpoint between \\(a\\) and \\(b\\).\nWe compare how accurate we get with this rule for the same f as before:\nsimpsons_r = [riemann(f, 0, 1, n, method=\"simpsons\") for n in ns];\n[ns (1).-left_r (1).-trapezoid_r (1).-simpsons_r]\n\nAs can be seen, for this function approximating with a parabola is much quicker to converge. That is, \\(n\\) can be smaller yet the same accuracy is maintained. (Of course, there are more computations involved for each, so the number of operations needed may or may not be fewer, that would require some analysis.)\n\n\n10.4.3 Error\nIt can be shown that the error for Simpson’s method is bounded by\n\\[\n\\frac{1}{90}\\frac{1}{2^5} M (b-a)^5 \\frac{1}{n^4},\n\\]\nwhere \\(M\\) is a bound on the fourth derivative. As we increase \\(n\\), the error gets small at a quick rate. By contrast, the error for the trapezoid method will be like \\(n^{-2}\\) and the left Riemann sum like \\(n^{-1}\\).\n\n\n10.4.4 Practice\n\nQuestion\nThe trapezoid rule has no error for linear functions and Simpson’s rule has no error for quadratic functions. Verify the latter by computing the following:\nf(x) = x^2; F(x) = x^3/3\nriemann(f, 0, 10, 100, method=\"simpsons\") - (F(10) - F(0));\nHow accurate is the approximation? Around\n#| echo: false\nchoices = [`1e-8`, `1e-10`, `1e-12`, `1e-14`, `1e-16`, `0`];\nanswer = 4;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion\nCompare the difference between the trapezoid rule and Simpson’s rule when integrating \\(\\cos(x)\\) from \\(0\\) to \\(\\pi/6\\). How big is the difference when \\(n=10,000\\)?\na, b, n = 0, pi/6, 10_000\nriemann(cos, a, b, n, method=\"trapezoid\") - riemann(cos, a, b, n, method=\"simpsons\");\nHow big is the difference?\nchoices = [`1e-8`, `1e-10`, `1e-12`, `1e-14`, `1e-16`, `0`];\nanswer = 2;\nradioq(choices, answer, keep_order=true)\n\n\nQuestion ….\nUsing Simpson’s rule and n=1000 compute the integral of \\(f(x) = 1/(1+x^2)\\) between \\(0\\) and \\(1\\).\n#| echo: false\na,b,n = 0, 1, 1000\nval = riemann(x -> 1/(1+x^2), a, b, n, method=\"simpsons\");\nnumericq(val, 1e-5)"
  },
  {
    "objectID": "integration.html#the-quadgk-function",
    "href": "integration.html#the-quadgk-function",
    "title": "10  Numeric integration with Julia",
    "section": "10.5 The quadgk function",
    "text": "10.5 The quadgk function\nJulia provides the quadgk function to do adaptive Gauss-Konrod quadrature, a modern, fast and accurate means to compute 1-dimensional integrals numerically. This is in the QuadGK package which is loaded with MTH229.\nThe use is straightforward, and similar to riemann above: you specify a function object, and the limits of integration. You don’t specify \\(n\\) – as this is computed adaptively – but you can optionally specify a tolerance which controls the accuracy, though we don’t do so here. For example, a typical usage might be:\na, err = quadgk(sin, 0, pi)     ## 2 is exact\nTwo values are returned, the answer and an estimate of the error. In the above, \\(2\\) is the exact answer to this integral, the estimated value a just a bit more \\(2\\), but is estimated to be off my no more than the second value, \\(1.78 \\cdot 10^{-12}\\).\nIf just the answer is of interest, then it can be extracted using index notation:\nquadgk(sin, 0, pi)[1]       # [1] picks out the first component or two\n\nFor another illustration, since Archimedes the known answer for \\(\\int_0^1 x^2 dx\\) is \\(1/3\\). We see that quadgk gets it right for all the digits:\nquadgk(x -> x^2, 0, 1)\nThe riemann function is good for pedagogical purposes, but the quadgk function should be used instead of the riemann function – besides being built-in to julia it is more accurate, more robust, fast, and less work to use.\n(That quadgk is exact with polynomials is no surprise, as the underlying choice of nodes and weights makes it so for polynomials of certain degree.)\n\n\n\n\n\n\nInfo\n\n\n\nFor other integration routines, the Cubature package is an interface to the Cubature library (http://ab-initio.mit.edu/wiki/index.php/Cubature) which provides serveral. Cubature is the term for higher dimensional integrals, quadrature refers to finding area. In that package, the function hquadrature is similar to quadgk. (The two are written by the same author.)\n\n\n\n10.5.1 Practice\n\nQuestion Use quadgk\nLet \\(f(x) = \\exp(-4 \\cdot |x-1/2|)\\). Find the integral over \\([0,1]\\) using quadgk:\n#| echo: false\nf(x) = exp(-4*abs(x-1/2))\nval = quadgk(f, 0, 1)[1];\nnumericq(val, 1e-5)\n\n\nQuestion Use quadgk\nLet \\(f(x) = \\sin(100\\pi x)/(\\pi x)\\). Find the integral over \\([0,1]\\) using quadgk:\n#| echo: false\nf(x) = sin(100pi *x)/(pi*x);\nval = quadgk(f, 0, 1)[1];\nnumericq(val, 1e-4)\n\n\nQuestion Use quadgk\nLet \\(f(x) = \\sin(100\\pi x)/(100\\pi x)\\). Using \\(1,000\\) points, find the right-Riemann integral over \\([0,1]\\).\n#| echo: false\nf(x) = sin(100*pi*x)/(100*pi*x)\na, b, n = 0, 1, 1000\nval = riemann(f, a, b, n, method=\"right\")\nnumericq(val, 1e-5)\n(The answer via Riemann sums isn’t even correct to 4 decimal points, due to the highly oscillatory nature of the function.)\n\n\nQuestion\nHow far off is this Riemann estimate, when \\(n=100,000\\)?\nf(x) = 1/(1 + x^4)\nquadgk(f, 0, 1)[1] - riemann(f, 0, 1, 100_000);\n#| echo: false\nchoices = [\"Roughly `1e-4`\",\n         \"Roughly `1e-6`\",\n         \"Roughly `1e-12`\"\n         ];\nanswer = 2;\nradioq(choices, answer)\n\n\nQuestion\nThe quadgk function allows you to specify issues where there are troubles. For example, we know that \\(f(x) = \\sin(x)/x\\) has an issue at 0. Directly trying this integral quadgk(x->sin(x)/x, -pi, pi) will fail, but you can specify the issue at \\(0\\) as follows quadgk(x -> sin(x)/x, -pi, 0, pi). Do so. What is the value of the result:\n#| echo: false\nval = quadgk(x -> sin(x)/x, -pi, 0, pi)[1];\nnumericq(val, 1e-4)\n\n\nQuestion\nLet \\(f(x) = |x - 0.3|^{-1/4}\\). We wish to find \\(\\int_0^1 f(x) dx\\). The problem with this function is the singularity at \\(x=0.3\\). (That is, the function is not continuous, so has no guarantee that an integral over a closed domain exists.) However, some such integrals do exist, and the quadgk function can integrate around such singularities by spelling them out in the domain of integration. Just specify the trouble spots between the endpoints:\nf(x) = abs(x - 0.3)^(-1/4)\nval = quadgk(f, 0, 0.3, 1);\nFollowing the above, what answer do you get?\n#| echo: false\nnumericq(val[1], 1e-4)"
  },
  {
    "objectID": "integration.html#applications",
    "href": "integration.html#applications",
    "title": "10  Numeric integration with Julia",
    "section": "10.6 Applications",
    "text": "10.6 Applications\nThere are many more applications of the integral beyond computing areas under the curve. Here we discuss two:\n\nfinding the volume of a figure with rotational symmetry (a glass in our example) and\nfinding the arc length of a line.\n\nIn each case one integrates a function related to the one describing the problem. If you keep this straight, the applications are no different than above.\n\n10.6.1 Volume as a function of radius.\nThe volume of a solid of revolution about the \\(y\\)-axis is illustrated here.\nThis figure shows a volume of revolution (a glass) with an emphasis on the radius of the solid. The volume can be determined if the radius is known.\n\n\n\nGlass\n\n\nThe basic formula requires the description of the radius as a function of \\(x\\) (if oriented as the figure) or the height, \\(h\\), (if oriented as in real life). Suppose we specify the radius with \\(r(h)\\), then the following formula holds with \\(b\\) the total height.\n\\[\nV(b) = \\int_0^b \\pi r(h)^2 dh.\n\\]\nFor a symmetrical drinking vessel, like most every glass you drink from, the volume can be computed from a formula if a function describing the radius is known. For a given glass, let \\(r(h)\\) give the radius as a function of height. Then, as above, the volume of the vessel as a function of height, \\(b\\), is given by an integral:\n\\[\nV(b) = \\int_0^b \\pi (r(h))^2 dh\n\\]\nWe wish to look at our intuition relating the height of the fluid in the vessel compared to the percentage of fluid of the whole. A basic question might be: If the vessel is filled half way by height, is the volume half of the total, more or less?\nThe answer, of course, depends on the shape of the glass. That is the shape of the function \\(r(h)\\). Note, if \\(r(h)\\) is a constant – the glass is a cylinder – then the half-height mark is also the half-volume mark. Not so in general.\nFor a standard measuring cup, the answer for different b’s is printed on the side:\n\n\n\nMeasuring cup\n\n\nWith the formula for the volume of a solid of revolution we can compute this marks numerically if we know the radius as a function of height.\nIn Glass Shape Influences Consumption Rate for Alcoholic Beverages the authors demonstrate that the shape of the glass can have an effect on the rate of consumption, presumably people drink faster when they aren’t sure how much they have left. In particular, they comment that people have difficulty judging the half-finished-by-volume mark.\nThis figure shows some of the wide variety of beer-serving glasses:\nBeer glasses\nWe work with metric units, as there is a natural relation between volume in cm\\(^3\\) and liquid measure (1 liter = 1000 cm\\(^3\\), so a 16-oz pint glass is roughly \\(450\\) cm\\(^3\\).)\nLet two glasses be given as follows. A typical pint glass with linearly increasing radius:\n\\[\nr(h) = 3 + \\frac{1}{5}h, \\quad 0 \\leq h \\leq b;\n\\]\nand a curved edge one:\n\\[\ns(h) = 3 + \\log(1 + h), \\quad 0 \\leq h \\leq b\n\\]\nHalf full\nOne could also consider a fluted one, such as appears in the comparison noted in the article.\n\nQuestion\nWhich of these functions might describe a fluted glass where the radius changes faster as the height gets bigger, that is the radius is a concave up function?\n#| echo: false\nchoices = [\"`r(h) = 2 + (x/10)^2, 0 <= x <= 10`\",\n         \"`r(h) = 2 + sqrt(x/10), 0 <= x <= 10`\",\n         \"`r(h) = 2 + x/10, 0 <= x <= 10`\"\n         ];\nanswer = 1;\nradioq(choices, answer)\n\nFor the two types of glasses in the figure, we create functions in julia as follows:\nr(h) = 3 + h/5\ns(h) = 2 + log(1 + h)\nr_vol(b) = quadgk(x -> pi*r(x)^2, 0, b)[1]\ns_vol(b) = quadgk(x -> pi*s(x)^2, 0, b)[1]\nThen we can easily find the volume as a function of height. For example at 10cm we have:\n(r_vol(10), s_vol(10))\nHowever, to find \\(b\\) that makes the glass \\(450\\) cm\\(^3\\) requires us to solve an equation involving an integral for \\(b\\):\n\\[\nV(b) = \\int_0^b \\pi r(h)^2 dh = 450.\n\\]\nNot to worry, we can use find_zero from the Roots package for that (again, this is loaded with the MTH229 package). To solve for when V(b) = r_vol(b) - 450 = 0 we have\nr_b = find_zero(x -> r_vol(x) - 450,  10)\nSo \\(b\\) is basically \\(9.17\\). Given this, how much volume is left at b/2?\nr_vol(r_b/2)\nWhich is what percent of the whole?\nr_vol(r_b/2) / r_vol(r_b) * 100\nAs this height is often mistaken for the half-way by volume mark, people tend to drink these pints faster than they think.\nNow compare to the height to get half the volume (225 ml):\nr_half = find_zero(x -> r_vol(x) - 225,  5)\nThis value is more than half of \\(b\\):\nr_half / r_b\nAt this height only half the volume is remaining (and not at 50% of the original height.)\n\n\n\n10.6.2 Practice\n\nQuestion\nCompare the above for the curved glass, where \\(s(h) = 3 + \\log(1 + h)\\).\nWhat is the height of the glass, b, needed to make the volume 450?\n#| echo: false\ns(h) = 3 + log(1 + h)\ns_vol(b) = quadgk(x -> pi*s(x)^2, 0, b)[1]\nb = find_zero(x -> s_vol(x) - 450, 8);\nval = b\nnumericq(val, 1e-3)\n\n\nQuestion\nFind the volume of the glass represented by \\(s(h) = 3 + \\log(1 + h), 0 \\leq h \\leq b\\) when the glass is filled to half its height. Report the value as a percentage of the total volume.\n#| echo: false\nval = s_vol(b/2) / s_vol(b) * 100;\nnumericq(val,1)\n\n\nQuestion\nNow, what height of filling will produce half the volume when? Report your answer in terms of a percentage of \\(b\\), height of the glass.\n#| echo: false\nb12 = find_zero(x -> s_vol(x) - 450/2, 4)\nval = b12/b*100;\nnumericq(val, .1)\n\n\nQuestion\nConsider this big Solo cup:\n\n\n\nSolo cup\n\n\nIt has approximate dimensions: smaller radius 5 feet, upper radius 8 feet and height 15 feet. How many gallons is it? At \\(8\\) pounds a gallon this would be pretty heavy!\nTwo facts are useful:\n\na cubic foot is 7.48052 gallons\nthe radius as a function of height is \\(r(h) = 5 + (3/15)\\cdot h\\)\n\n#| echo: false\ngft = 7.48052\nr(h) = 5 + (3/15)*h\na,err = quadgk(h -> pi*r(h)^2, 0, 15)\nval = a*gft\nnumericq(val, 1e1)"
  },
  {
    "objectID": "integration.html#example-arc-length",
    "href": "integration.html#example-arc-length",
    "title": "10  Numeric integration with Julia",
    "section": "10.7 Example, arc length",
    "text": "10.7 Example, arc length\nThe basic indefinite integral for a positive function answers the amount of area under the curve over a given interval. However, the integral can be interpreted in many different ways. For example, one can use an integral to answer how long a curve is. Of course one can estimate this answer. For example, consider this curve:\nplot(x -> x^2, 0, 1)\nThis curve has length no more than \\(2 = 1 + 1\\) – the distance along the \\(x\\) axis starting at \\(0\\) to \\(1\\) and then going up. It is also longer than \\(\\sqrt{2} = \\sqrt{1^2 + 1^2}\\) – the straight line distance between the two endpoints. But how long is it?\nIn general, the arc length of the curve \\(y=f(x)\\) between \\(a \\leq x \\leq b\\) (or how long is the curve) is given through the formula\n\\[\nl = \\int_a^b \\sqrt{1 + f'(x)^2} dx\n\\]\nThe formula is from the length of the hypotenuse of a right triangle with lengths \\(1\\) and \\(f'(x)\\), This image suggests an approximation for the length and why the hypotenuse of some triangle might be involved.\nArc length\nRather than focus on a derivation, we do some examples illustrating that to compute the arclength of the graph of a function is relatively straightforward using numeric integration. For example, our answer for \\(f(x) = x^2\\) is given by\nf(x) = x^2\nquadgk(x -> sqrt(1 + f'(x)^2), 0, 1)      # using f' notation defined in MTH229\n(We use an anonymous function for the integrand which involved the derivative being found through f'. If the graph is described by f, then this expression be the same for all these problems.)\n\nWhereas, the length of the \\(f(x) = \\sin(x)\\) over \\([0, \\pi]\\) would be:\nf(x) = sin(x)\nquadgk(x -> sqrt(1 + f'(x)^2), 0, pi)\nNext we look at a more practical problem.\n\n10.7.1 Example: the caternary shape\nA caternary shape is the shape a hanging chain will take as it is suspended between two posts. It appears elsewhere, for example, power wires will also have this shape as they are suspended between towers. A formula for a caternary can be written in terms of the hyperbolic cosine, cosh in julia or exponentials.\n\\[\ny = a \\cosh(x/a) = a \\cdot \\frac{e^{x/a} + e^{-x/a}}{2}.\n\\]\nSuppose we have the following wire hung between \\(x=-1\\) and \\(x=1\\) with \\(a = 2\\):\nf(x; a=2) = a * cosh(x/a)\nplot(f, -1, 1)\nHow long is the chain? Looking at the graph we can guess an answer is between \\(2\\) and \\(2.5\\), say, but it isn’t much work to get the answer:\nquadgk(x -> sqrt(1 + f'(x)^2), -1, 1)\n\n\n10.7.2 Practice\n\nQuestion\nThe sag in the chain is adjusted through the parameter \\(a\\) – chains with larger \\(a\\) have less sag.\nSuppose your chain has parameter a=3 what is the length? (Use quadgk)\n#| echo: false\nf(x; a=3) = a*cosh(x/a);\nval <- quadgk(x -> sqrt(1 + f'(x)^2), -1, 1)[1];\nnumericq(val, .001)\n\n\nQuestion: in the artist studio\nThis picture of Jasper Johns Near the Lagoon was taken at The Art Institute Chicago.\nJasper Johns\nThe museum notes have\n\nFor his Catenary series (1997–2003), of which Near the Lagoon is the largest and last work, Johns formed catenaries—a term used to describe the curve assumed by a cord suspended freely from two points—by tacking ordinary household string to the canvas or its supports.\n\nThis particular catenary has a certain length. The basic dimensions are 78in wide and 118in drop. If our shifted function is\n\\[\nf(x; a, b) = a \\cosh(x/a) - b\n\\]\nThen we have \\(f(0) = -118\\) and \\(f(78/2) = 0\\) using the origin midway between the two tops of the curve. Solving the first gives\n\\[\n-118 = a - b \\text{ or } b = a + 118.\n\\]\nThe second gives \\(a \\cdot \\cosh(78/(2a)) - (a + 118) = 0\\). This can be solved numerically for a:\ncatenary(x; a=1, b=0) = a*cosh(x/a) - b\na = newton(a -> catenary(78/2, a=a, b=118 + a), 1)\nRounding, we take \\(a=13\\). With these parameters (\\(a=13\\), \\(b = 131\\)), compute the length of John’s catenary.\n#| echo: false\na = 13\nb = 118 + a\nf(x) = catenary(x, a=13, b=118+13)\nval = quadgk(x -> sqrt(1 + f'(x)^2), -78/2, 78/2)[1];\nnumericq(val, 1)\n\n\nQuestion Bridges are parabolas\nSuspension bridges, like the Verrazano bridge, have different loading than a cable and hence a different shape. A parabola is the shape the cable takes under uniform loading.\nThe Verrazano-Narrows bridge has a span of 1298m. Suppose the drop of the main cables is 147 meters over this span. Then the cable itself can be modeled as a parabola with\n\n\\[\nx\n\\]\n-intercepts \\(a = 1298/2\\) and \\(-a\\) and\nvertex \\((0,b)\\) with \\(b=-147\\).\n\nThe parabola that fits these three points is\n\\[\ny = \\frac{-b}{a^2}(x^2 - a^2)\n\\]\nFind the arc length of the cable in meters.\n#| echo: false\na = 1298/2;\nb = -147;\nf(x) = (-b/a^2)*(x^2 - a^2);\nval = quadgk(x -> sqrt(1 + f'(x)^2), -1, 1)[1];\nnumericq(val, 1e-3)\nIn the picture of the Verrazano-Narrows bridge, would the shape during construction be a parabola or a cateneary?\n#| echo: false\nchoices = [\"A parabola, as just mentioned\",\n\"A catenary, basically, as in the picture there is basically no load on the cables.\"\n]\nanswer = 2\nradioq(choices, answer)\n\n\nQuestion The tractrix\nA boat sits at the point \\((a, 0)\\) and a man holds a rope taut attached to the boat at the origin \\((0,0)\\). The man walks on the \\(y\\) axis. The position \\(y\\) depends then on the position \\(x\\) of the boat, and if the rope is taut, the position satisfies:\n\\[\ny = a \\ln\\frac{a + \\sqrt{a^2 - x^2}}{x} - \\sqrt{a^2 - x^2}\n\\]\nThis can be entered into julia as:\ng(x, a) = a * log((a + sqrt(a^2 - x^2))/x) - sqrt(a^2 - x^2)\nLet \\(a=12\\), \\(f(x) = g(x, a)\\). Compute the length the bow of the boat has traveled between \\(x=1\\) and \\(x=a\\) using quadgk.\n#| echo: false\na = 12\nf(x) = g(x, a);\nval =quadgk(x -> sqrt(1 + f'(x)^2), 1, a)[1];\nnumericq(val, 1e-3)\n(The most elementary description of this curve is in terms of the relationship \\(dy/dx = -\\sqrt{a^2-x^2}/x\\) which could be used in place of f' in your work.)\n\n\n\n\n\n\nMore on the tractrix\n\n\n\nWatch this video to see an example of how the tractrix can be found in an everyday observation. Also here."
  },
  {
    "objectID": "integration.html#gauss-quadrature-using-weights",
    "href": "integration.html#gauss-quadrature-using-weights",
    "title": "10  Numeric integration with Julia",
    "section": "10.8 Gauss quadrature, Using weights",
    "text": "10.8 Gauss quadrature, Using weights\nWhat components go into the quadgk function? This section covers some of the background.\nThe trapezoid rule can be rearranged to become:\n\\[\n\\delta f(x_0) + 2\\delta f(x_2) + 2 \\delta f(x_3) + \\cdots + 2 \\delta f(x_{n}) + \\delta f(x_{n})\n\\]\nwhere \\(\\delta = (b-a)/n\\).\nWhereas for even \\(n\\), Simpson’s rule can be written with:\n\\[\n\\delta f(x_0) + 4\\delta f(x_1) + 2 \\delta f(x_2) + \\cdots +  4 \\delta f(x_{n-2}) + 2 \\delta f(x_{n-1}) + \\delta f(x_{n})\n\\]\nwith \\(\\delta = (b-a)/n \\cdot (1/6)\\).\nThese both have the general form of\n\\[\n\\sum_k w_k \\cdot f(x_k)\n\\]\nwhere \\(w_k\\) are weights and the \\(x_k\\) some choice of points (nodes) – not necessarily evenly spaced, though that is so in the examples we’ve seen. So, an alternative way to do the trapezoid formula in julia for \\(n=4\\) might be:\na, b, n = 0, 1, 4\ndelta = (b-a)/n\nf(x) = x^2\nwts = [1, 2, 2, 2, 1] * delta ## delta * [1, repeat([2],n-1), 1]'\nxs = a .+ (0:n) * delta\nsum(w * f(x) for (w,x) in zip(wts, xs))\nThe compact code of the last line to compute the approximate integral shows there are three important things in this form of the integral: the weights, the nodes or \\(x\\) values, and the function. The use of equally spaced nodes has been used by us so far, but it need not be the case. If fact Gauss showed he could get similar answers faster if it wasn’t the case.\nThe Gauss nodes and weights are computable (http://en.wikipedia.org/wiki/Gaussian_quadrature). The main tools are the so-called Legendre polynomials, which can be defined recursively with Bonnet’s formula:\n\\[\nP_0(x) = 1; P_1(x) = x; \\quad  n P_{n}(x)  = (2(n-1)+1) x P_{n-1}(x) -(n-1) P_{n-2}(x).\n\\]\nUsing julia’s Polynomials package this can be implemented almost verbatim:\nimport Polynomials\nimport Polynomials: Polynomial\nfunction lgp(n::Integer)\n    if n == 0 return Polynomial([1]) end\n    if n == 1 return Polynomial([0, 1]) end\n\n    (2*(n-1) + 1) / n * lgp(1) * lgp(n-1) - (n-1)/n * lgp(n-2)\nend\nThis is used as,\np4 = lgp(4)\nThe term recursion is applied to a function when it makes a reference to itself during a computation. With this function, don’t try it with values much bigger than \\(20\\), as the recursion can take a long time.\nThe nodes are the roots of the right polynomial. Here we have the values for p4\nxs = Polynomials.roots(p4)\n(The Konrod part of quadgk changes the nodes so they can be reused during the refinement.)\nFinally, the weights involve the derivative of \\(P_n\\) through:\n\\[\nw_i = \\frac{2}{(1 - x_i^2) \\cdot(P^{'}_n(x_i)/P_n(1))^2}\n\\]\nThese can be done simply with:\nweights(x) = 2 / ((1 - x^2) * (Polynomials.derivative(p4)(x)/p4(1))^2 )\nws = [weights(xi) for xi in xs]\nFrom here gauss_quadrature will do the integration of f over the interval \\([-1,1]\\), though we can do it ourself quickly enough. Here we compute the integral of \\(\\cos(\\pi/2 x)\\) over \\([-1,1]\\) (you can check this is very close to the answer \\(4/\\pi\\) even with just 4 nodes):\nf(x) = cos(pi/2*x)\nsum(w * f(x) for (w,x) in zip(ws, xs))\n\n10.8.1 Adaptive integration\nNext, we a have a brief discussion about an alternative means to compute integrals. The following function adapt implements a basic adaptive quadrature method for integration. The basic idea is that for a subinterval \\([a,b]\\) if the area of the trapezoid is not close to the area of Simpson’s parabolic estimate then the subinterval is split into two pieces \\([a,c]\\) and \\([c,b]\\) and the same question is asked. If the area is close the Simpson’s parabolic estimate is used to estimate the integral of \\(f\\) over that subinterval.\nAgain, we see recursion when programming this algorithm. To avoid infinite loops during this, we use a limit below to keep track.\nIn general, the value of adaptive methods like this, is the function calls concentrate on areas where \\(f\\) is not well approximated and where it is well approximated it just moves on. This approach works well for poorly behaved functions, as it has a more refined grid there.\n#| echo: false\n#from the MASS function adapt\nnothing\nfunction adapt(f, a, b, limit)\n\n    h = b-a\n    c = a + (b - a)/2\n\n    a1 = (f(a) + f(b)) * h/2          ## trapezoid\n    a2 = (f(a) + 4f(c) + f(b)) * h/6  ## Simpson's parabola\n\n    if isapprox(a1, a2)\n        return(a2)\n    end\n\n    if limit == 0\n        println(\"limit reached for this interval [$a, $b]\")\n    return(a2)\n    end\n\n    adapt(f, a, c, limit - 1) + adapt(f, c, b, limit-1)\nend\nDoes it work? Let’s see it for the area of \\(f(x) = x^2(1-x)^{10}\\) which is known to satisfy \\(\\beta(2+1, 10+1)\\)\nout = adapt(x -> x^2 * (1 -x)^10, 0, 1, 10)\nNot too far off (1e-10) from the known answer which is a beta function:\nout - beta(2 + 1, 10 + 1)\n(The use of isapprox above determines how accurate the values will be. This function uses two tolerances to test if the valus x and y are approximately the same. These could be changed easily enough so that more precise answers can be found.)"
  },
  {
    "objectID": "mth232.html",
    "href": "mth232.html",
    "title": "11  Notes on MTH 232 and Julia",
    "section": "",
    "text": "See the projects at https://github.com/mth229/232-projects. They can be used through Launch \n\nSymbolic\n\nDiscusses how to do some symbolic math in julia through the SymPy package.\nAn assignment for this material: ipynb view\n\n\nApplications of the integral: area between two curves, volume of solids of revolution, other volumes\n\n An assignment for this material: ipynb view\n\n\nTechniques of integration: substitution, integration by parts, partial fractions\n\n An assignment for this material: ipynb view\n\n\nTaylor polynomials\n\n An assignment for this material: ipynb view\n\n\nParametric equations and polar coordinates\n\n An assignment for this material: ipynb view"
  },
  {
    "objectID": "mth233.html",
    "href": "mth233.html",
    "title": "12  Notes on MTH 233 and Julia",
    "section": "",
    "text": "These are all located here and can be run through .\n\nVectors and vector-valued functions, \\(f: R -> R^n\\).\n\nNotes\n An assignment for this material: ipynb view\n\n\nFunctions of several variables, \\(f:R^n -> R\\). Notes\n\n An assignment for this material: ipynb view\n\n\nDouble and triple integration.\n\nNotes\n An assignment for this material: ipynb view"
  }
]